

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>TripleO &mdash; Root Pages  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="../programming/index.html" />
    <link rel="prev" title="OpenStack-Ansible" href="openstack-ansible.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Root Pages
          

          
          </a>

          
            
            
              <div class="version">
                2021.04.01
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Administration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../administration/authentication.html">Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/chromebook.html">Chromebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/graphics.html">Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/linux.html">Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/macs.html">Macs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/mail_servers.html">Mail Servers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/operating_systems.html">Operating Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/package_managers.html">Package Managers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/security.html">Security</a></li>
</ul>
<p class="caption"><span class="caption-text">Automation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../automation/ansible.html">Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="../automation/puppet.html">Puppet</a></li>
</ul>
<p class="caption"><span class="caption-text">Computer Hardware</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/graphics_cards.html">Graphics Cards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/laptops.html">Laptops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/monitors.html">Monitors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/storage_devices.html">Storage Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/webcams.html">Webcams</a></li>
</ul>
<p class="caption"><span class="caption-text">HTTP</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../http/clustering.html">Clustering and High Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/cms.html">Content Management Systems (CMSs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/http_servers.html">HTTP Servers</a></li>
</ul>
<p class="caption"><span class="caption-text">Networking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../networking/dns_servers.html">DNS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../networking/networking_hardware.html">Networking (Hardware)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../networking/linux.html">Linux Networking</a></li>
</ul>
<p class="caption"><span class="caption-text">Observation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../observation/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../observation/monitoring.html">Monitoring</a></li>
</ul>
<p class="caption"><span class="caption-text">OpenStack</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="openstack.html">OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer.html">OpenStack Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="kolla.html">Kolla</a></li>
<li class="toctree-l1"><a class="reference internal" href="openstack-ansible.html">OpenStack-Ansible</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">TripleO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#red-hat-openstack-platform-releases">Red Hat OpenStack Platform Releases</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#historical-milestones">Historical Milestones</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#upstream">Upstream</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downstream">Downstream</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#repositories">Repositories</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Upstream</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Downstream</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deployment-quick">Deployment (Quick)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#packstack">Packstack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install">Install</a></li>
<li class="toctree-l4"><a class="reference internal" href="#answer-file">Answer File</a></li>
<li class="toctree-l4"><a class="reference internal" href="#uninstall">Uninstall</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tripleo-quickstart">TripleO Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="#standalone">Standalone</a></li>
<li class="toctree-l3"><a class="reference internal" href="#infrared-2">InfraRed 2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deployment-full">Deployment (Full)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#undercloud">Undercloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">Uninstall</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#overcloud-provision-nodes-with-ironic">Overcloud (Provision Nodes with Ironic)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#overcloud-pre-deployed-provisioned-nodes">Overcloud (Pre-deployed/provisioned Nodes)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#operations">Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#updates-minor">Updates (Minor)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#upgrades-major">Upgrades (Major)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-a-compute-node">Add a Compute Node</a></li>
<li class="toctree-l3"><a class="reference internal" href="#remove-a-compute-node">Remove a Compute Node</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rebooting-the-cloud">Rebooting the Cloud</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ansible-playbooks-config-download">Ansible Playbooks (config-download)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#manual">Manual</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#configurations">Configurations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#composable-roles">Composable Roles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#openstack-services">OpenStack Services</a></li>
<li class="toctree-l3"><a class="reference internal" href="#networks">Networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#interfaces-os-net-config">Interfaces (os-net-config)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vlans">VLANs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ip-addressing">IP Addressing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#public">Public</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#containers">Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#packages">Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ceph">Ceph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#overcloud-cloud-init">Overcloud (cloud-init)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#minions">Minions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scaling-large-overcloud">Scaling (Large Overcloud)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#puppet">Puppet</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lab-tips">Lab Tips</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#service-telemetry-framework">Service Telemetry Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tips">Tips</a></li>
<li class="toctree-l3"><a class="reference internal" href="#errors">Errors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#openshift-on-openstack">OpenShift on OpenStack</a></li>
<li class="toctree-l2"><a class="reference internal" href="#history">History</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bibliography">Bibliography</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Programming</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../programming/c_and_c%2B%2B.html">C and C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/devops.html">DevOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/go.html">Go</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/packaging.html">Packaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/python.html">Python 3</a></li>
</ul>
<p class="caption"><span class="caption-text">Storage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../storage/backup_and_recovery.html">Backup and Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/bootloaders.html">Bootloaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/ceph.html">Ceph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/file_systems.html">File Systems</a></li>
</ul>
<p class="caption"><span class="caption-text">Virtualization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../virtualization/containers.html">Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../virtualization/kubernetes_administration.html">Kubernetes Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../virtualization/kubernetes_development.html">Kubernetes Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../virtualization/virtual_machines.html">Virtual Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../virtualization/wine.html">Wine</a></li>
</ul>
<p class="caption"><span class="caption-text">Commands</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../commands/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/compression.html">Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/configuration_management.html">Configuration Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/firewalls.html">Firewalls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/hardware.html">Hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/openstack.html">OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/package_managers.html">Package Managers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/permissions.html">Permissions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/phones.html">Phones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/security.html">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/software_code_management.html">Source Code Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/storage.html">Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/text_editors.html">Text Editors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/virtualization.html">Virtualization</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Root Pages</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">&lt;no title&gt;</a> &raquo;</li>
        
      <li>TripleO</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/openstack/tripleo.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tripleo">
<h1><a class="toc-backref" href="#id4">TripleO</a><a class="headerlink" href="#tripleo" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#tripleo" id="id4">TripleO</a></p>
<ul>
<li><p><a class="reference internal" href="#introduction" id="id5">Introduction</a></p>
<ul>
<li><p><a class="reference internal" href="#red-hat-openstack-platform-releases" id="id6">Red Hat OpenStack Platform Releases</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#historical-milestones" id="id7">Historical Milestones</a></p>
<ul>
<li><p><a class="reference internal" href="#upstream" id="id8">Upstream</a></p></li>
<li><p><a class="reference internal" href="#downstream" id="id9">Downstream</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#repositories" id="id10">Repositories</a></p>
<ul>
<li><p><a class="reference internal" href="#id1" id="id11">Upstream</a></p></li>
<li><p><a class="reference internal" href="#id2" id="id12">Downstream</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#deployment-quick" id="id13">Deployment (Quick)</a></p>
<ul>
<li><p><a class="reference internal" href="#packstack" id="id14">Packstack</a></p>
<ul>
<li><p><a class="reference internal" href="#install" id="id15">Install</a></p></li>
<li><p><a class="reference internal" href="#answer-file" id="id16">Answer File</a></p></li>
<li><p><a class="reference internal" href="#uninstall" id="id17">Uninstall</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tripleo-quickstart" id="id18">TripleO Quickstart</a></p></li>
<li><p><a class="reference internal" href="#standalone" id="id19">Standalone</a></p></li>
<li><p><a class="reference internal" href="#infrared-2" id="id20">InfraRed 2</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#deployment-full" id="id21">Deployment (Full)</a></p>
<ul>
<li><p><a class="reference internal" href="#undercloud" id="id22">Undercloud</a></p>
<ul>
<li><p><a class="reference internal" href="#id3" id="id23">Uninstall</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#overcloud-provision-nodes-with-ironic" id="id24">Overcloud (Provision Nodes with Ironic)</a></p></li>
<li><p><a class="reference internal" href="#overcloud-pre-deployed-provisioned-nodes" id="id25">Overcloud (Pre-deployed/provisioned Nodes)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#operations" id="id26">Operations</a></p>
<ul>
<li><p><a class="reference internal" href="#updates-minor" id="id27">Updates (Minor)</a></p></li>
<li><p><a class="reference internal" href="#upgrades-major" id="id28">Upgrades (Major)</a></p></li>
<li><p><a class="reference internal" href="#add-a-compute-node" id="id29">Add a Compute Node</a></p></li>
<li><p><a class="reference internal" href="#remove-a-compute-node" id="id30">Remove a Compute Node</a></p></li>
<li><p><a class="reference internal" href="#rebooting-the-cloud" id="id31">Rebooting the Cloud</a></p></li>
<li><p><a class="reference internal" href="#ansible-playbooks-config-download" id="id32">Ansible Playbooks (config-download)</a></p>
<ul>
<li><p><a class="reference internal" href="#manual" id="id33">Manual</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#configurations" id="id34">Configurations</a></p>
<ul>
<li><p><a class="reference internal" href="#composable-roles" id="id35">Composable Roles</a></p></li>
<li><p><a class="reference internal" href="#openstack-services" id="id36">OpenStack Services</a></p></li>
<li><p><a class="reference internal" href="#networks" id="id37">Networks</a></p>
<ul>
<li><p><a class="reference internal" href="#interfaces-os-net-config" id="id38">Interfaces (os-net-config)</a></p></li>
<li><p><a class="reference internal" href="#vlans" id="id39">VLANs</a></p></li>
<li><p><a class="reference internal" href="#ip-addressing" id="id40">IP Addressing</a></p></li>
<li><p><a class="reference internal" href="#public" id="id41">Public</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#containers" id="id42">Containers</a></p></li>
<li><p><a class="reference internal" href="#packages" id="id43">Packages</a></p></li>
<li><p><a class="reference internal" href="#ceph" id="id44">Ceph</a></p></li>
<li><p><a class="reference internal" href="#overcloud-cloud-init" id="id45">Overcloud (cloud-init)</a></p></li>
<li><p><a class="reference internal" href="#minions" id="id46">Minions</a></p></li>
<li><p><a class="reference internal" href="#scaling-large-overcloud" id="id47">Scaling (Large Overcloud)</a></p></li>
<li><p><a class="reference internal" href="#puppet" id="id48">Puppet</a></p></li>
<li><p><a class="reference internal" href="#lab-tips" id="id49">Lab Tips</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#troubleshooting" id="id50">Troubleshooting</a></p>
<ul>
<li><p><a class="reference internal" href="#service-telemetry-framework" id="id51">Service Telemetry Framework</a></p></li>
<li><p><a class="reference internal" href="#tips" id="id52">Tips</a></p></li>
<li><p><a class="reference internal" href="#errors" id="id53">Errors</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#openshift-on-openstack" id="id54">OpenShift on OpenStack</a></p></li>
<li><p><a class="reference internal" href="#history" id="id55">History</a></p></li>
<li><p><a class="reference internal" href="#bibliography" id="id56">Bibliography</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="introduction">
<h2><a class="toc-backref" href="#id5">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Supported operating systems: RHEL/CentOS &gt;= 7, Fedora</p>
<p>TripleO means “OpenStack on OpenStack.” The Undercloud is first deployed onto a single node with the essential OpenStack services to handle baremetal deployments. That server is then used to create and manage a full production cloud called the Overcloud.</p>
<p>TripleO is a collection of many services. As part of the Transformation Squad’s goal, Undercloud services are being removed and/or refactored to provide a simpler deployment tool. These are the services that are used on the Undercloud [52]:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Service</p></th>
<th class="head"><p>Removed In</p></th>
<th class="head"><p>Replaced By</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Ansible</p></td>
<td></td>
<td></td>
<td><p>Used for deploying the Undercloud and Overcloud services.</p></td>
</tr>
<tr class="row-odd"><td><p>Ceilometer</p></td>
<td><p>Stein</p></td>
<td></td>
<td><p>Collects information about the Overcloud nodes.</p></td>
</tr>
<tr class="row-even"><td><p>docker</p></td>
<td><p>Ussuri</p></td>
<td><p>Podman</p></td>
<td><p>Container runtime for OpenStack services.</p></td>
</tr>
<tr class="row-odd"><td><p>Glance</p></td>
<td></td>
<td></td>
<td><p>Image management used by Ironic.</p></td>
</tr>
<tr class="row-even"><td><p>Gnocchi</p></td>
<td><p>Stein</p></td>
<td></td>
<td><p>A more efficient alternative to Ceilometer.</p></td>
</tr>
<tr class="row-odd"><td><p>Heat</p></td>
<td></td>
<td></td>
<td><p>Heat parameters define the deployment settings.</p></td>
</tr>
<tr class="row-even"><td><p>Horizon</p></td>
<td><p>Stein</p></td>
<td></td>
<td><p>Web dashboard for deploying an Overcloud.</p></td>
</tr>
<tr class="row-odd"><td><p>Ironic</p></td>
<td></td>
<td></td>
<td><p>Manages the bare-metal provisioning.</p></td>
</tr>
<tr class="row-even"><td><p>Keystone</p></td>
<td></td>
<td></td>
<td><p>Authentication of OpenStack services.</p></td>
</tr>
<tr class="row-odd"><td><p>Kolla</p></td>
<td><p>Victoria</p></td>
<td><p>Ansible (<a class="reference external" href="https://opendev.org/openstack/tripleo-ansible/src/branch/master/tripleo_ansible/roles/tripleo_container_image_build">TCIB</a>)</p></td>
<td><p>Provides container images of OpenStack services.</p></td>
</tr>
<tr class="row-even"><td><p>MariaDB</p></td>
<td></td>
<td></td>
<td><p>Database for OpenStack services.</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral</p></td>
<td><p>Victoria</p></td>
<td><p>Ansible</p></td>
<td><p>Workflows are used to define and execute all of the deployment processes.</p></td>
</tr>
<tr class="row-even"><td><p>Neutron</p></td>
<td></td>
<td></td>
<td><p>Manages the Overcloud networks.</p></td>
</tr>
<tr class="row-odd"><td><p>Nova</p></td>
<td></td>
<td></td>
<td><p>Manages the Overcloud nodes after provisioning.</p></td>
</tr>
<tr class="row-even"><td><p>Paunch</p></td>
<td><p>Victoria</p></td>
<td><p>Ansible</p></td>
<td><p>Container state management.</p></td>
</tr>
<tr class="row-odd"><td><p>Podman</p></td>
<td></td>
<td></td>
<td><p>Container runtime for OpenStack services.</p></td>
</tr>
<tr class="row-even"><td><p>Puppet</p></td>
<td></td>
<td></td>
<td><p>Configuration management.</p></td>
</tr>
<tr class="row-odd"><td><p>RabbitMQ</p></td>
<td></td>
<td></td>
<td><p>Messaging back-end for OpenStack services.</p></td>
</tr>
<tr class="row-even"><td><p>Swift</p></td>
<td></td>
<td></td>
<td><p>Storage for Heat deployment plans.</p></td>
</tr>
<tr class="row-odd"><td><p>Zaqar</p></td>
<td><p>Victoria</p></td>
<td><p>Ansible</p></td>
<td><p>A messaging service used by Mistral.</p></td>
</tr>
</tbody>
</table>
<p>In Pike, most of the Overcloud services are deployed as containers built by Kolla. The most notable service that lacked container support was Neutron due to it’s complexity. Starting in Queens, all of the Overcloud services are installed as containers. Support for also running the Undercloud services in containers was added as a technology preview in Queens and later became the default configuration for Rocky. Previously, <a class="reference external" href="https://opendev.org/openstack/instack-undercloud">instack-undercloud</a> was used to setup and install the Undercloud services and now the same deployment method for the Overcloud is used for the Undercloud. [20]</p>
<div class="section" id="red-hat-openstack-platform-releases">
<h3><a class="toc-backref" href="#id6">Red Hat OpenStack Platform Releases</a><a class="headerlink" href="#red-hat-openstack-platform-releases" title="Permalink to this headline">¶</a></h3>
<p>Red Hat provides most of the development to the core OpenStack services.
The RPM Distribution of OpenStack (RDO) project is a community project
lead by Red Hat to use the latest upstream code from OpenStack and
package it to work and be distributable on Red Hat Enterprise Linux and
Fedora based operating systems. [2]</p>
<p>The Red Hat OpenStack Platform (RHOSP) is a solution by Red Hat that
takes the upstream OpenStack source code and makes it enterprise quality
by hardening the security and increasing it’s stability. Upgrades from one major release of RHOSP to the next have been supported since RHOSP 8.</p>
<p>Release Cycle:</p>
<ul class="simple">
<li><p>RHOSP &lt; 10 = Each release is supported for up to 3 years.</p></li>
<li><p>RHOSP &gt;= 10 = Starting with RHOSP 10, every third release of RHOSP is a long-life (LL) release with up to 5 years of support. In-between releases are supported for 1 year. Fast-forward upgrades are supported to upgrade directly from one LL release to the next (for example, 10 to 13).</p></li>
<li><p>RHOSP &gt;= 16 = Every release of RHOSP is now a LL release. [43]</p></li>
</ul>
<p>Releases:</p>
<ul class="simple">
<li><p>RHOSP 3 (Grizzly)</p>
<ul>
<li><p>Release: 2013-07-10</p></li>
<li><p>EOL: 2014-07-31</p></li>
</ul>
</li>
<li><p>RHOSP 4 (Havana)</p>
<ul>
<li><p>Release: 2013-12-19</p></li>
<li><p>EOL: 2015-06-19</p></li>
</ul>
</li>
<li><p>RHOSP 5 (Icehouse)</p>
<ul>
<li><p>Release: 2014-06-30</p></li>
<li><p>EOL: 2017-06-30</p></li>
</ul>
</li>
<li><p>RHOSP 6 (Juno)</p>
<ul>
<li><p>Release: 2015-02-09</p></li>
<li><p>EOL: 2018-02-17</p></li>
</ul>
</li>
<li><p>RHOSP 7 (Kilo)</p>
<ul>
<li><p>Release: 2015-08-05</p></li>
<li><p>EOL: 2018-08-05</p></li>
</ul>
</li>
<li><p>RHOSP 8 (Liberty)</p>
<ul>
<li><p>Release: 2016-04-20</p></li>
<li><p>EOL: 2019-04-20</p></li>
</ul>
</li>
<li><p>RHOSP 9 (Mitaka)</p>
<ul>
<li><p>Release: 2016-08-24</p></li>
<li><p>EOL: 2019-08-24</p></li>
</ul>
</li>
<li><p><strong>RHOSP 10 LL (Newton)</strong></p>
<ul>
<li><p>Release: 2016-12-15</p></li>
<li><p>EOL: 2021-12-15</p></li>
</ul>
</li>
<li><p>RHOSP 11 (Ocata)</p>
<ul>
<li><p>Release: 2017-05-18</p></li>
<li><p>EOL: 2018-05-18</p></li>
</ul>
</li>
<li><p>RHOSP 12 (Pike)</p>
<ul>
<li><p>Release: 2017-12-13</p></li>
<li><p>EOL: 2018-12-13</p></li>
</ul>
</li>
<li><p><strong>RHOSP 13 LL (Queens)</strong></p>
<ul>
<li><p>Release: 2018-06-27</p></li>
<li><p>EOL: 2023-06-27</p></li>
</ul>
</li>
<li><p>RHOSP 14 (Rocky)</p>
<ul>
<li><p>Release: 2019-01-10</p></li>
<li><p>EOL: 2020-01-10</p></li>
</ul>
</li>
<li><p>RHOSP 15 (Stein)</p>
<ul>
<li><p>Release: 2019-09-19</p></li>
<li><p>EOL: 2020-09-19</p></li>
</ul>
</li>
<li><p><strong>RHOSP 16 LL (Train)</strong></p>
<ul>
<li><p>Release: 2020-02-06</p></li>
<li><p>EOL: 2025-05-30</p></li>
</ul>
</li>
</ul>
<p>Starting with RHOSP 16, each minor release is tied to a specific version of RHEL. [1]</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>RHOSP</p></th>
<th class="head"><p>RHEL</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>16.0</p></td>
<td><p>8.1</p></td>
</tr>
<tr class="row-odd"><td><p>16.1</p></td>
<td><p>8.2</p></td>
</tr>
<tr class="row-even"><td><p>16.2</p></td>
<td><p>8.4</p></td>
</tr>
</tbody>
</table>
<p>RHOSP supports running a virtualized Undercloud on these platforms [3]:</p>
<ul class="simple">
<li><p>Kernel-based Virtual Machine (QEMU with KVM acceleration)</p></li>
<li><p>Red Hat Virtualization (RHV)</p></li>
<li><p>Microsoft Hyper-V</p></li>
<li><p>VMWare ESX and ESXi</p></li>
</ul>
<p>RHOSP only supports using libvirt with KVM as the compute hypervisor’s virtualization technology. [28]</p>
<p>The version of RHOSP in use can be found on the Undercloud by viewing the “/etc/rhosp-release” file. OpenStack packages can also be tracked down to which major release it is a part of by using <a class="reference external" href="https://access.redhat.com/downloads/content/package-browser">https://access.redhat.com/downloads/content/package-browser</a>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ yum install rhosp-release
$ cat /etc/rhosp-release
Red Hat OpenStack Platform release <span class="m">16</span>.0.1 <span class="o">(</span>Train<span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="historical-milestones">
<h2><a class="toc-backref" href="#id7">Historical Milestones</a><a class="headerlink" href="#historical-milestones" title="Permalink to this headline">¶</a></h2>
<div class="section" id="upstream">
<h3><a class="toc-backref" href="#id8">Upstream</a><a class="headerlink" href="#upstream" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Havana</p>
<ul>
<li><p><a class="reference external" href="https://spinal-stack.readthedocs.io/en/latest/changelog/havana/index.html">The first release of Spinal Stack.</a></p></li>
</ul>
</li>
<li><p>Icehouse</p>
<ul>
<li><p><a class="reference external" href="https://spinal-stack.readthedocs.io/en/latest/changelog/icehouse/index.html">The last release of Spinal Stack. The usage of OpenStack to deploy OpenStack was used as inspiration for TripleO.</a></p></li>
</ul>
</li>
<li><p>Juno</p>
<ul>
<li><p>TripleO (OpenStack-on-OpenStack) was released as the spiritual successor to Spinal Stack.</p></li>
</ul>
</li>
<li><p>Mitaka</p>
<ul>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/mitaka/tripleo-ui.html">Introduced the TripleO UI dashboard for helping to deploy an Overcloud.</a></p></li>
</ul>
</li>
<li><p>Ocata</p>
<ul>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/ocata/containerize-tripleo-overcloud.html">OpenStack services on the Overcloud are containerized using containers built by Kolla (except for Cinder, Manila, and Neutron).</a></p></li>
</ul>
</li>
<li><p>Pike</p>
<ul>
<li><p>config-download (Ansible content) was created as an alternative to Heat for deploying the OpenStack services on the Overcloud.</p></li>
</ul>
</li>
<li><p>Queens</p>
<ul>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/queens/fast-forward-upgrades.html">Introduced Fast Forward Upgrades (FFUs). The first supported FFU is from Newton straight to Queens.</a></p></li>
<li><p>All OpenStack services on the Overcloud have been containerized.</p></li>
<li><p>Experimental support for using containerized OpenStack services on the Undercloud.</p></li>
</ul>
</li>
<li><p>Rocky</p>
<ul>
<li><p>instack-undercloud is no longer used for installing the Undercloud. The Undercloud now reuses the same workflows used by the Overcloud deploy, update, and upgrade process.</p></li>
<li><p>Undercloud services are now containerized by default.</p></li>
<li><p><a class="reference external" href="https://blueprints.launchpad.net/tripleo/+spec/config-download-default">config-download is now the default deployment method.</a></p></li>
<li><p>config-download now supports using ceph-ansible for managing Ceph clusters.</p></li>
<li><p><a class="reference external" href="https://blueprints.launchpad.net/tripleo/+spec/all-in-one">Introduced Standalone deployments (an all-in-one Overcloud that does not require an Undercloud).</a></p></li>
<li><p>Deprecated the TripleO UI.</p></li>
</ul>
</li>
<li><p>Stein</p>
<ul>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/stein/podman.html">Container management can now use podman instead of docker.</a></p></li>
<li><p><a class="reference external" href="https://docs.openstack.org/tripleo-docs/latest/install/deprecated/basic_deployment_ui.html">Removed the TripleO UI.</a></p></li>
</ul>
</li>
<li><p>Train</p>
<ul>
<li><p>Fast Forward Upgrade from Queens to Train.</p></li>
<li><p><a class="reference external" href="https://blogs.rdoproject.org/2019/10/rdo-centos-stream/">The first upstream release to support CentOS 8.</a></p></li>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/train/undercloud-minion.html">Minion node support for scaling the Undercloud resources for Heat and Ironic.</a></p></li>
</ul>
</li>
<li><p>Ussuri</p>
<ul>
<li><p><a class="reference external" href="https://review.opendev.org/#/c/700738/">Replaced Paunch with Ansible for container management.</a></p></li>
<li><p><a class="reference external" href="https://blueprints.launchpad.net/tripleo/+spec/nova-less-deploy">Removed Undercloud dependencies on Glance, Neutron, and Nova by having a Nova-less deployment process.</a> <a class="reference external" href="https://github.com/openstack/metalsmith">MetalSmith</a> can now used to provision the Overcloud nodes separately from the Overcloud deployment. TripleO treats all deployments as pre-deployed servers.</p></li>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/ussuri/mistral-to-ansible.html">Removed Mistral and Zaqar from the Undercloud. The Overcloud deployment workflow now uses Ansible.</a></p></li>
<li><p><a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/ussuri/tripleo-operator-ansible.html">Provided standardized Ansible playbooks and roles for operators to manage their TripleO clouds.</a></p></li>
</ul>
</li>
<li><p>Victoria</p>
<ul>
<li><p>Kolla container images are no longer used. <a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/victoria/simple-container-generation.html">TripleO Container Image Build (TCIB)</a> is a new Ansible wrapper for creating smaller container images based on the RHEL Universal Base Image (UBI) 8 image.</p></li>
</ul>
</li>
</ul>
<p>[57][58]</p>
</div>
<div class="section" id="downstream">
<h3><a class="toc-backref" href="#id9">Downstream</a><a class="headerlink" href="#downstream" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>RHOSP 2</p>
<ul>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/2/html/Release_Notes/index.html">The first OpenStack product released by Red Hat.</a></p></li>
</ul>
</li>
<li><p>RHOSP 3</p>
<ul>
<li><p>The first RHOSP release to include the <a class="reference external" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/3/html/Deployment_Guide_Foreman_Technology_Preview/index.html">Foreman OpenStack Manager</a> to automate the deployment of servers and installation of OpenStack services.</p></li>
<li><p>This was the first RHOSP release to have official support.</p></li>
</ul>
</li>
<li><p>RHOSP 5</p>
<ul>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/5/html/Getting_Started_Guide/index.html">Introduced Packstack as an easy way to deploy a single-node proof-of-concept cloud using Puppet.</a>.</p></li>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/5/html/Technical_Notes/index.html">The first release to support RHEL 7</a>.</p></li>
<li><p><a class="reference external" href="https://www.redhat.com/en/about/press-releases/red-hat-acquire-enovance-leader-openstack-integration-services">Red Hat acquired eNovance, the company that created TripleO (previously named Spinal Stack), in June of 2014.</a></p></li>
</ul>
</li>
<li><p>RHOSP 6</p>
<ul>
<li><p><a class="reference external" href="https://access.redhat.com/articles/1320563">Introduced TripleO as another proof-of-concept deployment tool. It uses an all-in-one OpenStack cloud (the Undercloud) to deploy a production cloud (the Overcloud).</a></p></li>
</ul>
</li>
<li><p>RHOSP 7</p>
<ul>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_openstack_platform/7/html/director_installation_and_usage/index">TripleO, now known as Director downstream and temporarily renamed to the RDO Manager upstream, replaces the Foreman OpenStack Manager as the deployment tool.</a></p></li>
</ul>
</li>
<li><p>RHOSP 8</p>
<ul>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/8/html/upgrading_red_hat_openstack_platform/index">Automated minor updates and major upgrades.</a></p></li>
</ul>
</li>
<li><p>RHOSP 10</p>
<ul>
<li><p>The first long-life release to receive up to 5 years of support.</p></li>
</ul>
</li>
<li><p>RHOSP 13</p>
<ul>
<li><p>RHOSP’s second long-life release.</p></li>
<li><p>Introduced Fast Forward Upgrade path from RHOSP 10 to 13.</p></li>
</ul>
</li>
<li><p>RHOSP 14</p>
<ul>
<li><p>The TripleO UI has been deprecated.</p></li>
</ul>
</li>
<li><p>RHOSP 15</p>
<ul>
<li><p>The first release to support RHEL 8.</p></li>
<li><p><a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/15/html-single/release_notes/index#deprecated_functionality">Telemetry services (aodh, ceilometer, and gnocchi) are deprecated in favor of the Red Hat Service Assurance Framework.</a></p></li>
</ul>
</li>
<li><p>RHOSP 16</p>
<ul>
<li><p>RHOSP’s third long-life release.</p></li>
<li><p>Introduced Fast Forward Upgrade path from RHOSP 13 to 16.</p></li>
</ul>
</li>
</ul>
<p>[1]</p>
</div>
</div>
<div class="section" id="repositories">
<h2><a class="toc-backref" href="#id10">Repositories</a><a class="headerlink" href="#repositories" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3><a class="toc-backref" href="#id11">Upstream</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>The upstream TripleO project has three main repositories for each OpenStack release:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name and Aliases</p></th>
<th class="head"><p>Testing Level</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>General Availability (GA), Release, or Tested</p></td>
<td><p>High</p></td>
<td><p>Production</p></td>
</tr>
<tr class="row-odd"><td><p>Testing, Test, or Buildlogs</p></td>
<td><p>Medium</p></td>
<td><p>Pre-production</p></td>
</tr>
<tr class="row-even"><td><p>Trunk, Current, Consistent, or Untested</p></td>
<td><p>Low</p></td>
<td><p>Development</p></td>
</tr>
</tbody>
</table>
<p>If installing on RHEL, it is required to enable additional repositories:</p>
<blockquote>
<div><ul>
<li><p>RHEL 7 [40]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --disable<span class="o">=</span>*
$ sudo subscription-manager repos --enable rhel-7-server-rpms --enable rhel-7-server-rh-common-rpms --enable rhel-7-server-extras-rpms
</pre></div>
</div>
</li>
<li><p>RHEL 8 [74]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --disable<span class="o">=</span>*
$ sudo subscription-manager repos --enable<span class="o">=</span>rhel-8-for-x86_64-baseos-eus-rpms --enable<span class="o">=</span>rhel-8-for-x86_64-appstream-eus-rpms --enable<span class="o">=</span>rhel-8-for-x86_64-highavailability-eus-rpms --enable<span class="o">=</span>ansible-2-for-rhel-8-x86_64-rpms --enable<span class="o">=</span>fast-datapath-for-rhel-8-x86_64-rpms
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>If installing on CentOS 8, it is required to enable both the high availability (for Pacemaker packages) and PowerTools (for Ruby packages) repositories.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo dnf config-manager --set-enabled HighAvailability
$ sudo dnf config-manager --set-enabled PowerTools
</pre></div>
</div>
<ul>
<li><p><strong>GA</strong>:</p>
<ul>
<li><p>CentOS:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install centos-release-openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>
</pre></div>
</div>
</li>
<li><p>RHEL:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install https://repos.fedorapeople.org/repos/openstack/openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/rdo-release-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-<span class="si">${</span><span class="nv">RDO_RPM_RELEASE</span><span class="si">}</span>.noarch.rpm
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><strong>Testing</strong></p>
<ul>
<li><p>CentOS:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install centos-release-openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>
$ sudo yum-config-manager --enable centos-openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-test
</pre></div>
</div>
</li>
<li><p>RHEL:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install https://repos.fedorapeople.org/repos/openstack/openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/rdo-release-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-<span class="si">${</span><span class="nv">RDO_RPM_RELEASE</span><span class="si">}</span>.noarch.rpm
$ sudo yum-config-manager --enable openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-testing
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><strong>Trunk</strong></p>
<ul>
<li><p>Trunk builds are divided into different stages [54][65]:</p>
<ul class="simple">
<li><p>current = The latest individually successfully built packages from every RDO and OpenStack project.</p></li>
<li><p>consistent = The <code class="docutils literal notranslate"><span class="pre">current</span></code> build passed the tripleo-ci promotion jobs.</p></li>
<li><p>current-tripleo = The <code class="docutils literal notranslate"><span class="pre">consistent</span></code> build passed phase 1 CI promotion jobs.</p></li>
<li><p>current-tripleo-rdo = The <code class="docutils literal notranslate"><span class="pre">current-tripleo</span></code> build passed <a class="reference external" href="https://ci.centos.org/view/rdo/view/promotion-pipeline/job/rdo_trunk-promote-train-current-tripleo/">phase 2 CI promotion jobs</a>. This is also known as <code class="docutils literal notranslate"><span class="pre">current-passed-ci</span></code> because it has passed all of the available CI jobs.</p></li>
</ul>
</li>
<li><p>RDO repository (current-tripleo-rdo):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install https://repos.fedorapeople.org/repos/openstack/openstack-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/rdo-release-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-<span class="si">${</span><span class="nv">RDO_RPM_RELEASE</span><span class="si">}</span>.noarch.rpm
$ sudo yum-config-manager --enable rdo-trunk-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>-tested
</pre></div>
</div>
</li>
<li><p>Or <code class="docutils literal notranslate"><span class="pre">tripleo-repos</span></code> [22]:</p>
<ul>
<li><p>CentOS 7 (&lt;= Train):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install <span class="s2">&quot;https://trunk.rdoproject.org/centos7/current-tripleo-rdo/</span><span class="k">$(</span>curl -k https://trunk.rdoproject.org/centos7/current-tripleo-rdo/ <span class="p">|</span> grep python2-tripleo-repos- <span class="p">|</span> cut -d<span class="se">\&quot;</span> -f8<span class="k">)</span><span class="s2">&quot;</span>
</pre></div>
</div>
</li>
<li><p>CentOS 8 (&gt;= Train):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install <span class="s2">&quot;https://trunk.rdoproject.org/centos8-</span><span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span><span class="s2">/component/tripleo/current-tripleo-rdo/</span><span class="k">$(</span>curl -k  https://trunk.rdoproject.org/centos8-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/component/tripleo/current-tripleo-rdo/ <span class="p">|</span> grep <span class="s2">&quot;python3-tripleo-repos&quot;</span> <span class="p">|</span> cut -d<span class="se">\&quot;</span> -f8<span class="k">)</span><span class="s2">&quot;</span>
</pre></div>
</div>
</li>
<li><p>Setup the TripleO repositories:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo tripleo-repos -b <span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span> current-tripleo-rdo
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Or manually:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">EL_VER</span><span class="o">=</span><span class="s2">&quot;8&quot;</span>
$ sudo curl -L -o /etc/yum.repos.d/delorean-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>.repo https://trunk.rdoproject.org/centos<span class="si">${</span><span class="nv">EL_VER</span><span class="si">}</span>-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/current-tripleo-rdo/delorean.repo
$ sudo curl -L -o /etc/yum.repos.d/delorean-deps-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>.repo https://trunk.rdoproject.org/centos<span class="si">${</span><span class="nv">EL_VER</span><span class="si">}</span>-<span class="si">${</span><span class="nv">OPENSTACK_RELEASE</span><span class="si">}</span>/delorean-deps.repo
</pre></div>
</div>
</li>
<li><p>Create a container image prepare file that uses the <code class="docutils literal notranslate"><span class="pre">current-tripleo</span></code> (default), <code class="docutils literal notranslate"><span class="pre">current-tripleo-rdo</span></code>, or a Delorean hash tag. Container images are not built for <code class="docutils literal notranslate"><span class="pre">current</span></code>. Configure the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code> to use this file via the <code class="docutils literal notranslate"><span class="pre">container_images_file</span></code> parameter. Configure the Overcloud to use it by adding it as another Heat environment template: <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span> <span class="pre">--templates</span> <span class="pre">-e</span> <span class="pre">~/containers-prepare-parameters.yaml</span></code>. [76]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack tripleo container image prepare default --output-env-file ~/containers-prepare-parameters.yaml
$ <span class="si">${</span><span class="nv">EDITOR</span><span class="si">}</span> ~/containers-prepare-parameters.yaml
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">ContainerImagePrepare</span><span class="p">:</span>
     <span class="p p-Indicator">-</span> <span class="nt">set</span><span class="p">:</span>
         <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">docker.io/tripleo&lt;OPENSTACK_RELEASE&gt;</span>
         <span class="nt">tag</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">current-tripleo-rdo</span>
         <span class="c1"># Alternatively, to prevent unforeseen updates, the tag can be a Delorean hash.</span>
         <span class="c1"># For example, for</span>
         <span class="c1"># https://trunk.rdoproject.org/centos8-victoria/current-tripleo-rdo/7f/97/7f974e10d7184d5fc45445a3073333bd/</span>
         <span class="c1"># this tag can be used:</span>
         <span class="c1">#namespace: docker.io/tripleovictoria</span>
         <span class="c1">#tag: 7f974e10d7184d5fc45445a3073333bd</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<p>[53]</p>
</div>
<div class="section" id="id2">
<h3><a class="toc-backref" href="#id12">Downstream</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>It is recommended to disable any existing repositories to avoid package conflicts.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --disable<span class="o">=</span>*
</pre></div>
</div>
<ul>
<li><p>RHOSP 10 [26]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --enable<span class="o">=</span>rhel-7-server-rpms --enable<span class="o">=</span>rhel-7-server-extras-rpms --enable<span class="o">=</span>rhel-7-server-rh-common-rpms --enable<span class="o">=</span>rhel-ha-for-rhel-7-server-rpms --enable<span class="o">=</span>rhel-7-server-nfv-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-2-tools-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-2-mon-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-2-osd-rpms --enable<span class="o">=</span>rhel-7-server-openstack-10-rpms
</pre></div>
</div>
</li>
<li><p>RHOSP 13 [27]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --enable<span class="o">=</span>rhel-7-server-rpms --enable<span class="o">=</span>rhel-7-server-extras-rpms --enable<span class="o">=</span>rhel-7-server-rh-common-rpms --enable<span class="o">=</span>rhel-ha-for-rhel-7-server-rpms --enable<span class="o">=</span>rhel-7-server-nfv-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-3-tools-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-3-mon-rpms --enable<span class="o">=</span>rhel-7-server-rhceph-3-osd-rpms --enable<span class="o">=</span>rhel-7-server-openstack-13-rpms
</pre></div>
</div>
</li>
<li><p>RHOSP 16 [55]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --enable<span class="o">=</span>rhel-8-for-x86_64-baseos-rpms --enable<span class="o">=</span>rhel-8-for-x86_64-appstream-rpms --enable<span class="o">=</span>rhel-8-for-x86_64-highavailability-rpms --enable<span class="o">=</span>ansible-2.8-for-rhel-8-x86_64-rpms --enable<span class="o">=</span>openstack-16-for-rhel-8-x86_64-rpms --enable<span class="o">=</span>fast-datapath-for-rhel-8-x86_64-rpms
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="deployment-quick">
<h2><a class="toc-backref" href="#id13">Deployment (Quick)</a><a class="headerlink" href="#deployment-quick" title="Permalink to this headline">¶</a></h2>
<div class="section" id="packstack">
<h3><a class="toc-backref" href="#id14">Packstack</a><a class="headerlink" href="#packstack" title="Permalink to this headline">¶</a></h3>
<p>Supported operating system: RHEL/CentOS 7, Fedora</p>
<p>Packstack is part of Red Hat’s RDO project. It’s purpose is for
providing small and simple demonstrations of OpenStack. This tool does
not handle any upgrades of the OpenStack services.</p>
<p>Hardware requirements [9]:</p>
<ul class="simple">
<li><p>16GB RAM</p></li>
</ul>
<div class="section" id="install">
<h4><a class="toc-backref" href="#id15">Install</a><a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h4>
<p>Disable NetworkManager. It is not compatible with Packstack.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo systemctl disable NetworkManager
</pre></div>
</div>
<p>Install the Packstack utility.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum -y install openstack-packstack
</pre></div>
</div>
<p>There are two network scenarios that Packstack can deploy. The default
is to have an isolated network (1). Floating IPs will not be able to
access the network on the public interface. For lab environments,
Packstack can also configure Neutron to expose the network instead to
allow instances with floating IPs to access other IP addresses on the
network (2).</p>
<p><code class="docutils literal notranslate"><span class="pre">1.</span></code> Isolated Network Install</p>
<p>Generate a configuration file referred to as the “answer” file. This can
optionally be customized. Then install OpenStack using the answer file.
By default, the network will be entirely isolated. [4]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo packstack --gen-answer-file &lt;FILE&gt;
$ sudo packstack --answer-file &lt;FILE&gt;
</pre></div>
</div>
<p>Packstack logs are stored in /var/tmp/packstack/. The administrator and
demo user credentials will be saved to the user’s home directory.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">source</span> ~/keystonerc_admin
$ <span class="nb">source</span> ~/keystonerc_demo
</pre></div>
</div>
<p>Although the network will not be exposed by default, it can still be
configured later. The primary interface to the lab’s network, typically
<code class="docutils literal notranslate"><span class="pre">eth0</span></code>, will need to be configured as a Open vSwitch bridge to allow
this. Be sure to replace the “IPADDR”, “PREFIX”, and “GATEWAY” with the
server’s correct settings. Neutron will also need to be configured to
allow “flat” networks.</p>
<p>File: /etc/sysconfig/network-scripts/ifcfg-eth0</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DEVICE</span><span class="o">=</span><span class="n">eth0</span>
<span class="n">ONBOOT</span><span class="o">=</span><span class="n">yes</span>
<span class="n">DEVICETYPE</span><span class="o">=</span><span class="n">ovs</span>
<span class="n">TYPE</span><span class="o">=</span><span class="n">OVSPort</span>
<span class="n">OVS_BRIDGE</span><span class="o">=</span><span class="n">br</span><span class="o">-</span><span class="n">ex</span>
<span class="n">BOOTPROTO</span><span class="o">=</span><span class="n">none</span>
<span class="n">NM_CONTROLLED</span><span class="o">=</span><span class="n">no</span>
</pre></div>
</div>
<p>File: /etc/sysconfig/network-scripts/ifcfg-br-ex</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DEVICE</span><span class="o">=</span><span class="n">br</span><span class="o">-</span><span class="n">ex</span>
<span class="n">ONBOOT</span><span class="o">=</span><span class="n">yes</span>
<span class="n">DEVICETYPE</span><span class="o">=</span><span class="n">ovs</span>
<span class="n">TYPE</span><span class="o">=</span><span class="n">OVSBridge</span>
<span class="n">DEFROUTE</span><span class="o">=</span><span class="n">yes</span>
<span class="n">IPADDR</span><span class="o">=</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">1.200</span>
<span class="n">PREFIX</span><span class="o">=</span><span class="mi">24</span>
<span class="n">GATEWAY</span><span class="o">=</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">1.1</span>
<span class="n">PEERDNS</span><span class="o">=</span><span class="n">no</span>
<span class="n">BOOTPROTO</span><span class="o">=</span><span class="n">none</span>
<span class="n">NM_CONTROLLED</span><span class="o">=</span><span class="n">no</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">2.</span></code> Exposed Network Install</p>
<p>It is also possible to deploy OpenStack where Neutron can have access to
the public network. Run the Packstack installation with the command
below and replace “eth0” with the public interface name.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo packstack --allinone --provision-demo<span class="o">=</span>n --os-neutron-ovs-bridge-mappings<span class="o">=</span>extnet:br-ex --os-neutron-ovs-bridge-interfaces<span class="o">=</span>br-ex:eth0 --os-neutron-ml2-type-drivers<span class="o">=</span>vxlan,flat
</pre></div>
</div>
<p>Alternatively, use these configuration options in the answer file.</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="na">CONFIG_NEUTRON_ML2_TYPE_DRIVERS</span><span class="o">=</span><span class="s">vxlan,flat</span>
<span class="na">CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS</span><span class="o">=</span><span class="s">extnet:br-ex</span>
<span class="na">CONFIG_NEUTRON_OVS_BRIDGE_IFACES</span><span class="o">=</span><span class="s">br-ex:eth0</span>
<span class="na">CONFIG_PROVISION_DEMO</span><span class="o">=</span><span class="s">n</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo packstack --answer-file &lt;ANSWER_FILE&gt;
</pre></div>
</div>
<p>After the installation is finished, create the necessary network in Neutron as the admin user. In this example, the network will automatically allocate IP addresses between 192.168.1.201 and 192.168.1.254. The IP 192.168.1.1 is both the physical router and default gateway.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ . keystonerc_admin
$ openstack network create --share --provider-physical-network physical_network --provider-network-type flat --router external external_network
$ openstack subnet create --subnet-range <span class="m">192</span>.168.1.0/24 --gateway <span class="m">192</span>.168.1.1 --network external_network --allocation-pool <span class="nv">start</span><span class="o">=</span><span class="m">192</span>.168.1.201,end<span class="o">=</span><span class="m">192</span>.168.1.254 --no-dhcp public_subnet
</pre></div>
</div>
<p>The “external_network” can now be associated with a router in user accounts.</p>
<p>[5][90]</p>
</div>
<div class="section" id="answer-file">
<h4><a class="toc-backref" href="#id16">Answer File</a><a class="headerlink" href="#answer-file" title="Permalink to this headline">¶</a></h4>
<p>The “answer” configuration file defines how OpenStack should be setup
and installed. Using a answer file can provide a more customizable
deployment.</p>
<p>Common options:</p>
<ul>
<li><p>CONFIG_DEFAULT_PASSWORD = Any blank passwords in the answer file
will be set to this value.</p></li>
<li><p>CONFIG_KEYSTONE_ADMIN_TOKEN = The administrator authentication
token.</p></li>
<li><p>CONFIG_KEYSTONE_ADMIN_PW = The administrator password.</p></li>
<li><p>CONFIG_MARIADB_PW = The MariaDB root user’s password.</p></li>
<li><p>CONFIG_HORIZON_SSL = Configure an SSL for the Horizon dashboard.
This requires that SSLs be generated manually and then defined in the
configuration file [6]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ for cert in selfcert ssl_dashboard ssl_vnc; do sudo openssl req -x509 -sha256 -newkey rsa:2048 -keyout /etc/pki/tls/private/${cert}.key -out /etc/pki/tls/certs/${cert}.crt -days 365 -nodes; done
</pre></div>
</div>
<ul class="simple">
<li><p>CONFIG_SSL_CACERT_FILE=/etc/pki/tls/certs/selfcert.crt</p></li>
<li><p>CONFIG_SSL_CACERT_KEY_FILE=/etc/pki/tls/private/selfkey.key</p></li>
<li><p>CONFIG_VNC_SSL_CERT=/etc/pki/tls/certs/ssl_vnc.crt</p></li>
<li><p>CONFIG_VNC_SSL_KEY=/etc/pki/tls/private/ssl_vnc.key</p></li>
<li><p>CONFIG_HORIZON_SSL_CERT=/etc/pki/tls/certs/ssl_dashboard.crt</p></li>
<li><p>CONFIG_HORIZON_SSL_KEY=/etc/pki/tls/private/ssl_dashboard.key</p></li>
<li><p>CONFIG_HORIZON_SSL_CACERT=/etc/pki/tls/certs/selfcert.crt</p></li>
</ul>
</li>
<li><p>CONFIG_&lt;SERVICE&gt;_INSTALL = Install a specific OpenStack service.</p></li>
<li><p>CONFIG_&lt;NODE&gt;_HOST = The host to setup the relevant services on.</p></li>
<li><p>CONFIG_&lt;NODE&gt;_HOSTS = A list of hosts to setup the relevant
services on. This currently only exists for “COMPUTE” and “NETWORK.”
New hosts can be added and Packstack re-run to have them added to the
OpenStack cluster.</p></li>
<li><p>CONFIG_PROVISION_DEMO = Setup a demo project and user account with
an image and network configured.</p></li>
</ul>
</div>
<div class="section" id="uninstall">
<h4><a class="toc-backref" href="#id17">Uninstall</a><a class="headerlink" href="#uninstall" title="Permalink to this headline">¶</a></h4>
<p>For uninstalling everything that is installed by Packstack, run <a class="reference external" href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/6/html/Deploying_OpenStack_Proof_of_Concept_Environments/chap-Removing_Packstack_Deployments.html">this Bash script</a> on all of the OpenStack nodes. Use at your own risk.</p>
</div>
</div>
<div class="section" id="tripleo-quickstart">
<h3><a class="toc-backref" href="#id18">TripleO Quickstart</a><a class="headerlink" href="#tripleo-quickstart" title="Permalink to this headline">¶</a></h3>
<p>The TripleO Quickstart project was created to use Ansible to automate deploying a TripleO Undercloud and Overcloud. [7] The project recommends a minimum of 32GB RAM and 120GB of disk space when deploying with the default settings. [9] This deployment has to use a baremetal hypervisor. Deploying TripleO within a virtual machine that uses nested virtualization is not supported. [10]</p>
<ul>
<li><p>Download the tripleo-quickstart script or clone the entire repository
from OpenDev or GitHub.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -O https://opendev.org/openstack/tripleo-quickstart/raw/branch/master/quickstart.sh
</pre></div>
</div>
<p>OR</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ git clone https://opendev.org/openstack/tripleo-quickstart.git
$ <span class="nb">cd</span> tripleo-quickstart
</pre></div>
</div>
</li>
<li><p>Install dependencies for the quickstart script.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo bash quickstart.sh --install-deps
</pre></div>
</div>
</li>
</ul>
<p>TripleO can now be installed automatically with the default setup of 3
virtual machines. This will be created to meet the minimum TripleO cloud
requirements: (1) an Undercloud to deploy a (2) controller and (3)
compute node. [8] . Otherwise, a different node configuration from
“config/nodes/” can be specified or created.</p>
<p>Common node variables:</p>
<ul class="simple">
<li><p>{block|ceph|compute|control|default|objectstorage|undercloud}_{memory|vcpu}
= Define the amount of processor cores or RAM (in megabytes) to
allocate to the respective virtual machine type. Use “default” to
apply to all nodes that are not explicitly defined.</p></li>
</ul>
<p>Further customizations should be configured now before deploying the
TripleO environment. Refer to the <a class="reference external" href="https://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/undercloud-deploy/README.md">Undercloud Deploy role’s
documentation</a>
on all of the Ansible variables for the Undercloud. Add any override
variables to a YAML file and then add the arguments
<code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">&#64;&lt;VARIABLE_FILE&gt;.yaml</span></code> to the “quickstart.sh” commands.</p>
<p><code class="docutils literal notranslate"><span class="pre">1.</span></code> Automatic</p>
<ul>
<li><p>Run the quickstart script to install TripleO. Use “127.0.0.2” for the
localhost IP address if TripleO will be installed on the same system
that the quickstart command is running on.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --tags all &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
</ul>
<p>[7]</p>
<p><code class="docutils literal notranslate"><span class="pre">2.</span></code> Manual</p>
<ul class="simple">
<li><p>Common quickstart.sh options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--clean</span></code> = Remove previously created files from the working
directory on the start of TripleO Quickstart.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--extra-vars</span> <span class="pre">supported_distro_check=false</span></code> = Run on an unsupported hypervisor such as Fedora.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-clone</span></code> = Use the current working directory for
TripleO Quickstart. This should only be if the entire repository
has been cloned.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--nodes</span> <span class="pre">config/nodes/&lt;CONFIGURATION&gt;.yml</span></code> = Specify the
configuration that determines how many Overcloud nodes should be
deployed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--playbook</span></code> = Specify a Playbook to run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--release</span></code> = The OpenStack release to use. All of the available
releases can be found in the OpenDev or GitHub project in the
“config/release/” directory. Use “trunk/<code class="docutils literal notranslate"><span class="pre">&lt;RELEASE_NAME&gt;</span></code>” for
the development version and “stable/<code class="docutils literal notranslate"><span class="pre">&lt;RELEASE_NAME&gt;</span></code>” for the
stable version.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--retain-inventory</span></code> = Use the existing inventory. This is
useful for managing an existing TripleO Quickstart infrastructure.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--teardown</span> <span class="pre">{all|nodes|none|virthost}</span></code> = Delete everything
related to TripleO (all), only the virtual machines (nodes),
nothing (none), or the virtual machines and settings on the
hypervisor (virthost).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--tags</span> <span class="pre">all</span></code> = Deploy a complete all-in-one TripleO installation
automatically. If a Playbook is specified via <code class="docutils literal notranslate"><span class="pre">-p</span></code>, then
everything in that Playbook will run.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span></code> = Show verbose output from the Ansible playbooks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--config=~/.quickstart/config/general_config/containers_minimal.yml</span></code> = Deploy the Overcloud from Kolla docker containers. [20]</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul>
<li><p>Setup the Undercloud virtual machine.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --clean --teardown all --tags all --playbook quickstart.yml &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
<li><p>Install the Undercloud services.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --teardown none --no-clone --tags all --retain-inventory --playbook quickstart-extras-undercloud.yml &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
<li><p>Setup the Overcloud virtual machines.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --teardown none --no-clone --tags all --nodes config/nodes/1ctlr_1comp.yml --retain-inventory --playbook quickstart-extras-overcloud-prep.yml &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
<li><p>Install the Overcloud services.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --teardown none --no-clone --tags all --nodes config/nodes/1ctlr_1comp.yml --retain-inventory --playbook quickstart-extras-overcloud.yml &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
<li><p>Validate the installation.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ bash quickstart.sh --release trunk/queens --teardown none --no-clone --tags all --nodes config/nodes/1ctlr_1comp.yml --retain-inventory  --playbook quickstart-extras-validate.yml &lt;REMOTE_HYPERVISOR_IP&gt;
</pre></div>
</div>
</li>
</ul>
<p>[11]</p>
</div>
<div class="section" id="standalone">
<h3><a class="toc-backref" href="#id19">Standalone</a><a class="headerlink" href="#standalone" title="Permalink to this headline">¶</a></h3>
<p>Requirements:</p>
<ul class="simple">
<li><p>4 CPU cores</p></li>
<li><p>8GB RAM</p></li>
<li><p>50GB storage</p></li>
</ul>
<p>OpenStack services:</p>
<ul class="simple">
<li><p>Cinder</p></li>
<li><p>Glance</p></li>
<li><p>Keystone</p></li>
<li><p>Neutron</p></li>
<li><p>Nova</p></li>
<li><p>Placement</p></li>
<li><p>Swift</p></li>
</ul>
<p>Starting with Rocky, an all-in-one Overcloud can be deployed without the need of an Undercloud. This is known as a Standalone deployment. It can be used for proof-of-concept TripleO deployments or for developers as an alternative to <a class="reference external" href="https://docs.openstack.org/devstack/latest/">devstack</a>. It is possible to deploy more than one Overcloud node using this method and to scale-up to more nodes at a later date. Although possible in upstream TripleO, in RHOSP this is unsupported by Red Hat.</p>
<p>The process is almost exactly the same as an Undercloud deployment. It deploys a fully functional Overcloud onto the local server. Unlike a typical Overcloud deployment (before the Victoria release where Mistral was removed), Mistral is not used. Instructions on how to setup a Standalone cloud are documented <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/standalone.html">here</a>. After the installation, the config-download Ansible playbooks will be available in the home directory as <code class="docutils literal notranslate"><span class="pre">undercloud-ansible-&lt;UUID&gt;</span></code>.</p>
<p>By default, some services, such as Heat, are disabled. Use this template to re-enable it.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::HeatApi</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployment/heat/heat-api-container-puppet.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::HeatApiCfn</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployment/heat/heat-api-cfn-container-puppet.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::HeatApiCloudwatch</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployment/heat/heat-api-cloudwatch-disabled-puppet.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::HeatEngine</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployment/heat/heat-engine-container-puppet.yaml</span>
</pre></div>
</div>
<p><strong>Updates</strong></p>
<p>These steps apply to both Undercloud and Standalone cloud deployments.</p>
<ul>
<li><p>Update:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack <span class="o">{</span>undercloud install<span class="p">|</span>tripleo deploy<span class="o">}</span> --force-stack-update
</pre></div>
</div>
</li>
<li><p>Upgrade:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack <span class="o">{</span>undercloud<span class="p">|</span>tripleo<span class="o">}</span> upgrade
</pre></div>
</div>
</li>
<li><p>Reinstall:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack <span class="o">{</span>undercloud install<span class="p">|</span>tripleo deploy<span class="o">}</span>  --force-stack-create
</pre></div>
</div>
</li>
</ul>
<p>[48]</p>
</div>
<div class="section" id="infrared-2">
<h3><a class="toc-backref" href="#id20">InfraRed 2</a><a class="headerlink" href="#infrared-2" title="Permalink to this headline">¶</a></h3>
<p>InfraRed uses Ansible playbooks to automate deploying downstream RHOSP packages and upstream RDO packages.</p>
<p>Install InfraRed into a Python 2 virtual environment.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ virtualenv ~/venv_infrared
$ <span class="nb">source</span> ~/venv_infrared/bin/activate
$ git clone https://github.com/redhat-openstack/infrared.git
$ <span class="nb">cd</span> infrared
$ pip2 install --user .
</pre></div>
</div>
<p>As of 2019, these are the officially supported plugins in InfraRed.</p>
<ul class="simple">
<li><p>provision</p>
<ul>
<li><p>beaker</p></li>
<li><p>docker</p></li>
<li><p>foreman</p></li>
<li><p>openstack</p></li>
<li><p>virsh</p></li>
</ul>
</li>
<li><p>install</p>
<ul>
<li><p>build-packages</p></li>
<li><p>cloud-config</p></li>
<li><p>containers-sanity</p></li>
<li><p>install-ceph</p></li>
<li><p>oooq</p></li>
<li><p>packstack</p></li>
<li><p>patch-components</p></li>
<li><p>tripleo-overcloud</p></li>
<li><p>tripleo-standalone</p></li>
<li><p>tripleo-undercloud</p></li>
</ul>
</li>
<li><p>test</p>
<ul>
<li><p>browbeat</p></li>
<li><p>bzaf</p></li>
<li><p>gabbi</p></li>
<li><p>jordan</p></li>
<li><p>openstack-coverage</p></li>
<li><p>ospdui</p></li>
<li><p>pytest-runner</p></li>
<li><p>rally</p></li>
<li><p>robot</p></li>
<li><p>tempest</p></li>
<li><p>tripleo-config-changes</p></li>
<li><p>tripleo-post-tests</p></li>
</ul>
</li>
<li><p>other</p>
<ul>
<li><p>collect-logs</p></li>
<li><p>dellemc-idrac</p></li>
<li><p>list-builds</p></li>
</ul>
</li>
</ul>
<p>Use the <code class="docutils literal notranslate"><span class="pre">infrared</span> <span class="pre">plugin</span> <span class="pre">search</span></code> command to view the GitHub URL of each plugin. Then use <code class="docutils literal notranslate"><span class="pre">infrared</span> <span class="pre">plugin</span> <span class="pre">add</span> <span class="pre">&lt;GITHUB_URL&gt;</span></code> to install the plugin.</p>
<p>Alternatively, install plugins from the working directory of the <code class="docutils literal notranslate"><span class="pre">infrared</span></code> repository.</p>
<p>Install a provision plugin, such as virsh, along with the required plugins for deploying and managing a TripleO cloud.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ infrared plugin add plugins/virsh
$ infrared plugin add plugins/tripleo-undercloud
$ infrared plugin add plugins/tripleo-overcloud
$ infrared plugin add plugins/cloud-config
</pre></div>
</div>
<ul>
<li><p>Optionally create an answers file manually or by using the CLI and then import it. Otherwise, use the CLI arguments.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ infrared virsh --from-file<span class="o">=</span>virsh_prov.ini
</pre></div>
</div>
</li>
<li><p>[virsh]</p>
<ul class="simple">
<li><p><strong>host-address</strong> = Required argument. Edit with any value, OR override with CLI: –host-address=&lt;option&gt;</p></li>
<li><p>host-memory-overcommit = Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>host-key</strong> = Required argument. Edit with any value, OR override with CLI: –host-key=&lt;option&gt;</p></li>
<li><p>host-user = Default: <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p></li>
<li><p><strong>topology-nodes</strong> = The number of each node to deploy.</p>
<ul>
<li><p>Minimal: <code class="docutils literal notranslate"><span class="pre">&quot;ovb_undercloud:1,controller:1,compute:1&quot;</span></code>.</p></li>
<li><p>Minimal with OpenStack Virtual Baremetal (OVB) support for provisioning: <code class="docutils literal notranslate"><span class="pre">&quot;ovb_undercloud:1,ovb_controller:1,ovb_compute:1&quot;</span></code>.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Deploy the virtual machines that will be used by the lab.</p>
<ul>
<li><p>Virsh provisioner:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ infrared virsh --host-address <span class="m">127</span>.0.0.1 --host-key ~/.ssh/id_rsa --host-memory-overcommit yes --topology-nodes <span class="s2">&quot;ovb_undercloud:1,controller:1,compute:1&quot;</span>
</pre></div>
</div>
</li>
<li><p>OpenStack provisioner:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ infrared openstack --cloud <span class="si">${</span><span class="nv">OS_CLOUD</span><span class="si">}</span> --prefix &lt;OPTIONAL_RESOURCE_PREFIX&gt; --key-file ~/.ssh/id_rsa --topology-network 3_nets_ovb --topology-nodes <span class="s2">&quot;ovb_undercloud:1,ovb_controller:1,ovb_compute:1&quot;</span> --anti-spoofing False --dns &lt;DNS1&gt;,&lt;DNS2&gt; --provider-network &lt;EXTERNAL_PROVIDER_NETWORK&gt; --image &lt;RHEL_OR_CENTOS&gt; --username &lt;SSH_USER&gt;
</pre></div>
</div>
</li>
<li><p>An Ansible inventory of the hosts will be generated here: <code class="docutils literal notranslate"><span class="pre">~/.infrared/.workspaces/active/hosts</span></code>.</p></li>
</ul>
</li>
<li><p>Deploy the Undercloud.</p>
<ul>
<li><p>RHOSP:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">RHOSP_VERSION</span><span class="o">=</span><span class="m">16</span>
$ infrared tripleo-undercloud --version <span class="si">${</span><span class="nv">RHOSP_VERSION</span><span class="si">}</span> --build <span class="si">${</span><span class="nv">PUDDLE_VERSION</span><span class="si">}</span> --images-task rpm --ntp-server clock.redhat.com,clock2.redhat.com
</pre></div>
</div>
</li>
<li><p>RDO:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">RDO_VERSION</span><span class="o">=</span>train
$ infrared tripleo-undercloud --version <span class="si">${</span><span class="nv">RDO_VERSION</span><span class="si">}</span> --images-task<span class="o">=</span>import --images-url<span class="o">=</span>https://images.rdoproject.org/<span class="si">${</span><span class="nv">RDO_VERSION</span><span class="si">}</span>/rdo_trunk/current-tripleo/stable/
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Deploy the Overcloud.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ infrared tripleo-overcloud --deployment-files virt --version <span class="si">${</span><span class="nv">RDO_VERSION</span><span class="si">}</span> --introspect yes --tagging yes --deploy yes
</pre></div>
</div>
</li>
<li><p>After the Overcloud is deployed, optionally configure resources on it.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ infrared cloud-config --deployment-files virt --tasks create_external_network,forward_overcloud_dashboard,network_time,tempest_deployer_input
</pre></div>
</div>
</li>
</ul>
<p>[35]</p>
</div>
</div>
<div class="section" id="deployment-full">
<h2><a class="toc-backref" href="#id21">Deployment (Full)</a><a class="headerlink" href="#deployment-full" title="Permalink to this headline">¶</a></h2>
<p>Minimum recommended requirements [8]:</p>
<ul class="simple">
<li><p>Undercloud node:</p>
<ul>
<li><p>4 CPU cores</p></li>
<li><p>8GB RAM (16GB recommended)</p></li>
<li><p>60GB storage</p></li>
<li><p>2 network interface cards (NICs) [21]</p></li>
<li><p>A fully qualified domain name (FQDN)</p></li>
</ul>
</li>
<li><p>Overcloud nodes:</p>
<ul>
<li><p>4 CPU cores</p></li>
<li><p>8GB RAM</p></li>
<li><p>80GB storage</p></li>
</ul>
</li>
</ul>
<p>Here is an overview of the deployment process using TripleO:</p>
<ul class="simple">
<li><p>Install the all-in-one Undercloud. This cloud will be used by the OpenStack operator to control and manage the Overcloud.</p></li>
<li><p>Import the Overcloud nodes into Ironic.</p></li>
<li><p>Configure those nodes to load both an initramfs and full kernel via a PXE boot.</p></li>
<li><p>Optionally set the nodes to be “manageable” and introspect the Overcloud nodes. This will report back detailed information about each node.</p></li>
<li><p>Set the Overcloud nodes to be “available” for provisioning.</p></li>
<li><p>Optionally configure settings for the Overcloud deployment (highly recommended).</p></li>
<li><p>Deploy the Overcloud. This cloud will be the production cloud that developers can use.</p></li>
</ul>
<p>RHOSP enables high-availability (HA) for the control plane by default and requires having exactly 3 Controller nodes as part of the Overcloud. [45] TripleO can have HA enabled by setting the <code class="docutils literal notranslate"><span class="pre">ControllerCount</span></code> to <code class="docutils literal notranslate"><span class="pre">3</span></code> and including this template: <code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">/usr/share/openstack-tripleo-heat-templates/environments/docker-ha.yaml</span></code>. [46]</p>
<div class="section" id="undercloud">
<h3><a class="toc-backref" href="#id22">Undercloud</a><a class="headerlink" href="#undercloud" title="Permalink to this headline">¶</a></h3>
<p>The Undercloud can be installed onto a bare metal server or a virtual machine. Follow the “hypervisor” section to assist with automatically creating an Undercloud virtual machine. The Undercloud requires at least 2 NICs (typically <code class="docutils literal notranslate"><span class="pre">eth0</span></code> and <code class="docutils literal notranslate"><span class="pre">eth1</span></code>). The first is used for external connectivity. The second is dedicated to provisioning the Overcloud nodes with Ironic. On those nodes, the related interface that can reach the Undercloud’s <code class="docutils literal notranslate"><span class="pre">eth1</span></code> should be configured for PXE booting in the BIOS. [21]</p>
<p>Considerations before starting the Undercloud deployment:</p>
<ul>
<li><p>The Undercloud server requires two network interfaces. One with public Internet/management access and the second dedicated to provisioning.</p></li>
<li><p>Configure the hostname.</p></li>
<li><p>Set <cite>push_destination: True</cite> in a custom container-image-prepare.yaml file.</p></li>
<li><dl class="simple">
<dt>undercloud.conf</dt><dd><ul class="simple">
<li><p>The NTP and DNS resolvers need to be accurate and accessible.</p></li>
<li><p>If deploying or managing more than 250 hosts, it is required to change the ctlplane-subnet to a use a subnet mask with more available IP addresses.</p></li>
<li><p>Use the custom container-image-prepare.yaml file.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><strong>Undercloud (Automatic)</strong></p>
<ul>
<li><p>RDO provides pre-made Undercloud images.</p>
<blockquote>
<div><ul>
<li><p>&lt;= Queens:</p>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -O https://images.rdoproject.org/queens/delorean/current-tripleo-rdo/undercloud.qcow2
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>&gt;= Rocky:</p>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -O https://images.rdoproject.org/rocky/rdo_trunk/current-tripleo-rdo/undercloud.qcow2
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p>TripleO Quickstart can build an Undercloud image.</p>
<ul class="simple">
<li><p>Leave the overcloud_nodes variable blank to only deploy the Undercloud. Otherwise, provide a number of virtual machines that should be created for use in the Overcloud.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -O https://opendev.org/openstack/tripleo-quickstart/raw/branch/master/quickstart.sh
$ bash quickstart.sh --release trunk/queens --tags all --playbook quickstart.yml -e <span class="nv">overcloud_nodes</span><span class="o">=</span><span class="s2">&quot;&quot;</span> <span class="nv">$VIRTHOST</span>
</pre></div>
</div>
</li>
<li><p>Log into the virtual machine once TripleO Quickstart has completed
setting up the environment.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ssh -F ~/.quickstart/ssh.config.ansible undercloud
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><strong>Undercloud (Manual)</strong></p>
<ul>
<li><p>It is recommended to create a user named “stack” with sudo
privileges to manage the Undercloud.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo useradd stack
$ sudo passwd stack
$ <span class="nb">echo</span> <span class="s2">&quot;stack ALL=(root) NOPASSWD:ALL&quot;</span> <span class="p">|</span> sudo tee -a /etc/sudoers.d/stack
$ sudo chmod <span class="m">0440</span> /etc/sudoers.d/stack
$ su - stack
</pre></div>
</div>
</li>
<li><p>Install TripleO. For &lt;= Stein, install <code class="docutils literal notranslate"><span class="pre">python-tripleoclient</span></code> instead.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install python3-tripleoclient openstack-tripleo-common openstack-tripleo-heat-templates
</pre></div>
</div>
</li>
<li><p>Update the operating system and reboot the server.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum update <span class="o">&amp;&amp;</span> sudo reboot
</pre></div>
</div>
</li>
<li><p>Copy the sample configuration to use as a base template. Optionally configure it.</p>
<ul>
<li><p>&lt;= Stein:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ cp /usr/share/instack-undercloud/undercloud.conf.sample ~/undercloud.conf
</pre></div>
</div>
</li>
<li><p>&gt;= Train:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ cp /usr/share/python-tripleoclient/undercloud.conf.sample ~/undercloud.conf
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Common Undercloud configuration options. If using an automated power management driver with Ironic, the IP address for the Undercloud’s provisioning NIC must use the same network and broadcast domain. [15]</p>
<ul class="simple">
<li><p>enable_* = Enable or disable non-essential OpenStack services on the Undercloud.</p></li>
<li><p><strong>dhcp_{start|end}</strong> = The range of IP addresses to temporarily use for provisioning Overcloud nodes. This range is a limiting factor in how many nodes can be provisioned at once.</p></li>
<li><p><strong>local_interface</strong> = The network interface to use for provisioning new Overcloud nodes. This will be configured as an Open vSwitch bridge. Default: eth1.</p></li>
<li><p><strong>local_ip</strong> = The local IP address of the Undercloud node to be used for using DHCP for providing IP addresses for Overcloud nodes during PXE booting. This should not be a public IP address.</p></li>
<li><p><strong>inspection_iprange</strong> = The IP range to use for Ironic’s introspection of the Overcloud nodes. This range needs to unique from the DHCP start/end range.</p></li>
<li><p>local_mtu = The MTU size to use for the local interface.</p></li>
<li><p><strong>cidr</strong> = The CIDR range of IP addresses to use for the Overcloud nodes.</p></li>
<li><p>masquerade_network = The network CIDR that will be used for masquerading external network connections.</p></li>
<li><p><strong>gateway</strong> = The default gateway to use for external connectivity to the Internet during provisioning. Use the “local_ip” when masquerading is used.</p></li>
<li><p>undercloud_admin_vip = The IP address to listen on for admin API endpoints.</p></li>
<li><p>undercloud_hostname = The fully qualified hostname to use for the Undercloud.</p></li>
<li><p>undercloud_nameservers = A list of DNS resolvers to use.</p></li>
<li><p>undercloud_ntp_servers = A list of NTP servers to use.</p></li>
<li><p>undercloud_public_vip = The IP address to listen on for public API endpoints.</p></li>
<li><p>enabled_hardware_types = The Ironic power management drivers to enable. For virtual lab environments, append “manual-management”.</p></li>
</ul>
</li>
<li><p>Example of changing the control plane (provisioning) network details.</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[DEFAULT]</span>
<span class="na">undercloud_admin_host</span> <span class="o">=</span> <span class="s">192.168.100.3</span>
<span class="na">undercloud_public_host</span> <span class="o">=</span> <span class="s">192.168.100.2</span>
<span class="k">[ctlplane-subnet]</span>
<span class="na">cidr</span> <span class="o">=</span> <span class="s">192.168.100.0/24</span>
<span class="na">dhcp_start</span> <span class="o">=</span> <span class="s">192.168.100.4</span>
<span class="na">dhcp_end</span> <span class="o">=</span> <span class="s">192.168.100.150</span>
<span class="na">gateway</span> <span class="o">=</span> <span class="s">192.168.100.1</span>
<span class="na">inspection_iprange</span> <span class="o">=</span> <span class="s">192.168.100.201,192.168.100.250</span>
<span class="na">masquerade</span> <span class="o">=</span> <span class="s">true</span>
</pre></div>
</div>
</li>
<li><p>Deploy the Undercloud. Anytime the configuration for the Undercloud changes, this command needs to be re-ran to update the installation.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack undercloud install
</pre></div>
</div>
</li>
<li><p>The installation will be logged to
<code class="docutils literal notranslate"><span class="pre">$HOME/.instack/install-undercloud.log</span></code>.</p></li>
<li><p>After the installation, OpenStack user credentials will be saved
to <code class="docutils literal notranslate"><span class="pre">$HOME/stackrc</span></code>. Source this file before running OpenStack
commands to verify that the Undercloud is operational.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">source</span> ~/stackrc
$ openstack catalog list
</pre></div>
</div>
</li>
<li><p>All OpenStack service passwords will be saved to
<code class="docutils literal notranslate"><span class="pre">$HOME/undercloud-passwords.conf</span></code>.</p></li>
</ul>
</li>
</ul>
<p>[12]</p>
<p>The next step is to optionally provision the Overcloud nodes and then deploy the OpenStack services.</p>
<div class="section" id="id3">
<h4><a class="toc-backref" href="#id23">Uninstall</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>Use the script provided <a class="reference external" href="https://access.redhat.com/solutions/2210421">here</a> to uninstall the Undercloud services.</p>
</div>
</div>
<div class="section" id="overcloud-provision-nodes-with-ironic">
<h3><a class="toc-backref" href="#id24">Overcloud (Provision Nodes with Ironic)</a><a class="headerlink" href="#overcloud-provision-nodes-with-ironic" title="Permalink to this headline">¶</a></h3>
<p>TripleO can provision a full CentOS or RHEL operating system onto a new baremetal server using the Ironic service. The normal TripleO deployment process is split into these steps [59]:</p>
<ul class="simple">
<li><p>Upload pre-built Overcloud image files to Glance.</p></li>
<li><p>Import the <code class="docutils literal notranslate"><span class="pre">instackenv</span></code> file with power management details about the nodes.</p></li>
<li><p>Introspect the nodes. This will PXE/network boot the Overcloud nodes so that Ironic can gather hardware information used during provisioning.</p></li>
<li><p>Deploy the Overcloud. This will automatically provision the nodes. Provisioning can optionally be done manually before the deployment.</p></li>
</ul>
<hr class="docutils" />
<ul>
<li><p><strong>Image Preparation</strong></p>
<ul>
<li><p>GA releases do not have pre-built Overcloud image files. They must be manually created. [60]</p>
<ul>
<li><p>Make and switch into an “images” directory.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ mkdir ~/images
$ <span class="nb">cd</span> ~/images
</pre></div>
</div>
</li>
<li><p>Set the environment variable for the RDO repositories so all necessary packages can be installed. Then build all of the required images. [13]</p>
<ul>
<li><p>&lt;= Ocata</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">DIB_YUM_REPO_CONF</span><span class="o">=</span><span class="s2">&quot;/etc/yum.repos.d/delorean*&quot;</span>
$ openstack overcloud image build --all
</pre></div>
</div>
</li>
<li><p>&gt;= Pike</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">DIB_YUM_REPO_CONF</span><span class="o">=</span><span class="s2">&quot;/etc/yum.repos.d/delorean*&quot;</span>
$ openstack overcloud image build
</pre></div>
</div>
</li>
<li><p>&gt;= Train (CentOS 8)</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo dnf config-manager --set-enabled HighAvailability
$ sudo dnf config-manager --set-enabled PowerTools
$ <span class="nb">export</span> <span class="nv">DIB_YUM_REPO_CONF</span><span class="o">=</span><span class="s2">&quot;/etc/yum.repos.d/delorean* /etc/yum.repos.d/CentOS-HA.repo /etc/yum.repos.d/CentOS-PowerTools.repo&quot;</span>
$ openstack overcloud image build
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>RDO Trunk (current-tripleo-rdo)</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">OS_RELEASE</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
$ <span class="nb">export</span> <span class="nv">TRUNK_BRANCH</span><span class="o">=</span><span class="s2">&quot;current-tripleo-rdo&quot;</span>
$ mkdir ~/images
$ <span class="nb">cd</span> ~/images
$ curl -O https://images.rdoproject.org/<span class="si">${</span><span class="nv">OS_RELEASE</span><span class="si">}</span>/rdo_trunk/<span class="si">${</span><span class="nv">TRUNK_BRANCH</span><span class="si">}</span>/ironic-python-agent.tar
$ curl -O https://images.rdoproject.org/<span class="si">${</span><span class="nv">OS_RELEASE</span><span class="si">}</span>/rdo_trunk/<span class="si">${</span><span class="nv">TRUNK_BRANCH</span><span class="si">}</span>/overcloud-full.tar
$ tar -v -x -f ironic-python-agent.tar
$ tar -v -x -f overcloud-full.tar
</pre></div>
</div>
</li>
<li><p>RHOSP [38]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">OS_RELEASE</span><span class="o">=</span><span class="s2">&quot;13.0&quot;</span>
$ mkdir ~/images
$ <span class="nb">cd</span> ~/images
$ sudo yum install rhosp-director-images rhosp-director-images-ipa
$ tar -v -x -f /usr/share/rhosp-director-images/overcloud-full-latest-<span class="si">${</span><span class="nv">OS_RELEASE</span><span class="si">}</span>.tar
$ tar -v -x -f /usr/share/rhosp-director-images/ironic-python-agent-latest-<span class="si">${</span><span class="nv">OS_RELEASE</span><span class="si">}</span>.tar
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>These are the default image files that will be used.</p>
<ul class="simple">
<li><p>ironic-python-agent.initramfs</p></li>
<li><p>ironic-python-agent.kernel</p></li>
<li><p>overcloud-full.initrd</p></li>
<li><p>overcloud-full.qcow2</p></li>
<li><p>overcloud-full.vmlinuz</p></li>
</ul>
</li>
<li><p>Upload those images.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud image upload --image-path /home/stack/images/
</pre></div>
</div>
</li>
<li><p>For using containers, the RDO images from Docker Hub are configured by default. Enable container caching on the Undercloud by generating this template. This will increase the Overcloud deployment time since container images will only have to be pulled from Docker Hub once. [33]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack tripleo container image prepare default --output-env-file ~/templates/containers-prepare-parameter.yaml
</pre></div>
</div>
</li>
</ul>
<p><strong>Introspection</strong></p>
<ul>
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">instackenv.{json|yaml}</span></code> file that describes the physical infrastructure of the Overcloud. [15] By default Ironic manages rebooting machines using the IPMI “pxe_ipmitool” driver. [18] Below are the common values to use that define how to handle power management (PM) for the Overcloud nodes via Ironic.</p>
<ul>
<li><p>All</p>
<ul class="simple">
<li><p>name = A descriptive name of the node.</p></li>
<li><p>pm_type = The power management driver type to use. Common drivers include “pxe_ipmitool” and “manual-management”.</p></li>
<li><p>capabilities = Set custom capabilities. For example, the profile and boot options can be defined here: <code class="docutils literal notranslate"><span class="pre">&quot;profile:compute,boot_option:local&quot;</span></code>.</p></li>
</ul>
</li>
<li><p>IPMI</p>
<ul class="simple">
<li><p>pm_user = The PM user to use.</p></li>
<li><p>pm_password = The PM password to use.</p></li>
<li><p>pm_addr = The PM IP address to use.</p></li>
</ul>
</li>
<li><p>Fake PXE</p>
<ul class="simple">
<li><p>arch = The processor architecture. The standard is “x86_64”.</p></li>
<li><p>cpu = The number of processor cores.</p></li>
<li><p>mac = A list of MAC addresses that should be used for the PXE boot. This normally only contains one value.</p></li>
<li><p>memory = The amount of RAM, in MiB.</p></li>
<li><p>disk = The amount of disk space, in GiB. Set this to be 1 GiB less than the actual reported storage size. That will prevent partitioning issues during the Overcloud deployment.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">instackenv.json</span></code> syntax:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;nodes&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;DESCRIPTIVE_NAME&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;pm_type&quot;</span><span class="p">:</span> <span class="s2">&quot;manual-management&quot;</span><span class="p">,</span>
            <span class="nt">&quot;arch&quot;</span><span class="p">:</span> <span class="s2">&quot;x86_64&quot;</span><span class="p">,</span>
            <span class="nt">&quot;cpu&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;CPU_CORES&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;memory&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;RAM_MB&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;disk&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;DISK_GB&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;capabilities&quot;</span><span class="p">:</span> <span class="s2">&quot;profile:control,boot_option:local&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;DESCRIPTIVE_NAME&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;pm_type&quot;</span><span class="p">:</span> <span class="s2">&quot;pxe_ipmitool&quot;</span><span class="p">,</span>
            <span class="nt">&quot;pm_user&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;IPMI_USER&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;pm_password&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;IPMI_PASSWORD&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;pm_addr&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;IPMI_IP_ADDRESS&gt;&quot;</span><span class="p">,</span>
            <span class="nt">&quot;mac&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&quot;AA:BB:CC:DD:EE:FF&quot;</span>
            <span class="p">],</span>
            <span class="nt">&quot;capabilities&quot;</span><span class="p">:</span> <span class="s2">&quot;profile:compute,boot_option:local&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">instackenv.yaml</span></code> minimal syntax:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">nodes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DESCRIPTIVE_NAME&gt;</span>
    <span class="nt">pm_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">manual-management</span>
    <span class="nt">mac</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;AA:BB:CC:DD:EE:FF&quot;</span>
    <span class="nt">capabilities</span><span class="p">:</span> <span class="s">&quot;profile:&lt;FLAVOR&gt;,boot_option:local&quot;</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">instackenv.yaml</span></code> full syntax:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">nodes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DESCRIPTIVE_NAME&gt;</span>
    <span class="nt">pm_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">manual-management</span>
    <span class="nt">arch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">x86_64</span>
    <span class="nt">cpu</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CPU_CORES&gt;</span>
    <span class="nt">memory</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;RAM_MB&gt;</span>
    <span class="nt">disk</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DISK_GB&gt;</span>
    <span class="nt">mac</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="s">&quot;AA:BB:CC:DD:EE:FF&quot;</span>
    <span class="nt">capabilities</span><span class="p">:</span> <span class="s">&quot;profile:control,boot_option:local&quot;</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DESCRIPTIVE_NAME&gt;</span>
    <span class="nt">pm_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pxe_ipmitool</span>
    <span class="nt">pm_user</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;IPMI_USER&gt;</span>
    <span class="nt">pm_password</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;IPMI_PASSWORD&gt;</span>
    <span class="nt">pm_addr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;IPMI_IP_ADDRESS&gt;</span>
    <span class="nt">capabilities</span><span class="p">:</span> <span class="s">&quot;profile:compute,boot_option:local&quot;</span>
</pre></div>
</div>
</li>
<li><p>Virtual lab environment:</p>
<ul>
<li><p>The “manual-management” driver can be used. This will require the end-user to manually reboot the managed nodes.</p></li>
<li><p>Virtual machines deployed using Vagrant need to have vagrant-libvirt’s default eth0 management interface removed. The first interface on the machine (normally eth0) is used for introspection and provisioning and cannot be that management interface.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo virsh detach-interface <span class="si">${</span><span class="nv">VM_NAME</span><span class="si">}</span> network --persistent --mac <span class="k">$(</span>sudo virsh dumpxml <span class="si">${</span><span class="nv">VM_NAME</span><span class="si">}</span> <span class="p">|</span> grep -B4 vagrant-libvirt <span class="p">|</span> grep mac <span class="p">|</span> cut -d <span class="s2">&quot;&#39;&quot;</span> -f2<span class="k">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Import the nodes and then introspect them immediately. [24]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud node import --introspect --provide instackenv.json
</pre></div>
</div>
</li>
<li><p>Alternatively, import them and inspect them later.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud node import instackenv.json
Started Mistral Workflow tripleo.baremetal.v1.register_or_update. Execution ID: cf2ce144-a22a-4838-9a68-e7c3c5cf0dad
Waiting <span class="k">for</span> messages on queue <span class="s1">&#39;tripleo&#39;</span> with no timeout.
<span class="m">2</span> node<span class="o">(</span>s<span class="o">)</span> successfully moved to the <span class="s2">&quot;manageable&quot;</span> state.
Successfully registered node UUID c1456e44-5245-4a4d-b551-3c6d6217dac4
Successfully registered node UUID 9a277de3-02be-4022-ad26-ec4e66d97bd1
</pre></div>
</div>
<ul>
<li><p>Verify that Ironic has successfully added the new baremetal nodes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> None          <span class="p">|</span> None        <span class="p">|</span> manageable         <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> None          <span class="p">|</span> None        <span class="p">|</span> manageable         <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Start the introspection. [24] Each Overcloud node requires at least 4GB of RAM or else the introspection will fail with a kernel panic during the network booted live session.</p>
<ul>
<li><p><strong>Method #1:</strong> Automatical introspection with a managed Ironic driver (such as IPMI). This command will introspect all nodes in the <code class="docutils literal notranslate"><span class="pre">management</span></code> state and set them to the <code class="docutils literal notranslate"><span class="pre">available</span></code> state when complete.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud node introspect --all-manageable --provide
Waiting <span class="k">for</span> introspection to finish...
Waiting <span class="k">for</span> messages on queue <span class="s1">&#39;tripleo&#39;</span> with no timeout.
Introspection of node c1456e44-5245-4a4d-b551-3c6d6217dac4 completed. Status:SUCCESS. Errors:None
Introspection of node 9a277de3-02be-4022-ad26-ec4e66d97bd1 completed. Status:SUCCESS. Errors:None
Introspection completed.
Waiting <span class="k">for</span> messages on queue <span class="s1">&#39;tripleo&#39;</span> with no timeout.
<span class="m">2</span> node<span class="o">(</span>s<span class="o">)</span> successfully moved to the <span class="s2">&quot;available&quot;</span> state.
</pre></div>
</div>
</li>
<li><p><strong>Method #2:</strong> Automatic but the connection details are given via the CLI instead of the instackenv file.</p>
<ul>
<li><p>Automatically discover the available servers by scanning hardware devices (such as IPMI) via a CIDR range and using different logins.</p>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud node discover --range &lt;CIDR&gt; --credentials &lt;USER1&gt;:&lt;PASSWORD1&gt; --credentials &lt;USER2&gt;:&lt;PASSWORD2&gt;
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</li>
<li><p><strong>Method #3:</strong> Lab environment using the manual-management driver.</p>
<ul>
<li><p>In another terminal, verify that the “Power State” is “power on” and then manually start the virtual machines. The introspection will take a long time to complete.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud node introspect --all-manageable --provide
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> None          <span class="p">|</span> power on    <span class="p">|</span> manageable         <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> None          <span class="p">|</span> power on    <span class="p">|</span> manageable         <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
</pre></div>
</div>
</li>
<li><p>When the “Power State” becomes “power off” and the “Provisioning State” becomes “available” then manually shutdown the virtual machines.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> None          <span class="p">|</span> power off   <span class="p">|</span> available          <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> None          <span class="p">|</span> power off   <span class="p">|</span> available          <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+---------------+-------------+--------------------+-------------+
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Configure the necessary flavors (mandatory for getting accurate results when using the manual-management Ironic driver). [25] Commonly custom “control” and “compute” flavors will need to be created.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack flavor create --id auto --vcpus &lt;CPU_COUNT&gt; --ram &lt;RAM_IN_MB&gt; --disk &lt;DISK_IN_GB_MINUS_ONE&gt; --swap &lt;SWAP_IN_MB&gt; --property <span class="s2">&quot;capabilities:profile&quot;</span><span class="o">=</span><span class="s2">&quot;&lt;FLAVOR_NAME&gt;&quot;</span> &lt;FLAVOR_NAME&gt;
</pre></div>
</div>
</li>
<li><p>Configure the kernel and initramfs that the baremetal nodes should boot from.</p>
<ul>
<li><p>Queens (optional) [24]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
$ openstack overcloud node configure &lt;NODE_ID&gt;
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>If the profile and/or boot option were not specified in the instackenv.json file then configure it now. Verify that the profiles have been applied. Valid default flavors are <code class="docutils literal notranslate"><span class="pre">block-storage</span></code>, <code class="docutils literal notranslate"><span class="pre">ceph-storage</span></code>, <code class="docutils literal notranslate"><span class="pre">compute</span></code>, <code class="docutils literal notranslate"><span class="pre">control</span></code>, and <code class="docutils literal notranslate"><span class="pre">swift-storage</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node <span class="nb">set</span> --property <span class="nv">capabilities</span><span class="o">=</span><span class="s1">&#39;profile:control,boot_option:local&#39;</span> c1456e44-5245-4a4d-b551-3c6d6217dac4
$ openstack baremetal node <span class="nb">set</span> --property <span class="nv">capabilities</span><span class="o">=</span><span class="s1">&#39;profile:compute,boot_option:local&#39;</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1
$ openstack overcloud profiles list --all
+--------------------------------------+-----------+-----------------+-----------------+-------------------+-------+
<span class="p">|</span> Node UUID                            <span class="p">|</span> Node Name <span class="p">|</span> Provision State <span class="p">|</span> Current Profile <span class="p">|</span> Possible Profiles <span class="p">|</span> Error <span class="p">|</span>
+--------------------------------------+-----------+-----------------+-----------------+-------------------+-------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> available       <span class="p">|</span> control         <span class="p">|</span>                   <span class="p">|</span>       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> available       <span class="p">|</span> compute         <span class="p">|</span>                   <span class="p">|</span>       <span class="p">|</span>
+--------------------------------------+-----------+-----------------+-----------------+-------------------+-------
</pre></div>
</div>
</li>
<li><p>Set a DNS nameserver on the control plane subnet. Starting with Rocky, this is automatically set to the value of <code class="docutils literal notranslate"><span class="pre">undercloud_nameservers</span></code> from the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code> configuration.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack subnet <span class="nb">set</span> --dns-nameserver <span class="m">8</span>.8.8.8 --dns-nameserver <span class="m">1</span>.1.1.1 ctlplane-subnet
</pre></div>
</div>
</li>
</ul>
<p><strong>Deployment</strong></p>
<ul>
<li><p>Configure the networking Heat templates that define the physical and virtual network interface settings.</p>
<ul>
<li><p>Scenario #1 - Default templates:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ mkdir /home/stack/templates/
$ /usr/share/openstack-tripleo-heat-templates/tools/process-templates.py -o /home/stack/templates/
</pre></div>
</div>
</li>
<li><p>Scenario #2 - Variables can be customized via the “roles_data.yaml” and “network_data.yml” files. Example usage can be found <a class="reference external" href="https://github.com/redhat-openstack/tripleo-workshop/tree/master/composable-roles-dev">here</a>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ mkdir /home/stack/templates/
$ cp /usr/share/openstack-tripleo-heat-templates/roles_data.yaml /home/stack/templates/roles_data_custom.yaml
$ cp /usr/share/openstack-tripleo-heat-templates/network_data.yml /home/stack/templates/network_data_custom.yaml
$ /usr/share/openstack-tripleo-heat-templates/tools/process-templates.py --roles-data ~/templates/roles_data_custom.yaml --roles-data ~/templates/network_data_custom.yaml
</pre></div>
</div>
</li>
<li><p>Scenario #3 - No templates:</p>
<ul class="simple">
<li><p>If no custom network settings will be used, then the Heat templates do not need to be generated. By default, TripleO will configure different subnets to separate traffic (instead of also using VLANs) onto the default network interface of the Overcloud nodes.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>In a YAML Heat template, set the number of controller, compute, Ceph, and/or any other nodes that should be deployed.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">OvercloudControllerFlavor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">control</span>
  <span class="nt">OvercloudComputeFlavor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">compute</span>
  <span class="nt">OvercloudCephStorageFlavor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph</span>
  <span class="nt">ControllerCount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_CONTROLLER_NODES&gt;</span>
  <span class="nt">ComputeCount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_COMPUTE_NODES&gt;</span>
  <span class="nt">CephStorageCount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_CEPH_NODES&gt;</span>
</pre></div>
</div>
</li>
<li><p>Alternatively, the initial default count can be set in the <code class="docutils literal notranslate"><span class="pre">roles_data.yaml</span></code> file.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Controller</span>
  <span class="nt">CountDefault</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_CONTROLLER_NODES&gt;</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Compute</span>
  <span class="nt">CountDefault</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_COMPUTE_NODES&gt;</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">CephStorage</span>
  <span class="nt">CountDefault</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NUMBER_OF_CEPHSTORAGE_NODES&gt;</span>
</pre></div>
</div>
</li>
<li><p>Deploy the Overcloud with any custom Heat configurations. [13] Starting with the Pike release, most services are deployed as containers by default. For preventing the use of containers, remove the “docker.yaml” and “docker-ha.yaml” files from <code class="docutils literal notranslate"><span class="pre">${TEMPLATES_DIRECTORY}/environments/</span></code>. [14]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack <span class="nb">help</span> overcloud deploy
$ openstack overcloud deploy --templates ~/templates -r ~/templates/roles_data_custom.yaml
</pre></div>
</div>
<ul>
<li><p>Virtual lab environment:</p>
<ul>
<li><p>When the “Provisioning State” becomes “wait call-back” then manually start the virtual machines. The relevant Overcloud image will be copied to the local drive(s). At this point, Nova will have already changed the servers to have the “Status” of “BUILD”.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID                        <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> 16a09779-b324-4d83-bc7d-3d24d2f4aa5d <span class="p">|</span> power on    <span class="p">|</span> <span class="nb">wait</span> call-back     <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> 5c2d1374-8b20-4af6-b114-df15bbd3d9ca <span class="p">|</span> power on    <span class="p">|</span> <span class="nb">wait</span> call-back     <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
$ openstack server list
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
<span class="p">|</span> ID                                   <span class="p">|</span> Name                    <span class="p">|</span> Status <span class="p">|</span> Networks               <span class="p">|</span> Image          <span class="p">|</span> Flavor  <span class="p">|</span>
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> overcloud-novacompute-0 <span class="p">|</span> BUILD  <span class="p">|</span> <span class="nv">ctlplane</span><span class="o">=</span><span class="m">192</span>.168.24.35 <span class="p">|</span> overcloud-full <span class="p">|</span> compute <span class="p">|</span>
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> overcloud-controller-0  <span class="p">|</span> BUILD  <span class="p">|</span> <span class="nv">ctlplane</span><span class="o">=</span><span class="m">192</span>.168.24.34 <span class="p">|</span> overcloud-full <span class="p">|</span> control <span class="p">|</span>
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
</pre></div>
</div>
</li>
<li><p>The nodes will then be in the “Provisioning State” of “deploying”. At this phase the operating system image is copied over, partitions are resized, and SSH keys are configured for access to the <code class="docutils literal notranslate"><span class="pre">heat-admin</span></code> user account.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID                        <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> 16a09779-b324-4d83-bc7d-3d24d2f4aa5d <span class="p">|</span> power on    <span class="p">|</span> deploying          <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> 5c2d1374-8b20-4af6-b114-df15bbd3d9ca <span class="p">|</span> power on    <span class="p">|</span> deploying          <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
</pre></div>
</div>
</li>
<li><p>After that is complete, the virtual machines will power off. Ironic will report that the “Power State” is now “power on” and the Provisioning State” is now “active.” The nodes have now been provisioned with the Overcloud image. Change the boot order of each machine to start with the hard drive instead of the network interface card. Manually start the virtual machines after that.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> UUID                                 <span class="p">|</span> Name      <span class="p">|</span> Instance UUID                        <span class="p">|</span> Power State <span class="p">|</span> Provisioning State <span class="p">|</span> Maintenance <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> control01 <span class="p">|</span> 16a09779-b324-4d83-bc7d-3d24d2f4aa5d <span class="p">|</span> power on    <span class="p">|</span> active             <span class="p">|</span> False       <span class="p">|</span>
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> compute01 <span class="p">|</span> 5c2d1374-8b20-4af6-b114-df15bbd3d9ca <span class="p">|</span> power on    <span class="p">|</span> active             <span class="p">|</span> False       <span class="p">|</span>
+--------------------------------------+-----------+--------------------------------------+-------------+--------------------+-------------+
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>The deploy will continue onto the configuration management stage. Before Rocky, this process used os-collect-config (Heat). Starting with Rocky, this now uses config-download (Ansible).</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2019</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">30</span> <span class="mi">23</span><span class="p">:</span><span class="mi">40</span><span class="p">:</span><span class="mi">47</span><span class="n">Z</span> <span class="p">[</span><span class="n">overcloud</span><span class="o">-</span><span class="n">AllNodesDeploySteps</span><span class="o">-</span><span class="mi">5</span><span class="n">yoxyq2a4bgz</span><span class="p">]:</span> <span class="n">UPDATE_COMPLETE</span>  <span class="n">Stack</span> <span class="n">UPDATE</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="mi">2019</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">30</span> <span class="mi">23</span><span class="p">:</span><span class="mi">40</span><span class="p">:</span><span class="mi">47</span><span class="n">Z</span> <span class="p">[</span><span class="n">AllNodesDeploySteps</span><span class="p">]:</span> <span class="n">UPDATE_COMPLETE</span>  <span class="n">state</span> <span class="n">changed</span>
<span class="mi">2019</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">30</span> <span class="mi">23</span><span class="p">:</span><span class="mi">40</span><span class="p">:</span><span class="mi">51</span><span class="n">Z</span> <span class="p">[</span><span class="n">overcloud</span><span class="p">]:</span> <span class="n">UPDATE_COMPLETE</span>  <span class="n">Stack</span> <span class="n">UPDATE</span> <span class="n">completed</span> <span class="n">successfully</span>

 <span class="n">Stack</span> <span class="n">overcloud</span> <span class="n">UPDATE_COMPLETE</span>

<span class="n">Deploying</span> <span class="n">overcloud</span> <span class="n">configuration</span>
<span class="n">Enabling</span> <span class="n">ssh</span> <span class="n">admin</span> <span class="p">(</span><span class="n">tripleo</span><span class="o">-</span><span class="n">admin</span><span class="p">)</span> <span class="k">for</span> <span class="n">hosts</span><span class="p">:</span>
<span class="mf">192.168</span><span class="o">.</span><span class="mf">24.17</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">24.16</span>
<span class="n">Using</span> <span class="n">ssh</span> <span class="n">user</span> <span class="n">cloud</span><span class="o">-</span><span class="n">user</span> <span class="k">for</span> <span class="n">initial</span> <span class="n">connection</span><span class="o">.</span>
<span class="n">Using</span> <span class="n">ssh</span> <span class="n">key</span> <span class="n">at</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">stack</span><span class="o">/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">id_rsa</span> <span class="k">for</span> <span class="n">initial</span> <span class="n">connection</span><span class="o">.</span>
<span class="n">Inserting</span> <span class="n">TripleO</span> <span class="n">short</span> <span class="n">term</span> <span class="n">key</span> <span class="k">for</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">24.17</span>
<span class="ne">Warning</span><span class="p">:</span> <span class="n">Permanently</span> <span class="n">added</span> <span class="s1">&#39;192.168.24.17&#39;</span> <span class="p">(</span><span class="n">ECDSA</span><span class="p">)</span> <span class="n">to</span> <span class="n">the</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">known</span> <span class="n">hosts</span><span class="o">.</span>
<span class="n">Inserting</span> <span class="n">TripleO</span> <span class="n">short</span> <span class="n">term</span> <span class="n">key</span> <span class="k">for</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">24.16</span>
<span class="ne">Warning</span><span class="p">:</span> <span class="n">Permanently</span> <span class="n">added</span> <span class="s1">&#39;192.168.24.16&#39;</span> <span class="p">(</span><span class="n">ECDSA</span><span class="p">)</span> <span class="n">to</span> <span class="n">the</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">known</span> <span class="n">hosts</span><span class="o">.</span>
<span class="n">Starting</span> <span class="n">ssh</span> <span class="n">admin</span> <span class="n">enablement</span> <span class="n">workflow</span>
<span class="n">Started</span> <span class="n">Mistral</span> <span class="n">Workflow</span> <span class="n">tripleo</span><span class="o">.</span><span class="n">access</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">enable_ssh_admin</span><span class="o">.</span> <span class="n">Execution</span> <span class="n">ID</span><span class="p">:</span> <span class="mi">0</span><span class="n">a69a3a3</span><span class="o">-</span><span class="n">d9bb</span><span class="o">-</span><span class="mi">43</span><span class="n">c6</span><span class="o">-</span><span class="mi">8</span><span class="n">aed</span><span class="o">-</span><span class="mi">0</span><span class="n">ef33f6336d7</span>
<span class="n">ssh</span> <span class="n">admin</span> <span class="n">enablement</span> <span class="n">workflow</span> <span class="o">-</span> <span class="n">RUNNING</span><span class="o">.</span>
<span class="n">ssh</span> <span class="n">admin</span> <span class="n">enablement</span> <span class="n">workflow</span> <span class="o">-</span> <span class="n">RUNNING</span><span class="o">.</span>
<span class="n">ssh</span> <span class="n">admin</span> <span class="n">enablement</span> <span class="n">workflow</span> <span class="o">-</span> <span class="n">COMPLETE</span><span class="o">.</span>
<span class="n">Removing</span> <span class="n">TripleO</span> <span class="n">short</span> <span class="n">term</span> <span class="n">key</span> <span class="kn">from</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">24.17</span>
<span class="ne">Warning</span><span class="p">:</span> <span class="n">Permanently</span> <span class="n">added</span> <span class="s1">&#39;192.168.24.17&#39;</span> <span class="p">(</span><span class="n">ECDSA</span><span class="p">)</span> <span class="n">to</span> <span class="n">the</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">known</span> <span class="n">hosts</span><span class="o">.</span>
</pre></div>
</div>
<ul>
<li><p>Once the deployment is complete, verify that the Overcloud was deployed successfully. If it was not, then troubleshoot any stack resources that failed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PLAY</span> <span class="n">RECAP</span> <span class="o">*********************************************************************</span>
<span class="n">overcloud</span><span class="o">-</span><span class="n">controller</span><span class="o">-</span><span class="mi">0</span>     <span class="p">:</span> <span class="n">ok</span><span class="o">=</span><span class="mi">257</span>  <span class="n">changed</span><span class="o">=</span><span class="mi">142</span>  <span class="n">unreachable</span><span class="o">=</span><span class="mi">0</span>    <span class="n">failed</span><span class="o">=</span><span class="mi">0</span>
<span class="n">overcloud</span><span class="o">-</span><span class="n">novacompute</span><span class="o">-</span><span class="mi">0</span>    <span class="p">:</span> <span class="n">ok</span><span class="o">=</span><span class="mi">178</span>  <span class="n">changed</span><span class="o">=</span><span class="mi">78</span>   <span class="n">unreachable</span><span class="o">=</span><span class="mi">0</span>    <span class="n">failed</span><span class="o">=</span><span class="mi">0</span>
<span class="n">undercloud</span>                 <span class="p">:</span> <span class="n">ok</span><span class="o">=</span><span class="mi">21</span>   <span class="n">changed</span><span class="o">=</span><span class="mi">12</span>   <span class="n">unreachable</span><span class="o">=</span><span class="mi">0</span>    <span class="n">failed</span><span class="o">=</span><span class="mi">0</span>

<span class="n">Wednesday</span> <span class="mi">13</span> <span class="n">February</span> <span class="mi">2019</span>  <span class="mi">14</span><span class="p">:</span><span class="mi">38</span><span class="p">:</span><span class="mi">34</span> <span class="o">-</span><span class="mi">0500</span> <span class="p">(</span><span class="mi">0</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mf">00.103</span><span class="p">)</span>       <span class="mi">0</span><span class="p">:</span><span class="mi">40</span><span class="p">:</span><span class="mf">32.320</span> <span class="o">****</span>
<span class="o">===============================================================================</span>

<span class="n">Ansible</span> <span class="n">passed</span><span class="o">.</span>
<span class="n">Overcloud</span> <span class="n">configuration</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">Waiting</span> <span class="k">for</span> <span class="n">messages</span> <span class="n">on</span> <span class="n">queue</span> <span class="s1">&#39;tripleo&#39;</span> <span class="k">with</span> <span class="n">no</span> <span class="n">timeout</span><span class="o">.</span>
<span class="n">Host</span> <span class="mf">192.168</span><span class="o">.</span><span class="mf">24.23</span> <span class="ow">not</span> <span class="n">found</span> <span class="ow">in</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">stack</span><span class="o">/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">known_hosts</span>
<span class="n">Overcloud</span> <span class="n">Endpoint</span><span class="p">:</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">24.23</span><span class="p">:</span><span class="mi">5000</span>
<span class="n">Overcloud</span> <span class="n">Horizon</span> <span class="n">Dashboard</span> <span class="n">URL</span><span class="p">:</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">24.23</span><span class="p">:</span><span class="mi">80</span><span class="o">/</span><span class="n">dashboard</span>
<span class="n">Overcloud</span> <span class="n">rc</span> <span class="n">file</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">stack</span><span class="o">/</span><span class="n">overcloudrc</span>
<span class="n">Overcloud</span> <span class="n">Deployed</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack stack list
$ openstack stack failures list &lt;OVERCLOUD_STACK_ID&gt; --long
$ openstack stack show &lt;OVERCLOUD_STACK_ID&gt;
$ openstack stack resource list &lt;OVERCLOUD_STACK_ID&gt;
$ openstack stack resource show &lt;OVERCLOUD_STACK_ID&gt; &lt;RESOURCE_NAME&gt;
$ openstack overcloud failures list <span class="c1"># Requires &gt;= Rocky</span>
</pre></div>
</div>
</li>
<li><p>Source the Overcloud admin credentials to manage it.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">source</span> ~/overcloudrc
</pre></div>
</div>
</li>
<li><p>The nodes can be managed via SSH using the “heat-admin” user.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack server list
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
<span class="p">|</span> ID                                   <span class="p">|</span> Name                    <span class="p">|</span> Status <span class="p">|</span> Networks               <span class="p">|</span> Image          <span class="p">|</span> Flavor  <span class="p">|</span>
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
<span class="p">|</span> 9a277de3-02be-4022-ad26-ec4e66d97bd1 <span class="p">|</span> overcloud-novacompute-0 <span class="p">|</span> ACTIVE <span class="p">|</span> <span class="nv">ctlplane</span><span class="o">=</span><span class="m">192</span>.168.24.35 <span class="p">|</span> overcloud-full <span class="p">|</span> compute <span class="p">|</span>
<span class="p">|</span> c1456e44-5245-4a4d-b551-3c6d6217dac4 <span class="p">|</span> overcloud-controller-0  <span class="p">|</span> ACTIVE <span class="p">|</span> <span class="nv">ctlplane</span><span class="o">=</span><span class="m">192</span>.168.24.34 <span class="p">|</span> overcloud-full <span class="p">|</span> control <span class="p">|</span>
+--------------------------------------+-------------------------+--------+------------------------+----------------+---------+
$ ssh -l heat-admin <span class="m">192</span>.168.24.34
</pre></div>
</div>
</li>
</ul>
<p>[13][23]</p>
<ul>
<li><p>Passwords for the Overcloud services can be found by running:</p>
<ul>
<li><p>TripleO Queens:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack object save overcloud plan-environment.yaml
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>In &gt;= Rocky (or in Queens, if configured), the Ansible files used for the configuration management can be downloaded. Those files can then be imported into an external source such as Ansible Tower or AWX. The <code class="docutils literal notranslate"><span class="pre">tripleo-ansible-inventory</span></code> script is used to generate a dynamic inventory file for Ansible that contains the Overcloud hosts. [30]</p>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud config download
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>For a lab with a private network, use a proxy service from the hypervisor to access the dashboard and API IP address.</p>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sshuttle -r stack@undercloud <span class="m">192</span>.168.24.23
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="overcloud-pre-deployed-provisioned-nodes">
<h3><a class="toc-backref" href="#id25">Overcloud (Pre-deployed/provisioned Nodes)</a><a class="headerlink" href="#overcloud-pre-deployed-provisioned-nodes" title="Permalink to this headline">¶</a></h3>
<p>Introspection and the operating system provisioning can be skipped if the Overcloud nodes are already setup and running.</p>
<p>Pros:</p>
<ul class="simple">
<li><p>Easier to deploy, subjectively.</p></li>
<li><p>Faster to deploy if using a pre-configured operating system snapshot.</p></li>
<li><p>No Nova or Ironic dependencies.</p></li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li><p>All Overclouds nodes must be pre-provisioned. Ironic cannot manage any for provisioning.</p></li>
<li><p>Requires the operating system to already be installed.</p></li>
<li><p>Repositories have to be installed and enabled manually.</p></li>
<li><p>Validations are not supported.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Overcloud Nodes</strong></p>
<ul>
<li><p>Install CentOS or RHEL.</p></li>
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">stack</span></code> user. Add the <code class="docutils literal notranslate"><span class="pre">stack</span></code> user’s SSH key from the Undercloud to allow access during deployment.</p>
<ul class="simple">
<li><p>Alternatively, specify a different user for the deployment with <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span> <span class="pre">--overcloud-ssh-user</span> <span class="pre">&lt;USER&gt;</span> <span class="pre">--overcloud-ssh-key</span> <span class="pre">&lt;PRIVATE_KEY_FLIE&gt;</span></code>. This user is only used during the initial deployment to create a <code class="docutils literal notranslate"><span class="pre">tripleo-admin</span></code> user (or the user <code class="docutils literal notranslate"><span class="pre">heat-admin</span></code> in Queens release and older).</p></li>
</ul>
</li>
<li><p>Enable the RDO or RHOSP repositories.</p></li>
<li><p>Install the Heat user agent (required only for &lt;= Queens when not using config-download).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum -y install python-heat-agent*
</pre></div>
</div>
</li>
</ul>
<p><strong>Undercloud/Director</strong></p>
<ul>
<li><p>For config-download scenarios on &lt; Train, generate Heat templates for pre-provisioned nodes from a special roles data file. Starting in Train, it uses the default <code class="docutils literal notranslate"><span class="pre">/usr/share/openstack-tripleo-heat-templates/roles_data.yaml</span></code> file. Previously, roles such as <code class="docutils literal notranslate"><span class="pre">ControllerDeployedServer</span></code> and <code class="docutils literal notranslate"><span class="pre">ComputeDeployedServer</span></code> were used. These now use the standard <code class="docutils literal notranslate"><span class="pre">Controller</span></code> and <code class="docutils literal notranslate"><span class="pre">Compute</span></code> roles.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ mkdir /home/stack/templates/
$ /usr/share/openstack-tripleo-heat-templates/tools/process-templates.py --roles-data /usr/share/openstack-tripleo-heat-templates/deployed-server/deployed-server-roles-data.yaml --output /home/stack/templates/
</pre></div>
</div>
</li>
<li><p>TripleO needs a hostname and port mapping to know what IP addresses to connect to for the deployment. The <code class="docutils literal notranslate"><span class="pre">NeutronPublicInterface</span></code> (eth0 by default) will be converted into a bridge (br-ex by default). It will have static IP addressing set to what the <code class="docutils literal notranslate"><span class="pre">fixed_ips</span></code> and <code class="docutils literal notranslate"><span class="pre">cidr</span></code> are set to. The <code class="docutils literal notranslate"><span class="pre">ControlPlaneDefaultRoute</span></code> will set the default route in <code class="docutils literal notranslate"><span class="pre">/etc/sysconfig/network-scripts/route-br-ex</span></code>.</p></li>
<li><p><strong>Scenario 1: Use the Undercloud control plane network.</strong></p>
<ul>
<li><p>The control plane IP address of each Overcloud node should be within the range of the <code class="docutils literal notranslate"><span class="pre">network_cidr</span></code> value defined in the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code> configuration. By default this is <code class="docutils literal notranslate"><span class="pre">192.168.24.0/24</span></code> with 192.168.24.{1,2,3} all being reserved/used by the Undercloud.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="c1"># This allows the IPs for provisioning to be manually set via DeployedServerPortMap.</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::DeployedServer::ControlPlanePort</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployed-server/deployed-neutron-port.yaml</span>
  <span class="c1"># These role resources will convert the NeutronPublicInterface into the required br-ex bridge interface.</span>
  <span class="c1">## Open vSwitch</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::ControllerDeployedServer::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-static-bridge.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::ComputeDeployedServer::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-static-bridge.yaml</span>

<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="c1"># The Overcloud NIC that has a default route.</span>
  <span class="c1">## Specify the exact network interface name.</span>
  <span class="c1">## Alternatively, use a Heat alias such as &quot;nic1&quot; (eth0) or &quot;nic2&quot; (eth1) if the NICs are named</span>
  <span class="c1">## differently on the Overcloud nodes.</span>
  <span class="nt">NeutronPublicInterface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nic2</span>
  <span class="c1"># The default route for the Overcloud nodes.</span>
  <span class="c1"># Example: 192.168.24.1</span>
  <span class="nt">ControlPlaneDefaultRoute</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DEFAULT_ROUTE_IP_ADDRESS&gt;</span>
  <span class="nt">EC2MetadataIp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;UNDERCLOUD_LOCAL_IP&gt;</span>
  <span class="nt">DeployedServerPortMap</span><span class="p">:</span>
    <span class="nt">&lt;CONTROLLER0_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER0_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="c1"># Example = 192.168.24.0/24</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="c1"># Example = 192.168.24.0/24</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;CONTROLLER1_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER1_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;CONTROLLER2_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER2_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;COMPUTE0_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPUTE0_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;COMPUTE1_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPUTE1_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><strong>Scenario 2: Use a custom network (not on the Undercloud control plane).</strong></p>
<ul>
<li><p>The Undercloud must be configured to use a public host for API communication during provisioning. The only way to do that, for security reasons, is to enable a TLS certificate.</p>
<ul>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">undercloud_public_host</span></code> in the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code> to an IP address or hostname that will be accessible by the Overcloud control plane IP addresses.</p></li>
<li><p>Create a YAML file with the Puppet Hiera data that forces the deployment to use the public API endpoint on the Undercloud instead of the internal one. Set the <code class="docutils literal notranslate"><span class="pre">hieradata_override</span></code> value to the file path of that YAML file in the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">heat_clients_endpoint_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">public</span>
<span class="l l-Scalar l-Scalar-Plain">heat::engine::default_deployment_signal_transport</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">TEMP_URL_SIGNAL</span>
</pre></div>
</div>
</li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">generate_service_certificate</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code> in the <code class="docutils literal notranslate"><span class="pre">undercloud.conf</span></code>. This will generate a self-signed certificate.</p></li>
<li><p>Load the new Undercloud configuration by re-running <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">undercloud</span> <span class="pre">install</span></code>.</p></li>
</ul>
</li>
<li><p>Set a custom control plane virtual IP that will be used by the HAProxy load balancer.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::ControllerDeployedServer::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-static-bridge.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::ComputeDeployedServer::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-static-bridge.yaml</span>
  <span class="c1"># These resources will allow for a custom control plane virtual IP to be used for controller node services.</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::DeployedServer::ControlPlanePort</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployed-server/deployed-neutron-port.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Network::Ports::ControlPlaneVipPort</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/deployed-server/deployed-neutron-port.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Network::Ports::RedisVipPort</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/network/ports/noop.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Network::Ports::OVNDBsVipPort</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">/usr/share/openstack-tripleo-heat-templates/network/ports/noop.yaml</span>

<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">NeutronPublicInterface</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NIC&gt;</span>
  <span class="nt">ControlPlaneDefaultRoute</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DEFAULT_ROUTE_IP_ADDRESS&gt;</span>
  <span class="nt">EC2MetadataIp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;UNDERCLOUD_PUBLIC_HOST&gt;</span>
  <span class="nt">DeployedServerPortMap</span><span class="p">:</span>
    <span class="nt">control_virtual_ip</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="c1"># This IP must be accessible by all of the Overcloud nodes and should be on the same network.</span>
        <span class="c1"># It must also must be a unique IP address and not conflict with any other IP addresses.</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROL_VIRTUAL_IP_ADDRESS&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;CONTROLLER0_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER0_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="c1"># Example = 192.168.122.0/24</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="c1"># Example = 192.168.122.0/24</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
    <span class="nt">&lt;COMPUTE0_SHORT_HOSTNAME&gt;-ctlplane</span><span class="p">:</span>
      <span class="nt">fixed_ips</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_address</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPUTE0_IPV4&gt;</span>
      <span class="nt">subnets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">cidr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
      <span class="nt">network</span><span class="p">:</span>
        <span class="nt">tags</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NETWORK_ADDRESS&gt;/&lt;PREFIX&gt;</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>If config-download will be used, hostname maps have to be defined. These must be mapped to the short hostname of the servers that relate to the port mappings.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">HostnameMap</span><span class="p">:</span>
    <span class="nt">overcloud-controller-0</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER0_SHORT_HOSTNAME&gt;</span>
    <span class="nt">overcloud-controller-1</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER1_SHORT_HOSTNAME&gt;</span>
    <span class="nt">overcloud-controller-2</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTROLLER2_SHORT_HOSTNAME&gt;</span>
    <span class="nt">overcloud-novacompute-0</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPUTE0_SHORT_HOSTNAME&gt;</span>
    <span class="nt">overcloud-novacompute-1</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPUTE1_SHORT_HOSTNAME&gt;</span>
</pre></div>
</div>
</li>
<li><p>Start the deployment of the Overcloud using at least these arguments and templates. The Heat templates defining the hostname and port maps must also be included.</p>
<ul>
<li><p>&lt;= Stein:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --disable-validations --templates ~/templates <span class="se">\</span>
    -e ~/templates/environments/deployed-server-environment.yaml <span class="se">\</span>
    -e ~/templates/environments/deployed-server-bootstrap-environment-<span class="o">[</span>centos<span class="p">|</span>rhel<span class="o">]</span>.yaml <span class="se">\</span>
    -e ~/templates/environments/deployed-server-pacemaker-environment.yaml <span class="se">\</span>
    -r /usr/share/openstack-tripleo-heat-templates/deployed-server/deployed-server-roles-data.yaml
</pre></div>
</div>
</li>
<li><p>&gt;= Train (the default composable roles data can now be used):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --disable-validations --templates ~/templates <span class="se">\</span>
    -e ~/templates/environments/deployed-server-environment.yaml <span class="se">\</span>
    -r /usr/share/openstack-tripleo-heat-templates/roles_data.yaml
</pre></div>
</div>
</li>
<li><p>&gt;= Victoria:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --disable-validations --templates ~/templates <span class="se">\</span>
    --deployed-server
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<p><strong>config-download (&gt;= Rocky)</strong></p>
<p>No further action is required.</p>
<p><strong>config-download (Queens)</strong></p>
<p>Add the <code class="docutils literal notranslate"><span class="pre">--config-download</span> <span class="pre">-e</span> <span class="pre">~/templates/environments/config-download-environment.yaml</span></code> template after (not before) the predeployed server templates to properly enable config-download.</p>
<p><strong>os-collect-config (Queens, Automatic)</strong></p>
<ul>
<li><p>When using Queens without config-download, the deployment will pause on the creation of the Overcloud nodes. The Heat agent on the Overcloud nodes need to be registered for the deployment to continue. For new deployments only (not scaling), automatic detection of the Heat agents can be used. Use the Overcloud node roles defined in the “roles_data.yaml” configuration file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2019</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">12</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="n">Z</span> <span class="p">[</span><span class="n">overcloud</span><span class="o">.</span><span class="n">Compute</span><span class="o">.</span><span class="mf">0.</span><span class="n">NovaCompute</span><span class="p">]:</span> <span class="n">CREATE_IN_PROGRESS</span>  <span class="n">state</span> <span class="n">changed</span>
<span class="mi">2019</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span> <span class="mi">12</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">01</span><span class="n">Z</span> <span class="p">[</span><span class="n">overcloud</span><span class="o">.</span><span class="n">Controller</span><span class="o">.</span><span class="mf">0.</span><span class="n">Controller</span><span class="p">]:</span> <span class="n">CREATE_IN_PROGRESS</span>  <span class="n">state</span> <span class="n">changed</span>
</pre></div>
</div>
</li>
<li><p>Then run the <code class="docutils literal notranslate"><span class="pre">get-occ-config</span></code> script on the Undercloud to configure the service.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">OVERCLOUD_ROLES</span><span class="o">=</span><span class="s2">&quot;ControllerDeployedServer ComputeDeployedServer&quot;</span>
$ <span class="nb">export</span> <span class="nv">ControllerDeployedServer_hosts</span><span class="o">=</span><span class="s2">&quot;&lt;CONTROLLER0_IP&gt; &lt;CONTROLLER1_IP&gt; &lt;CONTROLLER2_IP&gt;&quot;</span>
$ <span class="nb">export</span> <span class="nv">ComputeDeployedServer_hosts</span><span class="o">=</span><span class="s2">&quot;&lt;COMPUTE0_IP&gt; &lt;COMPUTE1_IP&gt;&quot;</span>
$ /usr/share/openstack-tripleo-heat-templates/deployed-server/scripts/get-occ-config.sh
</pre></div>
</div>
</li>
</ul>
<p><strong>os-collect-config (Queens, Manual)</strong></p>
<ul>
<li><p>Use the manual method if the automatic one does not work.</p></li>
<li><p>Generate metadata URLs for the Overcloud nodes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="k">for</span> STACK <span class="k">in</span> <span class="k">$(</span>openstack stack resource list -n5 --filter <span class="nv">name</span><span class="o">=</span>deployed-server -c stack_name -f value overcloud<span class="k">)</span> <span class="p">;</span> <span class="k">do</span> <span class="nv">STACKID</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="nv">$STACK</span> <span class="p">|</span> cut -d <span class="s1">&#39;-&#39;</span> -f2,4 --output-delimiter <span class="s2">&quot; &quot;</span><span class="k">)</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">&quot;== Metadata URL for </span><span class="nv">$STACKID</span><span class="s2"> ==&quot;</span> <span class="p">;</span> openstack stack resource metadata <span class="nv">$STACK</span> deployed-server <span class="p">|</span> jq -r <span class="s1">&#39;.[&quot;os-collect-config&quot;].request.metadata_url&#39;</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="k">done</span>
</pre></div>
</div>
</li>
<li><p>On the Overcloud nodes, add the correct metadata URL to the os-collect-config configuration, and then restart the service.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo rm /usr/libexec/os-apply-config/templates/etc/os-collect-config.conf
$ sudo vi /usr/libexec/os-apply-config/templates/etc/os-collect-config.conf
</pre></div>
</div>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[DEFAULT]</span>
<span class="na">collectors</span><span class="o">=</span><span class="s">request</span>
<span class="na">command</span><span class="o">=</span><span class="s">os-refresh-config</span>
<span class="na">polling_interval</span><span class="o">=</span><span class="s">30</span>

<span class="k">[request]</span>
<span class="na">metadata_url</span><span class="o">=</span><span class="s">&lt;METADATA_URL&gt;</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo systemctl restart os-collect-config
</pre></div>
</div>
</li>
<li><p>If issues are encountered with the manual process, stop the service and then run the os-collect-config command and force it to use the primary configuration file.</p></li>
</ul>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo rm -rf /var/lib/heat-config/deployed/*
$ sudo systemctl stop os-collect-config
$ sudo os-collect-config --debug --force --one-time --config-file /etc/os-collect-config.conf
</pre></div>
</div>
</div></blockquote>
<p>[36][37]</p>
</div>
</div>
<div class="section" id="operations">
<h2><a class="toc-backref" href="#id26">Operations</a><a class="headerlink" href="#operations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="updates-minor">
<h3><a class="toc-backref" href="#id27">Updates (Minor)</a><a class="headerlink" href="#updates-minor" title="Permalink to this headline">¶</a></h3>
<p>Minor updates keep the cloud at the same major OpenStack version. These provide both bug and security fixes.</p>
<p><strong>Undercloud:</strong></p>
<ul class="simple">
<li><p>Update the containers prepare parameters to use the new containers. The template that defines those values should be used for both the Undercloud and Overcloud.</p></li>
<li><p>Update the Undercloud.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack undercloud upgrade
</pre></div>
</div>
<p><strong>Overcloud:</strong></p>
<ul class="simple">
<li><p>Regenerate the Heat templates if they were also manually generated for the initial deployment.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ ./tools/process-templates.py -o ~/templates/
</pre></div>
</div>
<ul class="simple">
<li><p>Update the Heat stack configuration using the same arguments from <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>. This will disable tasks that should not run during an update.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ opentack overcloud update prepare &lt;OVERCLOUD_DEPLOYMENT_ARGUMENTS&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Run the <code class="docutils literal notranslate"><span class="pre">update_tasks</span></code> and <code class="docutils literal notranslate"><span class="pre">post_update_tasks</span></code> from config-download.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud update run
</pre></div>
</div>
<ul class="simple">
<li><p>Re-enable the tasks that were disabled by the prepare step.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ opentack overcloud upgrade converge &lt;OVERCLOUD_DEPLOYMENT_ARGUMENTS&gt;
</pre></div>
</div>
<p>[68]</p>
</div>
<div class="section" id="upgrades-major">
<h3><a class="toc-backref" href="#id28">Upgrades (Major)</a><a class="headerlink" href="#upgrades-major" title="Permalink to this headline">¶</a></h3>
<p>Both the Undercloud and Overcloud must first be updated to the latest minor release before attempting an upgrade. The upgrade process is very similar to the update process.</p>
<p><strong>Undercloud:</strong></p>
<ul class="simple">
<li><p>Update the containers prepare parameters to use the new containers. The template that defines those values should be used for both the Undercloud and Overcloud.</p></li>
<li><p>Upgrade the Undercloud.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack undercloud upgrade
</pre></div>
</div>
<p><strong>Overcloud:</strong></p>
<ul class="simple">
<li><p>Regenerate the Heat templates if they were also manually generated for the initial deployment.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ ./tools/process-templates.py -o ~/templates/
</pre></div>
</div>
<ul class="simple">
<li><p>Update the Heat stack configuration using the same arguments from <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>. This will disable tasks that should not run during an upgrade.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ opentack overcloud upgrade prepare &lt;OVERCLOUD_DEPLOYMENT_ARGUMENTS&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Upgrade each Controller node, one at a time.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud upgrade run --limit overcloud-controller-0
$ openstack overcloud upgrade run --limit overcloud-controller-1
$ openstack overcloud upgrade run --limit overcloud-controller-2
</pre></div>
</div>
<ul class="simple">
<li><p>Upgrade all of the Compude nodes.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud upgrade run --limit Compute
</pre></div>
</div>
<ul class="simple">
<li><p>Re-enable the tasks that were disabled by the prepare step.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ opentack overcloud upgrade converge &lt;OVERCLOUD_DEPLOYMENT_ARGUMENTS&gt;
</pre></div>
</div>
<p>[69]</p>
</div>
<div class="section" id="add-a-compute-node">
<h3><a class="toc-backref" href="#id29">Add a Compute Node</a><a class="headerlink" href="#add-a-compute-node" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>From the Undercloud, create a <cite>instackenv.json</cite> file describing the new node. Import the file using Ironic.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">source</span> ~/stackrc
$ openstack baremetal import --json ~/instackenv.json
</pre></div>
</div>
<ul class="simple">
<li><p>Automatically configure it to use the existing kernel and ramdisk for PXE booting.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal configure boot
</pre></div>
</div>
<ul class="simple">
<li><p>Set the new node to the “manageable” state. Then introspect the new node so Ironic can automatically determine it’s resources and hardware information.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node manage &lt;NODE_UUID&gt;
$ openstack overcloud node introspect &lt;NODE_UUID&gt; --provided
</pre></div>
</div>
<ul class="simple">
<li><p>Configure the node to be a compute node.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node <span class="nb">set</span> --property <span class="nv">capabilities</span><span class="o">=</span><span class="s1">&#39;profile:compute,boot_option:local&#39;</span> &lt;NODE_UUID&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Update the compute node scale using a Heat template.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">ComputeCount</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;NEW_COMPUTE_COUNT&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Redeploy the Overcloud while specifying the number of compute nodes that should exist in total after it is complete. The <cite>ComputeCount</cite> parameter in the Heat templates should also be increased to reflect it’s new value.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --templates ~/templates &lt;DEPLOYMENT_OPTIONS&gt;
</pre></div>
</div>
<p>[19]</p>
</div>
<div class="section" id="remove-a-compute-node">
<h3><a class="toc-backref" href="#id30">Remove a Compute Node</a><a class="headerlink" href="#remove-a-compute-node" title="Permalink to this headline">¶</a></h3>
<p>Disable the Nova services.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ . ~/overcloudrc
$ openstack compute service <span class="nb">set</span> &lt;NODE&gt; nova-compute --disable
</pre></div>
</div>
<p>Delete the Compute node and include the templates used during deployment. [49]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ . ~/strackrc
$ openstack overcloud node delete --stack overcloud --templates ~/templates &lt;NODE&gt;
</pre></div>
</div>
<p>Delete additional services related to the Compute node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ . ~/overcloudrc
$ openstack compute service delete &lt;NODE&gt;
$ openstack network agent delete &lt;NODE&gt;
$ openstack resource provider delete &lt;NDOE&gt;
</pre></div>
</div>
<p>Decrease the <code class="docutils literal notranslate"><span class="pre">ComputeCount</span></code> in the Heat parameters used for the deployment.</p>
<p>[50]</p>
</div>
<div class="section" id="rebooting-the-cloud">
<h3><a class="toc-backref" href="#id31">Rebooting the Cloud</a><a class="headerlink" href="#rebooting-the-cloud" title="Permalink to this headline">¶</a></h3>
<p>Servers hosting the cloud services will eventually need to go through a reboot to load up the latest patches for kernels, glibc, and other vital system components. This is the order in which servers should be restarted, one node at a time.</p>
<ul>
<li><p>Undercloud</p></li>
<li><p>Controller</p>
<ul>
<li><p>Stop clustered services on a controller node before rebooting.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo pcs cluster stop
</pre></div>
</div>
</li>
<li><p>Reconnect to the clustered services after the reboot.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo pcs cluster start
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Ceph</p>
<ul>
<li><p>Disable rebalancing before rebooting.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo ceph osd <span class="nb">set</span> noout
$ sudo ceph osd <span class="nb">set</span> norebalance
</pre></div>
</div>
</li>
<li><p>Enable rebalancing after all of the nodes are back online.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo ceph osd <span class="nb">unset</span> noout
$ sudo ceph osd <span class="nb">unset</span> norebalance
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Compute</p>
<ul>
<li><p>Disallow new instances from spawning on a specific compute node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack compute service list
$ openstack compute service <span class="nb">set</span> &lt;COMPUTE_HOST&gt; nova-compute --disable
</pre></div>
</div>
</li>
<li><p>Live migrate all instances off of that compute node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ nova host-evacuate-live &lt;COMPUTE_HOST&gt;
</pre></div>
</div>
</li>
<li><p>Verify that all instances have been migrated off before rebooting.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack server list --host &lt;COMPUTE_HOST&gt; --all-projects
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<p>[34]</p>
</div>
<div class="section" id="ansible-playbooks-config-download">
<h3><a class="toc-backref" href="#id32">Ansible Playbooks (config-download)</a><a class="headerlink" href="#ansible-playbooks-config-download" title="Permalink to this headline">¶</a></h3>
<p>The Queens release of TripleO featured optional usage of Ansible configuration management via a feature called <code class="docutils literal notranslate"><span class="pre">config-download</span></code>. It has been the default method of deployment since Rocky where it also added official support for deploying Ceph and Octavia. TripleO will log into the Overcloud nodes and configure a <code class="docutils literal notranslate"><span class="pre">tripleo-admin</span></code> user that will be used by Ansible for running updates and upgrades [39]. Use these arguments to enable config-download on Queens.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --templates ~/templates --config-download -e /usr/share/openstack-tripleo-heat-templates/environments/config-download-environment.yaml --overcloud-ssh-user heat-admin --overcloud-ssh-key ~/.ssh/id_rsa
</pre></div>
</div>
<p>In Queens, for reverting back to using Heat for the deployment, remove the config-download arguments and include an environment file with these resource registries [56]:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::SoftwareDeployment</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::StructuredDeployment</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::DeploymentSteps</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::StructuredDeploymentGroup</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::Heat::SoftwareDeployment</span><span class="p p-Indicator">:</span>  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Heat::SoftwareDeployment</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::Heat::StructuredDeployment</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Heat::StructuredDeployment</span>
</pre></div>
</div>
<p>The latest playbooks and variables used to deploy the Overcloud can be downloaded to the current working directory.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud config download
</pre></div>
</div>
<p>All of that Ansible content is stored in a local git repository at <code class="docutils literal notranslate"><span class="pre">/var/lib/mistral/overcloud/</span></code>. The log files of the last config-download run are found at <code class="docutils literal notranslate"><span class="pre">/var/lib/mistral/overcloud/ansible.log</span></code> and <code class="docutils literal notranslate"><span class="pre">/var/lib/mistral/overcloud/ansible-errors.json</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">deploy_steps_playbook.yaml</span></code> file is the primary playbook that executes all of the deployment playbooks. Before running the playbook, the tripleo-admin account needs to be configured on the Overcloud nodes. This can be done manually if the playbooks for the deployment or scale-up are used manually (ex., not using <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>) [36]:</p>
<ul>
<li><p>Queens:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">OVERCLOUD_HOSTS</span><span class="o">=</span><span class="s2">&quot;&lt;IP1&gt; &lt;IP2&gt;&quot;</span>
$ /usr/share/openstack-tripleo-heat-templates/deployed-server/scripts/enable-ssh-admin.sh
</pre></div>
</div>
</li>
<li><p>Train:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud admin authorize
</pre></div>
</div>
</li>
</ul>
<p>A static inventory can be created using the available dynamic inventory script <code class="docutils literal notranslate"><span class="pre">tripleo-ansible-inventory</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tripleo-ansible-inventory --ansible_ssh_user tripleo-admin --static-yaml-inventory tripleo-ansible-inventory.yaml
</pre></div>
</div>
<p>Tags (as of Stein):</p>
<ul class="simple">
<li><p>always</p></li>
<li><p>facts</p></li>
<li><p>common_roles</p></li>
<li><p>container_config</p></li>
<li><p>container_config_scripts</p></li>
<li><p>container_config_tasks</p></li>
<li><p>container_image_prepare</p></li>
<li><p>container_startup_configs</p></li>
<li><p>external_deploy_steps</p></li>
<li><p>external_post_deploy_steps</p></li>
<li><p>host_config</p></li>
<li><p>host_prep_steps</p></li>
<li><p>overcloud</p></li>
<li><p>pre_deploy_steps</p></li>
<li><p>step0</p></li>
<li><p>step1</p></li>
<li><p>step2</p></li>
<li><p>step3</p></li>
<li><p>step4</p></li>
<li><p>step5</p></li>
<li><p>tripleo_ssh_known_hosts</p></li>
</ul>
<p>For only updating the Ansible playbooks based on the Heat templates, pass the <code class="docutils literal notranslate"><span class="pre">--stack-only</span></code> argument to the Overcloud deployment. They can then be downloaded and executed manually.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --stack-only
</pre></div>
</div>
<p>[41]</p>
<p>If the playbooks are already generated from a successful STACK_CREATE of the Overcloud, then the deployment can be ran again using only the playbooks (skipping the need to parse the Heat templates).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --config-download-only
</pre></div>
</div>
<p>Fact caching is enabled by default which can lead to issues with re-deployment. This can be manually cleared out on the Undercloud.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo rm -rf /var/lib/mistral/ansible_fact_cache/*
</pre></div>
</div>
<p>Force re-running tasks that only run during the initial deployment by using the <code class="docutils literal notranslate"><span class="pre">force=true</span></code> variable. The example below will run the network configuration tasks again.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ansible-playbook -i inventory.yaml --become --tags facts,post_deploy_steps deploy_steps_playbook.yaml -e <span class="nv">force</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
<div class="section" id="manual">
<h4><a class="toc-backref" href="#id33">Manual</a><a class="headerlink" href="#manual" title="Permalink to this headline">¶</a></h4>
<p>The deployment of OpenStack services can be done manually outside of TripleO. The Ansible playbooks are generated, the inventory file is created, SSH keys are configured, and then the playbooks can be run to do the actual deployment. This is useful for debugging the deployment or running it on a server that is not the Undercloud.</p>
<ul>
<li><p>Generate the Ansible playbooks by rendering the Overcloud Heat stack.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --stack-only ...
</pre></div>
</div>
</li>
<li><p>Download the deployment playbooks. Then change into the directory it creates.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud config download
$ <span class="nb">cd</span> /home/stack/tripleo-config/overcloud/
</pre></div>
</div>
</li>
<li><p>Generate a static inventory file.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tripleo-ansible-inventory --static-yaml-inventory tripleo-ansible-inventory.yaml
</pre></div>
</div>
</li>
<li><p>Copy the private key used to access the “tripleo-admin” user on the Overcloud.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo cp /var/lib/mistral/overcloud/ssh_private_key ./
$ sudo chown stack.stack ssh_private_key
</pre></div>
</div>
</li>
<li><p>Setup the authorized SSH keys for the “tripleo-admin” user on the Overcloud nodes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud admin authorize
</pre></div>
</div>
</li>
<li><p>Run the Overcloud deployment. The “deploy_steps_playbook.yaml” is the primary playbook that combines all of the other playbooks into one.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ansible-playbook --inventory tripleo-ansible-inventory.yaml --key-file ssh_private_key --become deploy_steps_playbook.yaml
</pre></div>
</div>
</li>
</ul>
<p>[41]</p>
</div>
</div>
</div>
<div class="section" id="configurations">
<h2><a class="toc-backref" href="#id34">Configurations</a><a class="headerlink" href="#configurations" title="Permalink to this headline">¶</a></h2>
<p>These are configurations specific to Overcloud deployments using TripleO. Custom settings are defined using a YAML Heat template.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">&lt;KEY&gt;</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;VALUE&gt;</span>
</pre></div>
</div>
<div class="section" id="composable-roles">
<h3><a class="toc-backref" href="#id35">Composable Roles</a><a class="headerlink" href="#composable-roles" title="Permalink to this headline">¶</a></h3>
<p>Roles in TripleO (not to be confused with Ansible roles) are used to define what Linux and OpenStack services will be configured on an Overcloud node. Each Overcloud node is assigned a role based on profile tagging.</p>
<p>View the default roles.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ less /usr/share/openstack-tripleo-heat-templates/roles_data.yaml
</pre></div>
</div>
<p>View the available roles and see what services are set for each role.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud roles list
$ openstack overcloud roles show &lt;ROLE&gt;
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ls -1 /usr/share/openstack-tripleo-heat-templates/roles/
$ less /usr/share/openstack-tripleo-heat-templates/roles/&lt;ROLE&gt;.yaml
</pre></div>
</div>
<p>Create a roles_data file that contains only the roles that will be used for deployment.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud roles generate &lt;ROLE1&gt; &lt;ROLE2&gt; &gt; roles_data_custom.yaml
</pre></div>
</div>
<p>Use a specified roles_data file to generate a new set of TripleO Heat Templates (THT) based on the roles that are defined.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ ./tools/process-templates.py -r roles_data.yaml -o ~/templates/
</pre></div>
</div>
<p>Services can be disabled from being deployed and configured on the Overcloud one of two ways.</p>
<ol class="arabic simple">
<li><p>Remove the service entry from the relevant role in the <code class="docutils literal notranslate"><span class="pre">roles_data.yaml</span></code>. Then run <code class="docutils literal notranslate"><span class="pre">process-templates.py</span></code> again to regenerate the TripleO Heat Templates.</p></li>
<li><p>Create a new Heat template file and map the service to <code class="docutils literal notranslate"><span class="pre">OS::Heat::None</span></code>.</p></li>
</ol>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::&lt;SERVICE&gt;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::None</span>
</pre></div>
</div>
<p>Most services are mapped to a THT deployment template in <code class="docutils literal notranslate"><span class="pre">/usr/share/openstack-tripleo-heat-templates/deployment/</span></code>. Service deployment templates are named <code class="docutils literal notranslate"><span class="pre">*-ansible.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">*-puppet.yaml</span></code> based on what configuration management is used to deploy the service.</p>
<p>Even if a role has a service listed, the default may be set to have it be disabled. To re-enable the service, it must be mapped to the deployment template. A <code class="docutils literal notranslate"><span class="pre">grep</span></code> can help find the related mapping.</p>
<p>Syntax:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ grep -r OS::TripleO::Services::&lt;SERVICE&gt;: /usr/share/openstack-tripleo-heat-templates/ <span class="p">|</span> grep -v OS::Heat::None
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::&lt;SERVICE&gt;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;DEPLOYMENT_TEMPLATE&gt;</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ grep -r OS::TripleO::Services::MySQL: /usr/share/openstack-tripleo-heat-templates/ <span class="p">|</span> grep -v OS::Heat::None
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::MySQL</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">deployment/database/mysql-container-puppet.yaml</span>
</pre></div>
</div>
<p>Additional service defaults are set in these files:</p>
<ul class="simple">
<li><p>Undercloud: /usr/share/openstack-tripleo-heat-templates/environments/undercloud.yaml</p></li>
<li><p>Overcloud: /usr/share/openstack-tripleo-heat-templates/overcloud-resource-registry-puppet.j2.yaml</p></li>
</ul>
<p>[63][64]</p>
<p>Some variables, such as RhsmVars, can be set on a per-role basis. These will override defaults values set by the service templates. These can be set in the composable role definition file or a Heat environment template.</p>
<p>Role:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;COMPOSABLE_ROLE_NAME&gt;</span>
  <span class="nt">RoleParametersDefault</span><span class="p">:</span>
    <span class="nt">&lt;KEY&gt;</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;VALUE&gt;</span>
</pre></div>
</div>
<p>Heat:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">&lt;COMPOSABLE_ROLE_NAME&gt;Parameters</span><span class="p">:</span>
    <span class="nt">&lt;KEY&gt;</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;VALUE&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="openstack-services">
<h3><a class="toc-backref" href="#id36">OpenStack Services</a><a class="headerlink" href="#openstack-services" title="Permalink to this headline">¶</a></h3>
<p>Configuration options for OpenStack services can be defined using ExtraConfig.</p>
<ul class="simple">
<li><p>AllNodesExtraConfig or ExtraConfig = Apply the settings to all nodes.</p></li>
<li><p>&lt;ROLE&gt;ExtraConfig = Apply the settings to all nodes deployed using the composable role.</p></li>
</ul>
<p>There are different deployment hooks used for configuration.</p>
<ul class="simple">
<li><p>ExtraConfigPre = Before Puppet.</p></li>
<li><p>ExtraConfig = During Puppet. Use this one for changing Puppet settings.</p></li>
<li><p>ExtraConfigPost = After Puppet.</p></li>
</ul>
<p>The configuration for OpenStack services are handled by Puppet (not Ansible).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ grep -r &lt;VARIABLE&gt; /usr/share/openstack-tripleo-heat-templates/deployment/*/*-puppet.yaml
$ grep -r &lt;VARIABLE&gt; /usr/share/openstack-puppet/modules/
</pre></div>
</div>
<p>The variables defined in TripleO Heat templates will be rendered as Puppet Hieradata to this location inside the OpenStack service’s container and then applied by Puppet:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">var</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">config</span><span class="o">-</span><span class="n">data</span><span class="o">/&lt;</span><span class="n">OPENSTACK_SERVICE</span><span class="o">&gt;/</span><span class="n">etc</span><span class="o">/</span><span class="n">puppet</span><span class="o">/</span><span class="n">hieradata</span><span class="o">/</span><span class="n">service_configs</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>This is the order in how to attempt modifying a variable. If it is not possible, then try the next one down. The deployment will fail if there is a duplicate declaration of a variable.</p>
<ol class="arabic simple">
<li><p>Use a Heat parameter if exposed via a deployment template</p></li>
<li><p>Use the Puppet class to override a value.</p></li>
<li><p>Use the generic Puppet <code class="docutils literal notranslate"><span class="pre">config</span></code> class to manually override settings not exposed by Puppet.</p></li>
</ol>
<p>Not all of the Puppet variables for OpenStack service configuration are exposed as Heat parameters. These can still be manually set. Puppet manifests define the default variables that are set. These also show what Puppet dictionary variables are used for each configuration.</p>
<p>All of the service manifests can be found here: <code class="docutils literal notranslate"><span class="pre">/usr/share/openstack-puppet/modules/${OPENSTACK_SERVICE}/manifests/</span></code>. The OpenStack services on <a class="reference external" href="https://opendev.org/openstack?q=puppet&amp;tab=&amp;sort=recentupdate">OpenDev.org each have a related puppet-&lt;SERVICE&gt; repository</a> that hosts the Puppet manifests. Miscellaneous service configuration are grouped into the <a class="reference external" href="https://opendev.org/openstack/puppet-tripleo">puppet-tripleo</a> project. Other Puppet dependencies and default settings are provided by the <a class="reference external" href="https://opendev.org/openstack/puppet-openstacklib">puppet-openstacklib</a> project.</p>
<p>The Puppet class for a service is typically named using the convention <code class="docutils literal notranslate"><span class="pre">&lt;OPENSTACK_SERVICE&gt;::&lt;MANIFEST&gt;</span></code>. The actual class name will be listed in the manifest files. Below shows how <code class="docutils literal notranslate"><span class="pre">awk</span></code> can be used to extract the class names along with the exposed variables that can be modified.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-puppet/modules/<span class="si">${</span><span class="nv">OPENSTACK_SERVICE</span><span class="si">}</span>/manifests/
$ awk <span class="s1">&#39;/^class/,/)/&#39;</span> ./*.pp <span class="c1"># Search the top-level directory.</span>
$ awk <span class="s1">&#39;/^class/,/)/&#39;</span> ./*/*.pp <span class="c1"># Search in all of the sub-directories.</span>
</pre></div>
</div>
<p>Once the correct class and variable are found, the setting can be defined in a Heat template.</p>
<p>Syntax:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">&lt;ROLE&gt;ExtraConfig</span><span class="p">:</span>
    <span class="c1"># The primary manifest handles at least the primary configuration file.</span>
    <span class="l l-Scalar l-Scalar-Plain">&lt;PUPPET_CLASS&gt;::&lt;VARIABLE&gt;:</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;VALUE&gt;</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="c1"># Only apply this configuration to Overcloud nodes deployed using the &quot;Controller&quot; role.</span>
  <span class="nt">ControllerExtraConfig</span><span class="p">:</span>
    <span class="c1"># The class name is &quot;keystone::wsgi::apache&quot;.</span>
    <span class="c1"># The variable exposed by the class is &quot;workers&quot;.</span>
    <span class="c1"># The value is overridden and set to &quot;4&quot; (instead of the default &quot;$::os_workers_keystone&quot;).</span>
    <span class="l l-Scalar l-Scalar-Plain">keystone::wsgi::apache::workers</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</pre></div>
</div>
<p>Settings that are not handled by Puppet resources can be overridden manually. The dictionary name for each configuration file is defined in <code class="docutils literal notranslate"><span class="pre">manifests/config.pp</span></code> in the <code class="docutils literal notranslate"><span class="pre">&lt;OPENSTACK_SERVICE&gt;::config</span></code> class. For the main configuration file, the naming convention for the variable to set is <code class="docutils literal notranslate"><span class="pre">&lt;OPENSTACK_SERVICE&gt;::config::&lt;OPENSTACK_SERVICE&gt;_config</span></code>.</p>
<p>Syntax:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">&lt;ROLE&gt;ExtraConfig</span><span class="p">:</span>
    <span class="l l-Scalar l-Scalar-Plain">&lt;PUPPET_CLASS&gt;::&lt;VARIABLE&gt;</span><span class="p p-Indicator">:</span>
      <span class="s">&#39;&lt;SECTION&gt;/&lt;KEY&gt;&#39;</span><span class="p p-Indicator">:</span>
        <span class="nt">value</span><span class="p">:</span> <span class="s">&#39;&lt;VALUE&gt;&#39;</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">UndercloudExtraConfig</span><span class="p">:</span>
    <span class="l l-Scalar l-Scalar-Plain">heat::config::heat_config</span><span class="p p-Indicator">:</span>
      <span class="s">&#39;DEFAULT/stack_action_timeout&#39;</span><span class="p p-Indicator">:</span>
        <span class="nt">value</span><span class="p">:</span> <span class="s">&#39;7200&#39;</span>
    <span class="l l-Scalar l-Scalar-Plain">heat::config::heat_api_paste_ini</span><span class="p p-Indicator">:</span>
      <span class="s">&#39;filter:authtoken/admin_user&#39;</span><span class="p p-Indicator">:</span>
        <span class="nt">value</span><span class="p">:</span> <span class="s">&#39;heat2&#39;</span>
</pre></div>
</div>
<p>[32]</p>
<p>The root MySQL account password can be configured for the Undercloud and/or Overcloud.</p>
<p>Undercloud:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># undercloud.conf</span>
<span class="k">[auth]</span>
<span class="na">undercloud_db_password</span><span class="o">=</span><span class="s">&lt;PASSWORD&gt;</span>
</pre></div>
</div>
<p>Overcloud:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">MysqlRootPassword</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;PASSWORD&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="networks">
<h3><a class="toc-backref" href="#id37">Networks</a><a class="headerlink" href="#networks" title="Permalink to this headline">¶</a></h3>
<p>When no network template is defined, VLANs are not used and instead each network will be assigned different subnets. Networks are only created using the <code class="docutils literal notranslate"><span class="pre">STACK_CREATE</span></code> phase and will not run during the <code class="docutils literal notranslate"><span class="pre">STACK_UPDATE</span></code> phase unless the Heat parameter <code class="docutils literal notranslate"><span class="pre">NetworkDeploymentActions:</span> <span class="pre">['CREATE','UPDATE']</span></code> is set.</p>
<div class="section" id="interfaces-os-net-config">
<h4><a class="toc-backref" href="#id38">Interfaces (os-net-config)</a><a class="headerlink" href="#interfaces-os-net-config" title="Permalink to this headline">¶</a></h4>
<p>os-net-config is developed as part of TripleO and used to configure the network interfaces, DNS nameservers, IP addresses, and routes on all nodes (Undercloud and Overcloud).</p>
<p>Render the TripleO Heat Templates (THT) to view the static net-config files. These provide different layouts and examples for how to configure the networking interfaces.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /usr/share/openstack-tripleo-heat-templates/
$ mkdir ~/templates/
$ /usr/share/openstack-tripleo-heat-templates/tools/process-templates.py -o ~/templates/
$ <span class="nb">cd</span> ~/templates/
$ ls -1 net-config-*
net-config-bond.yaml
net-config-bridge.yaml
net-config-linux-bridge.yaml
net-config-noop.yaml
net-config-standalone.yaml
net-config-static-bridge-nic-two-only.yaml
net-config-static-bridge-two-nics.yaml
net-config-static-bridge-with-external-dhcp.yaml
net-config-static-bridge.yaml
net-config-static.yaml
net-config-undercloud.yaml
</pre></div>
</div>
<p>Set a custom net-config file on a per-role basis by overriding the resource registry for network configuration.</p>
<p>Syntax:</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::&lt;ROLE&gt;::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;PATH_TO&gt;/&lt;NIC_CONFIG_TEMPLATE&gt;.yaml</span>
</pre></div>
</div>
</div></blockquote>
<p>Example:</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Controller::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-bond.yaml</span>
</pre></div>
</div>
</div></blockquote>
<p>A network environment template can be used to set related TripleO-provided net-config settings for all roles.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ls -1 environments/net-*
environments/net-2-linux-bonds-with-vlans.yaml
environments/net-bond-with-vlans-no-external.yaml
environments/net-bond-with-vlans.yaml
environments/net-dpdkbond-with-vlans.yaml
environments/net-multiple-nics-vlans.yaml
environments/net-multiple-nics.yaml
environments/net-noop.yaml
environments/net-single-nic-linux-bridge-with-vlans.yaml
environments/net-single-nic-with-vlans-no-external.yaml
environments/net-single-nic-with-vlans.yaml
$ openstack overcloud deploy -e ~/templates/environments/&lt;NETWORK_ENVIRONMENT&gt;.yaml
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">$network_config</span></code> dictionary stores the entire os-net-config configuration. The <a class="reference external" href="https://opendev.org/openstack/tripleo-heat-templates/src/branch/master/network/scripts/run-os-net-config.sh">run-os-net-config.sh</a> script will find and replace all references to <code class="docutils literal notranslate"><span class="pre">interface_name</span></code> with the Heat parameter value for <code class="docutils literal notranslate"><span class="pre">NeutronPublicInterface</span></code> and also replaces <code class="docutils literal notranslate"><span class="pre">bridge_name</span></code> with <code class="docutils literal notranslate"><span class="pre">NeutronPhysicalBridge</span></code>. The script will default any interface not defined in the os-net-config settings to use DHCP. If DHCP does not work, then the “network” service may fail to restart during the Overcloud deployment leading to an inaccessible Overcloud.</p>
<p>net-config THT template:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">resources</span><span class="p">:</span>
  <span class="nt">OsNetConfigImpl</span><span class="p">:</span>
    <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::SoftwareConfig</span>
    <span class="nt">properties</span><span class="p">:</span>
      <span class="nt">group</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">script</span>
      <span class="nt">config</span><span class="p">:</span>
        <span class="nt">str_replace</span><span class="p">:</span>
          <span class="nt">template</span><span class="p">:</span>
            <span class="nt">get_file</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">network/scripts/run-os-net-config.sh</span>
          <span class="nt">params</span><span class="p">:</span>
            <span class="nt">$network_config</span><span class="p">:</span>
</pre></div>
</div>
<p>The configuration file is stored on every node at <code class="docutils literal notranslate"><span class="pre">/etc/os-net-config/config.yaml</span></code>. Settings from a custom file can be manually applied for testing by running <code class="docutils literal notranslate"><span class="pre">os-net-config</span> <span class="pre">-c</span> <span class="pre">&lt;OS_NET_CONFIG_FILE&gt;.yaml</span> <span class="pre">-v</span> <span class="pre">--detailed-exit-codes</span> <span class="pre">--cleanup</span></code>.</p>
<p>Every network object that can be managed is known as a <code class="docutils literal notranslate"><span class="pre">type</span></code>. Common types include: interface, ovs_bond, ovs_bridge, route_rule, team, and vlan. The full list of valid parameters are listed in the <a class="reference external" href="https://opendev.org/openstack/os-net-config/src/branch/master/os_net_config/schema.yaml">schema.yaml</a> file of os-net-config.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">interface</span></code> type accepts passing nic1 (eth0), nic2 (eth1), etc. as the <code class="docutils literal notranslate"><span class="pre">name</span></code> attribute for dynamically associating an interface. Alternatively, the actual name of the network interface, such as eth0 or eth1, can be defined.</p>
<p>Below are sample configurations that can be defined in a net-config THT template. They will render out the Heat parameters during the deployment.</p>
<p>DHCP:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">$network_config</span><span class="p">:</span>
  <span class="nt">network_config</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interface</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nic1</span>
      <span class="nt">use_dhcp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>Static:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">$network_config</span><span class="p">:</span>
  <span class="nt">network_config</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interface</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">network_interface</span>
      <span class="nt">addresses</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_netmask</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">192.168.122.101/24</span>
      <span class="nt">dns_servers</span><span class="p">:</span>
        <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DnsServers</span>
      <span class="nt">domain</span><span class="p">:</span>
        <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">DnsSearchDomains</span>
</pre></div>
</div>
<p>Control Plane IP Address:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">$network_config</span><span class="p">:</span>
  <span class="nt">network_config</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interface</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">eth3</span>
      <span class="nt">addresses</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">ip_netmask</span><span class="p">:</span>
            <span class="nt">list_join</span><span class="p">:</span>
              <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/</span>
              <span class="p p-Indicator">-</span> <span class="p p-Indicator">-</span> <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ControlPlaneIp</span>
                <span class="p p-Indicator">-</span> <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ControlPlaneSubnetCidr</span>
      <span class="nt">routes</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">default</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
          <span class="nt">next_hop</span><span class="p">:</span>
            <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ControlPlaneDefaultRoute</span>
</pre></div>
</div>
<p>Bridge on a Bond:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">$network_config</span><span class="p">:</span>
  <span class="nt">network_config</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ovs_bridge</span>
      <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bridge_interface</span>
      <span class="nt">use_dhcp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
      <span class="nt">members</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ovs_bond</span>
          <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bond0</span>
          <span class="nt">ovs_options</span><span class="p">:</span>
            <span class="nt">get_param</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">BondInterfaceOvsOptions</span>
          <span class="nt">members</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interface</span>
              <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nic1</span>
            <span class="p p-Indicator">-</span> <span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">interface</span>
              <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nic2</span>
</pre></div>
</div>
<p>[61]</p>
<p>Only Open vSwitch (OVS) and Open Virtual Networking (OVN) are supported for bridge types. Linux Bridge is not tested in CI nor supported by Red Hat. RHEL 8 removed support for the legacy bridge utilities. [62]</p>
</div>
<div class="section" id="vlans">
<h4><a class="toc-backref" href="#id39">VLANs</a><a class="headerlink" href="#vlans" title="Permalink to this headline">¶</a></h4>
<p>There are 6 different types of networks in a standard TripleO deployment using a VLANs template.</p>
<ul class="simple">
<li><p>External = The external network that can access the Internet. This is used for the Horizon dashboard, public API endpoints, and floating IP addresses. Default VLAN: 10.</p></li>
<li><p>Internal = Default VLAN: 20.</p></li>
<li><p>Storage = Default VLAN: 30.</p></li>
<li><p>StorageMgmt = Default VLAN: 40</p></li>
<li><p>Tenant = Default VLAN: 50</p></li>
<li><p>Management = Default VLAN: 60.</p></li>
</ul>
<p>The VLANs need to be trunked on the switch. A 7th native VLAN should also be configured on the switch for the provisioning network.</p>
</div>
<div class="section" id="ip-addressing">
<h4><a class="toc-backref" href="#id40">IP Addressing</a><a class="headerlink" href="#ip-addressing" title="Permalink to this headline">¶</a></h4>
<p>Configure the network CIDRs, IP address ranges to allocation, and VLAN tags.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">NETWORK_TYPE</span><span class="o">&gt;</span><span class="n">NetCidr</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">CIDR</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">NETWORK_TYPE</span><span class="o">&gt;</span><span class="n">AllocationPools</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">start</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">START_IP</span><span class="o">&gt;</span>
    <span class="n">end</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">END_IP</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">NETWORK_TYPE</span><span class="o">&gt;</span><span class="n">NetworkVlanID</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">VLAN_ID</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Configure these settings to match the IP address that the Undercloud is configured to use for provisioning. The default value is <code class="docutils literal notranslate"><span class="pre">192.168.24.1</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ControlPlaneSubnetCidr</span><span class="p">:</span> <span class="s1">&#39;24&#39;</span>
<span class="n">ControlPlaneDefaultRoute</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">UNDERCLOUD_IP_OR_ROUTER</span><span class="o">&gt;</span>
<span class="n">EC2MetadataIp</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">UNDERCLOUD_IP</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="public">
<h4><a class="toc-backref" href="#id41">Public</a><a class="headerlink" href="#public" title="Permalink to this headline">¶</a></h4>
<p>Configure the Overcloud access to the public Internet. Define the default router for the External network, DNS resolvers, and the NTP servers. It is important the DNS is setup correctly because if chronyc fails to resolve the NTP servers then it will not try to resolve them again. DNS is also required to download and install additional TripleO packages.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ExternalInterfaceDefaultRoute</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PUBLIC_DEFAULT_GATEWAY_ADDRESS</span><span class="o">&gt;</span>
<span class="n">DnsServers</span><span class="p">:</span>
  <span class="o">-</span> <span class="mf">10.5</span><span class="o">.</span><span class="mf">30.160</span>
  <span class="o">-</span> <span class="mf">10.11</span><span class="o">.</span><span class="mf">5.19</span>
<span class="n">NtpServer</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">clock</span><span class="o">.</span><span class="n">redhat</span><span class="o">.</span><span class="n">com</span>
  <span class="o">-</span> <span class="n">clock2</span><span class="o">.</span><span class="n">redhat</span><span class="o">.</span><span class="n">com</span>
</pre></div>
</div>
<p>Define the allowed network tag/tunnel types that Neutron networks use. The Neutron tunnel type is used for internal transmissions between the compute and network nodes. By default, the Neutron network bridge will be attached to <code class="docutils literal notranslate"><span class="pre">br-int</span></code> if left blank. This will configure a provider network. Otherwise, <code class="docutils literal notranslate"><span class="pre">br-ex</span></code> should be specified for self-service networks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NeutronNetworkType</span><span class="p">:</span> <span class="s2">&quot;vxlan,gre,vlan,flat&quot;</span>
<span class="n">NeutronTunnelTypes</span><span class="p">:</span> <span class="s2">&quot;vxlan&quot;</span>
<span class="n">NeutronExternalNetworkBridge</span><span class="p">:</span> <span class="s2">&quot;&#39;&#39;&quot;</span>
</pre></div>
</div>
<p>Define the interface to use for public networks. The <code class="docutils literal notranslate"><span class="pre">NeutronPublicInterface</span></code> (nic1/eth0 by default) will be converted into the an Open vSwitch bridge named based on the value of <code class="docutils literal notranslate"><span class="pre">NeutronPhysicalBridge</span></code> (br-ex by default). Optionally, define a VLAN tag for it. If no IP addressing information is configured for this interface, TripleO will default to configuring DHCP.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NeutronPublicInterface</span><span class="p">:</span> <span class="n">eth1</span>
<span class="n">NeutronPhysicalBridge</span><span class="p">:</span> <span class="n">br0</span>
<span class="n">NeutronPublicInterfaceTag</span><span class="p">:</span> <span class="mi">100</span>
</pre></div>
</div>
<p>Configure bonding interface options, if applicable. Below is an example for LACP.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bonding_options</span><span class="p">:</span> <span class="s2">&quot;mode=802.3ad lacp_rate=slow updelay=1000 miimon=100&quot;</span>
</pre></div>
</div>
<p>Configure the bridge that will be used for public routers and floating IPs. Map it to a user-friendly name that will be used by Neutron resources.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NeutronPhysicalBridge</span><span class="p">:</span> <span class="n">br</span><span class="o">-</span><span class="n">ctlplane</span>
<span class="n">NeutronBridgeMappings</span><span class="p">:</span> <span class="n">datacentre</span><span class="p">:</span><span class="n">br</span><span class="o">-</span><span class="n">ctlplane</span>
</pre></div>
</div>
<p>[31]</p>
</div>
</div>
<div class="section" id="containers">
<h3><a class="toc-backref" href="#id42">Containers</a><a class="headerlink" href="#containers" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Configure the Undercloud to cache container images and serve them to the Overcloud nodes. This caching speeds up the deployment and lowers the amount of Internet bandwidth used. By default, Overcloud nodes will directly get images from the defined public registries. A private registry on the Undercloud will need to be configured as an insecure registry (it does not use a SSL/TLS certificate by default).</p></li>
</ul>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="c1"># undercloud.conf</span>
<span class="k">[DEFAULT]</span>
<span class="na">container_images_file</span> <span class="o">=</span> <span class="s">/home/stack/containers-prepare-parameter.yml</span>
<span class="na">container_insecure_registries</span> <span class="o">=</span> <span class="s">[&#39;192.168.24.1:8787&#39;]</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="c1"># containers-prepare-parameters.yml</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">DockerInsecureRegistryAddress</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">192.168.24.1:8787</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">undercloud.ctlplane.localdomain:8787</span>
  <span class="nt">ContainerImagePrepare</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">push_destination</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Authenticate with a registry. For example, the Red Hat repository that contains the RHOSP container images. [42]</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
<span class="nt">ContainerImageRegistryCredentials</span><span class="p">:</span>
  <span class="nt">registry.redhat.io</span><span class="p">:</span>
    <span class="nt">&lt;RED_HAT_USERNAME&gt;</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;RED_HAT_PASSWORD&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Information on how to define custom registries, set container names, version tags to use, and other related settings can be found <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/container_image_prepare.html">here</a>.</p></li>
<li><p>Custom package repositories and RPMs installed in containers are handled by the <a class="reference external" href="https://opendev.org/openstack/ansible-role-tripleo-modify-image">tripleo-modify-image</a> Ansible role.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">ContainerImagePrepare</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">push_destination</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
    <span class="nt">includes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CONTAINER_NAME&gt;</span>
    <span class="nt">modify_role</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tripleo-modify-image</span>
    <span class="nt">modify_append_tag</span><span class="p">:</span> <span class="s">&quot;-hotfix&quot;</span>
    <span class="nt">modify_vars</span><span class="p">:</span>
      <span class="l l-Scalar l-Scalar-Plain">&lt;TRIPLEO_MODIFY_IMAGES_ROLE_VARIABLES&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="packages">
<h3><a class="toc-backref" href="#id43">Packages</a><a class="headerlink" href="#packages" title="Permalink to this headline">¶</a></h3>
<p>By default, TripleO will not install packages. The standard Overcloud image from RDO already has all of the OpenStack packages installed. When using a custom image or not using Ironic for deploying Overcloud nodes, packages can be configured to be installed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">EnablePackageInstall</span><span class="p">:</span> <span class="n">true</span>
</pre></div>
</div>
<p>A different repository for Overcloud service containers can be configured (&gt;= Pike).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DockerNamespace</span><span class="p">:</span> <span class="n">registry</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">tld</span><span class="o">/</span><span class="n">rocky</span>
<span class="n">DockerNamespaceIsRegistry</span><span class="p">:</span> <span class="n">true</span>
<span class="n">DockerInsecureRegistryAddress</span><span class="p">:</span> <span class="n">registry</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">tld</span>
<span class="n">DockerNamespaceIsInsecureRegistry</span><span class="p">:</span> <span class="n">true</span>
</pre></div>
</div>
</div>
<div class="section" id="ceph">
<h3><a class="toc-backref" href="#id44">Ceph</a><a class="headerlink" href="#ceph" title="Permalink to this headline">¶</a></h3>
<p><strong>Releases</strong></p>
<p>Ceph is fully supported as a back-end for Overcloud storage services. If Ceph is enabled in TripleO, it will be used by default for Glance and Cinder. Before Pike, puppet-ceph was used to manage Ceph. Experimental support for using ceph-ansible was added in Pike. [17] It is fully supported via config-download as of Rocky. In Train, it uses the same Ansible inventory as config-download. Ceph updates are handled during the <code class="docutils literal notranslate"><span class="pre">external_deploy_steps_tasks</span></code> stage of config-download.</p>
<p>Red Hat Ceph Storage (RHCS) is the supported enterprise version of Ceph. RHCS 3.2 added official support for BlueStore. Using Ceph’s FileStore mechanism has been deprecated since RHOSP 14. FileStore to BlueStore migration is supported by Red Hat. Customers must first update to RHCS 4 and then each OSD node is upgraded one at a time. [16]</p>
<p>RHCS releases and supported platforms:</p>
<ul class="simple">
<li><p>RHCS 2 (Jewel) = RHOSP 10, 11, and 12.</p></li>
<li><p>RHCS 3 (Luminous) = RHOSP 13 and 14.</p></li>
<li><p>RHCS 4 (Nautilus) = RHOSP &gt;= 15.</p></li>
</ul>
<p><strong>Deployment Types</strong></p>
<p>TripleO can use an existing/independent <code class="docutils literal notranslate"><span class="pre">external</span></code> Ceph cluster. This is not managed by TripleO, and only provides connection details for OpenStack to communicate with the Ceph cluster. This requires the <code class="docutils literal notranslate"><span class="pre">environments/ceph-ansible-external.yaml</span></code> template. For a managed <code class="docutils literal notranslate"><span class="pre">internal</span></code> cluster, TripleO can deploy and manage the life-cycle of Ceph by using the <code class="docutils literal notranslate"><span class="pre">environments/ceph-ansible.yaml</span></code> template.</p>
<p><strong>Packages</strong></p>
<p>There are package and container requirements for both <code class="docutils literal notranslate"><span class="pre">internal</span></code> and <code class="docutils literal notranslate"><span class="pre">external</span></code> deployments of Ceph. The ceph-ansible package has to be installed for either the internal or external use case. For RHOSP, this is provided by the <code class="docutils literal notranslate"><span class="pre">ceph-tools</span></code> repository. As of Pike, the <code class="docutils literal notranslate"><span class="pre">ceph-container</span></code> has to be used to manage the Ceph services (even only as a client). This means that troubleshooting must be done inside the container. All OSD daemons run through a single container on each OSD node.</p>
<p><strong>Architecture</strong></p>
<p>TripleO puts the ceph-mon[itors] on the Overcloud Controller nodes. The OSDs are recommended to be placed on dedicated hardware. Hyperconverged infrastructure (HCI) is supported to run OSDs on the Compute nodes alongside the OpenStack services. For the Edge deployments, the ceph-mons live on the OSD nodes.</p>
<p>If the specified disks for deployment are clean, TripleO will create the LVMs required for the Ceph OSDs.</p>
<p>Pools for each OpenStack service are automatically created.</p>
<ul class="simple">
<li><p>images = Glance</p></li>
<li><p>metrics = Gnocchi</p></li>
<li><p>backups = Cinder</p></li>
<li><p>vms = Nova</p></li>
<li><p>volumes = Cinder</p></li>
</ul>
<p>One keyring at <code class="docutils literal notranslate"><span class="pre">/etc/ceph/ceph.client.openstack.keyring</span></code> is created by default to access all of the pool/rbds.</p>
<p><strong>Deployment (Internal)</strong></p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">environments/ceph-ansible.yaml</span></code> Heat template. The command output of <code class="docutils literal notranslate"><span class="pre">ceph-ansible</span></code> is saved in the config-download directory at <code class="docutils literal notranslate"><span class="pre">ceph-ansible/ceph-ansible-command.log</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">~/templates/environments/ceph-ansible.yaml</span></code> = Enables Ceph
<code class="docutils literal notranslate"><span class="pre">~/ceph.yaml</span></code> = Specify a custom file with your own overrides</p>
<p>Configure the object storage back-end: <code class="docutils literal notranslate"><span class="pre">bluestore</span></code> or <code class="docutils literal notranslate"><span class="pre">filestore</span></code>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">osd_objectstore</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;BACKEND&gt;</span>
</pre></div>
</div>
<p>Example configuration of letting <code class="docutils literal notranslate"><span class="pre">ceph-volume</span></code> automatically determine which disks to use for what purpose (OSD or metadata). LVM is the recommended scenario.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">CephAnsibleDisksConfig</span><span class="p">:</span>
    <span class="nt">devices</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/dev/sdb</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/dev/sdc</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/dev/nvme1n1</span>
    <span class="nt">osd_scenario</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">lvm</span>
    <span class="nt">osd_objectstore</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bluestore</span>
</pre></div>
</div>
<p>Manually created LVMs can also be defined to skip the usage of <code class="docutils literal notranslate"><span class="pre">ceph-volume</span></code>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">CephAnsibleDisksConfig</span><span class="p">:</span>
    <span class="nt">lvm_volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">data-lv2</span>
        <span class="nt">data_vg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vg2</span>
        <span class="nt">db</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db-lv2</span>
        <span class="nt">db_vg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vg2</span>
    <span class="nt">osd_scenario</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">lvm</span>
    <span class="nt">osd_objectstore</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bluestore</span>
</pre></div>
</div>
<p>If the initial deployment of TripleO with internal Ceph fails, the storage devices used for Ceph should be cleaned. If the undercloud.conf has <code class="docutils literal notranslate"><span class="pre">clean_nodes</span> <span class="pre">=</span> <span class="pre">True</span></code> set then the cleaning will be done automatically when Ironic chances a node state from <code class="docutils literal notranslate"><span class="pre">active</span></code> to <code class="docutils literal notranslate"><span class="pre">available</span></code> or <code class="docutils literal notranslate"><span class="pre">manageable</span></code> to <code class="docutils literal notranslate"><span class="pre">available</span></code>.</p>
<p>Example of common settings for Ceph in RHOSP:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">CephAnsiblePlaybookVerbosity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span>
  <span class="nt">CephPoolDefaultSize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">CephPoolDefaultPgNum</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">32</span>
  <span class="nt">LocalCephAnsibleFetchDirectoryBackup</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/tmp/fetch_dir</span>
  <span class="nt">CephAnsibleDisksConfig</span><span class="p">:</span>
    <span class="nt">osd_scenario</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">lvm</span>
    <span class="nt">osd_objectstore</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bluestore</span>
    <span class="nt">lvm_volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">data-lv2</span>
        <span class="nt">data_vg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vg2</span>
        <span class="nt">db</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">db-lv2</span>
        <span class="nt">db_vg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vg2</span>
  <span class="nt">CephAnsibleExtraConfig</span><span class="p">:</span>
    <span class="nt">mon_host_v1</span><span class="p">:</span>
      <span class="nt">enabled</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>
  <span class="c1"># Required on RHOSP 15 until RHCS 4 becomes GA.</span>
  <span class="nt">EnableRhcs4Beta</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<ul class="simple">
<li><p>CephAnsiblePlaybookVerbosity = If set to &gt; 0, then the playbooks are kept (and the verbosity is enabled for the playbook).</p></li>
<li><p>CephAnsiblePoolDefaultSize = Set the replica size for each pool. Default: 3. Lab recommended: 1.</p></li>
<li><p>CephAnsibleDefaultPgNum = For a production environment, use <a class="reference external" href="https://access.redhat.com/labs/cephpgc/">PGCalc</a> to determine the optimal value. Set to a low number for a lab with 1 disk. Lab recommended: 32.</p></li>
<li><p>CephAnsibleExtraConfig: mon_host_v1: enabled: false = Force msgr2 (messenger v2). By default, both v1 and v2 are used, which causes issues in lab environments such as Standalone.</p></li>
</ul>
<p><strong>Deployment (External)</strong></p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">environments/ceph-ansible-external.yaml</span></code> Heat template.</p>
<p>TripleO Queens:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">NovaEnableRbdBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">CinderEnableRbdBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">CinderBackupBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ceph</span>
  <span class="nt">GlanceBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbd</span>
  <span class="nt">GnocchiBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">rbd</span>
  <span class="nt">NovaRbdPoolName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">vms</span>
  <span class="nt">CinderRbdPoolName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">volumes</span>
  <span class="nt">CinderBackupRbdPoolName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">backups</span>
  <span class="nt">GlanceRbdPoolName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">images</span>
  <span class="nt">GnocchiRbdPoolName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">metrics</span>
  <span class="nt">CephClientUserName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">openstack</span>
  <span class="nt">CephClusterFSID</span><span class="p">:</span> <span class="s">&#39;&lt;CLUSTER_FILE_SYSTEM_ID&gt;&#39;</span>
  <span class="nt">CephClientKey</span><span class="p">:</span> <span class="s">&#39;&lt;CEPHX_USER_KEY&gt;&#39;</span>
  <span class="nt">CephExternalMonHost</span><span class="p">:</span> <span class="s">&#39;&lt;CEPH_MONITOR_1&gt;,</span><span class="nv"> </span><span class="s">&lt;CEPH_MONITOR_2&gt;,</span><span class="nv"> </span><span class="s">&lt;CEPH_MONITOR_3&gt;&#39;</span>
</pre></div>
</div>
<p>[29]</p>
</div>
<div class="section" id="overcloud-cloud-init">
<h3><a class="toc-backref" href="#id45">Overcloud (cloud-init)</a><a class="headerlink" href="#overcloud-cloud-init" title="Permalink to this headline">¶</a></h3>
<p>Any Overcloud node that is provisioned and managed by Ironic and Nova can be configured using cloud-init configuration data.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::NodeUserData</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;CLOUD_INIT_CONFIG&gt;.yml</span>
</pre></div>
</div>
</div>
<div class="section" id="minions">
<h3><a class="toc-backref" href="#id46">Minions</a><a class="headerlink" href="#minions" title="Permalink to this headline">¶</a></h3>
<p>Introduced in the Train release [47], the Undercloud can be scaled horizontally by using <code class="docutils literal notranslate"><span class="pre">minion</span></code> nodes to help with a large Overcloud deployment, update, or upgrade. This runs the “heat-engine” and “ironic-conductor” services on additional nodes. There are no limits to the number of minions that can be used. When not in use, minion nodes can be turned off. The only requirement is that all of the nodes are on the Control Plane network. The framework for the minion installer is based on the standalone installer.</p>
<ul class="simple">
<li><p>Copy the required files from the Undercloud to the minions.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ scp tripleo-undercloud-outputs.yaml tripleo-undercloud-passwords.yaml &lt;USER&gt;@&lt;MINION_MACHINE&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Install the TripleO packages.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum install python3-tripleoclient
</pre></div>
</div>
<p>Configure the Minion node. The <code class="docutils literal notranslate"><span class="pre">minion_local_ip</span></code> and the <code class="docutils literal notranslate"><span class="pre">minion_local_interface</span></code> should be on the Overcloud control plane / provisioning network. The <code class="docutils literal notranslate"><span class="pre">container_images_file</span></code> should also use the same custom <code class="docutils literal notranslate"><span class="pre">container-image-prepare.yaml</span></code> file that the Undercloud uses (if applicable).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ cp /usr/share/python-tripleoclient/minion.conf.sample ~/minion.conf
</pre></div>
</div>
<p>Install the Minion services.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack undercloud minion install
</pre></div>
</div>
<ul class="simple">
<li><p>Verify the services are running as expected.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">source</span> ~/stackrc
$ openstack orchestration service list
$ openstack baremetal conductor list
</pre></div>
</div>
<p>[44]</p>
</div>
<div class="section" id="scaling-large-overcloud">
<h3><a class="toc-backref" href="#id47">Scaling (Large Overcloud)</a><a class="headerlink" href="#scaling-large-overcloud" title="Permalink to this headline">¶</a></h3>
<p>RHOSP 13 (Queens) supports deploying 500 Overcloud nodes. The Undercloud needs resource allocations related directly to how many Overcloude nodes will be deployed: 1 CPU core and 8GB RAM per every 15 nodes. Undercloud services require a few other configuration tweaks to handle the large capacity. [66] Set the <code class="docutils literal notranslate"><span class="pre">NodeCreateBatchSize</span></code> Heat parameter to a value equal to the number of Overcloud nodes. This will greatly decrease the initial Heat template processing time.</p>
</div>
<div class="section" id="puppet">
<h3><a class="toc-backref" href="#id48">Puppet</a><a class="headerlink" href="#puppet" title="Permalink to this headline">¶</a></h3>
<p>Puppet is used for configuring the OpenStack and operating system services.</p>
<ul class="simple">
<li><p>Train = Puppet 5</p></li>
<li><p>Queens = Puppet 4</p></li>
<li><p>Newton = Puppet 3</p></li>
</ul>
</div>
<div class="section" id="lab-tips">
<h3><a class="toc-backref" href="#id49">Lab Tips</a><a class="headerlink" href="#lab-tips" title="Permalink to this headline">¶</a></h3>
<p>These are trips and tricks for setting up a full, yet basic, TripleO cloud for testing the deployment.</p>
<ul>
<li><p>Use the Standalone deployment or at least the minimum amount of nodes required for TripleO: 1 Undercloud, 1 Controller, and 1 Compute.</p></li>
<li><p>Use the most minimally required resources for each node role. These values have been verified on the Train release.</p>
<ul class="simple">
<li><p>Undercloud: 4 vCPUs and 8GB RAM</p></li>
<li><p>Controller: 2 vCPUs and 12GB RAM</p></li>
<li><p>Compute: 1 vCPU</p>
<ul>
<li><p>Pre-deployed: 2GB RAM</p></li>
<li><p>Ironic provisioned: 4GB RAM</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Enable swap. This is especially required for environments with limited RAM.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::AllNodesExtraConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">extraconfig/all_nodes/swap.yaml</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">swap_size_megabytes</span><span class="p">:</span> <span class="s">&#39;8192&#39;</span>
</pre></div>
</div>
</li>
<li><p>If using OpenStack as the lab infrastructure, disable port security to allow any MAC and IP address to be used. Also disable security groups to avoid further connection issues.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ openstack port set --disable-port-security --no-security-group &lt;PORT&gt;
</pre></div>
</div>
</li>
<li><p>Use the low resource usage template: <code class="docutils literal notranslate"><span class="pre">environments/low-memory-usage.yaml</span></code>. This sets the <code class="docutils literal notranslate"><span class="pre">worker</span></code> count to 1 for all of the OpenStack services, lowers the Apache resource utilization (used as the CGI handler for OpenStack services), and configures low defaults for (optional) Ceph services.</p></li>
<li><p>Avoid using complex network templates such as <code class="docutils literal notranslate"><span class="pre">environments/network-isolation.yaml</span></code> and <code class="docutils literal notranslate"><span class="pre">environments/network-environment.yaml</span></code>. By default, TripleO will use flat networking for all of the services and separate traffic using different subnets.</p></li>
<li><p>For virtual machines without nested virtualization, set the parameter <code class="docutils literal notranslate"><span class="pre">NovaComputeLibvirtType</span></code> to <code class="docutils literal notranslate"><span class="pre">qemu</span></code>.</p></li>
<li><p>Use <a class="reference external" href="https://opendev.org/openstack/tripleo-heat-templates/src/commit/d2bcf0f530cade1ca65b90fbe91953dfb67958b0/ci/environments/scenario000-standalone.yaml">this template</a> (designed for Train) as a reference to prevent deploying unnecessary services on the Overcloud. That template will disable everything except Keystone. Alternatively, remove services from the <code class="docutils literal notranslate"><span class="pre">roles_data.yaml</span></code> file.</p></li>
<li><p>Disable Swift. Then use NFS as the back-end for Cinder, Glance, Gnocchi, and Nova based off of the configuration files from <code class="docutils literal notranslate"><span class="pre">/usr/share/openstack-tripleo-heat-templates/environments/storage/*-nfs.yaml</span></code>. [51] Add the NFS mount option ‘nosharecache’ to address <a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1513275">this</a> bug.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="c1"># Disable Swift</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::SwiftProxy</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::None</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::SwiftStorage</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::None</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::SwiftRingBuilder</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">OS::Heat::None</span>

<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">ControllerExtraConfig</span><span class="p">:</span>
    <span class="l l-Scalar l-Scalar-Plain">tripleo::haproxy::swift_proxy_server</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="c1"># Enable NFS back-ends</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::CephMgr</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">~/templates/docker/services/ceph-ansible/ceph-mgr.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::CephMon</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">~/templates/docker/services/ceph-ansible/ceph-mon.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::CephOSD</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">~/templates/docker/services/ceph-ansible/ceph-osd.yaml</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::Services::CephClient</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">~/templates/docker/services/ceph-ansible/ceph-client.yaml</span>

<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="c1"># Cinder</span>
  <span class="nt">CinderBackupBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs</span>
  <span class="nt">CinderEnableIscsiBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="nt">CinderEnableNfsBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">CinderEnableRbdBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="c1"># docker (Queens)</span>
  <span class="c1">#CinderNfsMountOptions: &#39;rw,sync,vers=4,minorversion=2,nosharecache,context=system_u:object_r:cinder_var_lib_t:s0&#39;</span>
  <span class="c1"># Podman (Train)</span>
  <span class="nt">CinderNfsMountOptions</span><span class="p">:</span> <span class="s">&#39;rw,sync,vers=4,minorversion=2,nosharecache,context=system_u:object_r:container_file_t:s0&#39;</span>
  <span class="nt">CinderNfsServers</span><span class="p">:</span> <span class="s">&#39;&lt;NFS_SERVER_IP&gt;:/exports/cinder&#39;</span>
  <span class="c1"># Glance</span>
  <span class="nt">GlanceBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">file</span>
  <span class="nt">GlanceNfsEnabled</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="c1"># docker (Queens)</span>
  <span class="c1">#GlanceNfsOptions: &#39;rw,sync,vers=4,minorversion=2,nosharecache,context=system_u:object_r:glance_var_lib_t:s0&#39;</span>
  <span class="c1"># Podman (Train)</span>
  <span class="nt">GlanceNfsOptions</span><span class="p">:</span> <span class="s">&#39;rw,sync,vers=4,minorversion=2,nosharecache,context=system_u:object_r:container_file_t:s0&#39;</span>
  <span class="nt">GlanceNfsShare</span><span class="p">:</span> <span class="s">&#39;&lt;NFS_SERVER_IP&gt;:/exports/glance&#39;</span>
  <span class="c1"># Gnocchi</span>
  <span class="nt">GnocchiBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">file</span>
  <span class="c1"># Nova</span>
  <span class="nt">NovaNfsEnabled</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">NovaEnableRbdBackend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="c1"># docker and Podman</span>
  <span class="nt">NovaNfsOptions</span><span class="p">:</span> <span class="s">&#39;rw,sync,vers=4,minorversion=2,nosharecache,context=system_u:object_r:nfs_t:s0&#39;</span>
  <span class="nt">NovaNfsShare</span><span class="p">:</span> <span class="s">&#39;&lt;NFS_SERVER_IP&gt;:/exports/nova&#39;</span>
</pre></div>
</div>
<ul>
<li><p>TripleO will not create or manage an NFS server. If using the Undercloud as the NFS server, the firewall ports for the service will need to be opened.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo iptables -I INPUT -p tcp -m tcp --dport <span class="m">111</span> -j ACCEPT
$ sudo iptables -I INPUT -p tcp -m tcp --dport <span class="m">2049</span> -j ACCEPT
$ sudo iptables -I INPUT -p udp -m udp --dport <span class="m">111</span> -j ACCEPT
$ sudo iptables -I INPUT -p udp -m udp --dport <span class="m">2049</span> -j ACCEPT
$ sudo iptables-save <span class="p">|</span> sudo tee /etc/sysconfig/iptables
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="troubleshooting">
<h2><a class="toc-backref" href="#id50">Troubleshooting</a><a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<div class="section" id="service-telemetry-framework">
<h3><a class="toc-backref" href="#id51">Service Telemetry Framework</a><a class="headerlink" href="#service-telemetry-framework" title="Permalink to this headline">¶</a></h3>
<p>The Red Hat Service Telemetry Framework (STF) provides a standardized way to log and monitor all of the services in RHOSP. This was previously known as the Service Assurance Framework (SAF). STF is hosted on the Red Hat OpenShift Container Platform (RHOCP).</p>
<p>Services:</p>
<ul>
<li><p>RHOSP nodes:</p>
<ul class="simple">
<li><p>ceilometer = Collects metrics and events from OpenStack services.</p></li>
<li><p>collectd = Collects metrics and events from the infrastructure and non-OpenStack services.</p></li>
<li><p>Red Hat AMQ = Sends metrics and events to AMQ Interconnect on RHOCP.</p></li>
</ul>
</li>
<li><p>RHOCP operators:</p>
<ul class="simple">
<li><p>AMQ Interconnect = Recieves metrics and events from Red Hat AMQ on RHOSP. These are then sent to the Smart Gateway.</p></li>
<li><p>Smart Gateway = Routes metrics to Prometheus and events to ElasticSearch.</p></li>
<li><p>Prometheus = Stores all of the time-series metrics onto a persistent storage backend. Provides a dashboard and API to search the data.</p></li>
<li><p>AlertManager = Waits for an alert rule to be triggered by Prometheus. Once an alert is recieved, the AlertManager sends communication to the system administrators about possible issues.</p></li>
<li><p>ElasticSearch = Stores all of the events onto a persistent storage backend. Provides a dashboard and API to search the data.</p></li>
</ul>
</li>
<li><p>Visual dashboard:</p>
<blockquote>
<div><ul class="simple">
<li><p>Grafana = Not officially part of the STF. Available as a useful community plugin to visualize the data.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>[75]</p>
</div>
<div class="section" id="tips">
<h3><a class="toc-backref" href="#id52">Tips</a><a class="headerlink" href="#tips" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Disable the Extra Packages for Enterprise Linux (EPEL) and Puppet Labs repositories if these are available. These will cause package conflicts and result in the installation of wrong dependencies.</p></li>
<li><p>If a deployment fails, view the config-download playbook errors: <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">failures</span> <span class="pre">list</span></code>.</p></li>
<li><p>If highly-available (HA) services on the Controller nodes are stopped or not working, cleanup and restart the affected resources managed by Pacemaker.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo pcs status
$ sudo crm_resource -C &lt;RESOURCE_BUNDLE&gt;
$ sudo pcs resource restart &lt;RESOURCE_BUNDLE&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Changes can be made to a container manually for testing. For permanent changes, use the <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/container_image_prepare.html">containers-prepare-parameter.yaml</a> file.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo systemctl stop tripleo_&lt;SERVICE&gt;
$ sudo vim /var/lib/config-data/puppet-generated/&lt;CONTAINER_NAME&gt;/etc/foo/bar.conf
$ sudo vim /var/lib/config-data/puppet-generated/&lt;CONTAINER_NAME&gt;/etc/httpd/conf.d/10-&lt;SERVICE&gt;_wsgi.conf
$ sudo systemctl start tripleo_&lt;SERVICE&gt;
</pre></div>
</div>
<ul class="simple">
<li><p>Puppet variables can be retrieved from Hieradata on both the Undercloud and Overcloud nodes. Example:</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo hiera -c /etc/puppet/hiera.yaml mysql::server::root_password
</pre></div>
</div>
<ul>
<li><p>Enable various parameters to assist with debugging.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">parameter_defaults</span><span class="p">:</span>
  <span class="nt">ContainerHealthcheckDisabled</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">ContainerImagePrepareDebug</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="c1"># Enable &#39;Debug&#39; logging for all OpenStack services.</span>
  <span class="nt">Debug</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">SELinuxMode</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">permissive</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="errors">
<h3><a class="toc-backref" href="#id53">Errors</a><a class="headerlink" href="#errors" title="Permalink to this headline">¶</a></h3>
<p>“<strong>No valid host was found</strong>” when running <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">OVERCLOUD_STACK_NAME</span><span class="o">&gt;.&lt;</span><span class="n">ROLE_TYPE</span><span class="o">&gt;.&lt;</span><span class="n">NODE_INDEX</span><span class="o">&gt;.&lt;</span><span class="n">ROLE_NAME</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">resource_type</span><span class="p">:</span> <span class="n">OS</span><span class="p">::</span><span class="n">TripleO</span><span class="p">::</span><span class="o">&lt;</span><span class="n">ROLE_TYPE</span><span class="o">&gt;</span><span class="n">Server</span> <span class="n">physical_resource_id</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">RESOURCE_ID</span><span class="o">&gt;</span> <span class="n">status</span><span class="p">:</span> <span class="n">CREATE_FAILED</span> <span class="n">status_reason</span><span class="p">:</span> <span class="o">|</span> <span class="n">ResourceInError</span><span class="p">:</span> <span class="n">resources</span><span class="o">.&lt;</span><span class="n">ROLE_NAME</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">Went</span> <span class="n">to</span> <span class="n">status</span> <span class="n">ERROR</span> <span class="n">due</span> <span class="n">to</span> <span class="s2">&quot;Message: No valid host was found. There are not enough hosts available., Code: 500&quot;</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">overcloud</span><span class="o">.</span><span class="n">Controller</span><span class="o">.</span><span class="mf">0.</span><span class="n">Controller</span><span class="p">:</span> <span class="n">resource_type</span><span class="p">:</span> <span class="n">OS</span><span class="p">::</span><span class="n">TripleO</span><span class="p">::</span><span class="n">ControllerServer</span> <span class="n">physical_resource_id</span><span class="p">:</span> <span class="mf">2e41</span><span class="n">f61b</span><span class="o">-</span><span class="mi">8</span><span class="n">f3c</span><span class="o">-</span><span class="mi">4</span><span class="n">fed</span><span class="o">-</span><span class="n">a523</span><span class="o">-</span><span class="mf">0e56</span><span class="n">a7a88ecc</span> <span class="n">status</span><span class="p">:</span> <span class="n">CREATE_FAILED</span> <span class="n">status_reason</span><span class="p">:</span> <span class="o">|</span> <span class="n">ResourceInError</span><span class="p">:</span> <span class="n">resources</span><span class="o">.</span><span class="n">Controller</span><span class="p">:</span> <span class="n">Went</span> <span class="n">to</span> <span class="n">status</span> <span class="n">ERROR</span> <span class="n">due</span> <span class="n">to</span> <span class="s2">&quot;Message: No valid host was found. There are not enough hosts available., Code: 500&quot;</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">overcloud</span><span class="o">.</span><span class="n">Compute</span><span class="o">.</span><span class="mf">0.</span><span class="n">NovaCompute</span><span class="p">:</span> <span class="n">resource_type</span><span class="p">:</span> <span class="n">OS</span><span class="p">::</span><span class="n">TripleO</span><span class="p">::</span><span class="n">ComputeServer</span> <span class="n">physical_resource_id</span><span class="p">:</span> <span class="n">ab29fe63</span><span class="o">-</span><span class="mi">4103</span><span class="o">-</span><span class="mi">4</span><span class="n">afd</span><span class="o">-</span><span class="n">bc95</span><span class="o">-</span><span class="mi">9</span><span class="n">a9e720920ed</span> <span class="n">status</span><span class="p">:</span> <span class="n">CREATE_FAILED</span> <span class="n">status_reason</span><span class="p">:</span> <span class="o">|</span> <span class="n">ResourceInError</span><span class="p">:</span> <span class="n">resources</span><span class="o">.</span><span class="n">NovaCompute</span><span class="p">:</span> <span class="n">Went</span> <span class="n">to</span> <span class="n">status</span> <span class="n">ERROR</span> <span class="n">due</span> <span class="n">to</span> <span class="s2">&quot;Message: No valid host was found. There are not enough hosts available., Code: 500&quot;</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">overcloud</span><span class="o">.</span><span class="n">BlockStorage</span><span class="o">.</span><span class="mf">0.</span><span class="n">BlockStorage</span><span class="p">:</span> <span class="n">resource_type</span><span class="p">:</span> <span class="n">OS</span><span class="p">::</span><span class="n">TripleO</span><span class="p">::</span><span class="n">BlockStorageServer</span> <span class="n">physical_resource_id</span><span class="p">:</span> <span class="mi">7640</span><span class="n">f169</span><span class="o">-</span><span class="mi">7790</span><span class="o">-</span><span class="mi">4</span><span class="n">b73</span><span class="o">-</span><span class="mi">9006</span><span class="o">-</span><span class="mi">8171</span><span class="n">ddd450e4</span> <span class="n">status</span><span class="p">:</span> <span class="n">CREATE_FAILED</span> <span class="n">status_reason</span><span class="p">:</span> <span class="o">|</span> <span class="n">ResourceInError</span><span class="p">:</span> <span class="n">resources</span><span class="o">.</span><span class="n">BlockStorage</span><span class="p">:</span> <span class="n">Went</span> <span class="n">to</span> <span class="n">status</span> <span class="n">ERROR</span> <span class="n">due</span> <span class="n">to</span> <span class="s2">&quot;Message: No valid host was found. There are not enough hosts available., Code: 500&quot;</span>
</pre></div>
</div>
<ul>
<li><p>All Overcloud nodes are required to have been successfully introspected.</p>
<ul class="simple">
<li><p>If introspection is failing with a kernel panic, ensure the nodes have at least 4GB of RAM.</p></li>
</ul>
</li>
<li><p>All nodes must have “Maintenance” mode set to “False” and be in the “Provisioning State” of “available” .</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node list
$ openstack baremetal node maintenance <span class="nb">unset</span> &lt;BAREMETAL_NODE&gt;
$ openstack baremetal node provide &lt;BAREMETAL_NODE&gt;
</pre></div>
</div>
</li>
<li><p>All Overcloud nodes require a <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/profile_matching.html">profile tag</a> that will determine what type of node it will be.</p>
<ul>
<li><p>Manually set the profile type for each node: block-storage, ceph-storage, compute, control, or swift-storage.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack baremetal node <span class="nb">set</span> --property <span class="nv">capabilities</span><span class="o">=</span><span class="s1">&#39;profile:&lt;PROFILE_TYPE&gt;,boot_option:local&#39;</span> &lt;BAREMETAL_NODE&gt;
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Ensure that each <code class="docutils literal notranslate"><span class="pre">&lt;ROLE_NAME&gt;Count:</span></code> Heat parameter is correctly set to the number of nodes that are available.</p></li>
</ul>
<hr class="docutils" />
<p>“<strong>StackValidationFailed: The Resource Type (OS::TripleO::&lt;ROLE&gt;::&lt;RESOURCE&gt;) could not be found.</strong>” when running <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>.</p>
<ul>
<li><p>The &lt;ROLE&gt; needs to be set to a valid role defined in the <code class="docutils literal notranslate"><span class="pre">roles_data.yaml</span></code> file.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">resource_registry</span></code> mapping must link a resource type to a file ending with the <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> extension (<code class="docutils literal notranslate"><span class="pre">.yml</span></code> will not work). Example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">resource_registry</span><span class="p">:</span>
  <span class="l l-Scalar l-Scalar-Plain">OS::TripleO::ControllerDeployedServer::Net::SoftwareConfig</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">net-config-static-bridge.yaml</span>
</pre></div>
</div>
</li>
<li><p>The resource type may be undefined. That means a THT template is missing and needs to be included as part of the deployment.</p></li>
<li><p>The resource type may be misspelled.</p></li>
</ul>
<hr class="docutils" />
<p>“<strong>Config download already in progress with execution id &lt;MISTRAL_EXECUTION_ID&gt; for stack overcloud</strong>” when running <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>.</p>
<ul>
<li><p>Check the status of the Mistral execution: <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">workflow</span> <span class="pre">execution</span> <span class="pre">show</span> <span class="pre">&lt;MISTRAL_EXECUTION_ID&gt;</span></code>.</p></li>
<li><p>Check if the deployment is still running: <code class="docutils literal notranslate"><span class="pre">ps</span> <span class="pre">faux</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">ansible-playbook</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kill</span></code> any lingering Ansible processes.</p></li>
</ul>
</li>
<li><p>Manually set the workflow execution state to <code class="docutils literal notranslate"><span class="pre">CANCELLED</span></code> or <code class="docutils literal notranslate"><span class="pre">FAILED</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack workflow execution update -s FAILED &lt;MISTRAL_EXECUTION_ID&gt;
</pre></div>
</div>
</li>
<li><p>Re-run <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">overcloud</span> <span class="pre">deploy</span></code>.</p></li>
</ul>
<hr class="docutils" />
<p><strong>ERROR configuring &lt;OPENSTACK_SERVICE&gt;</strong></p>
<ul class="simple">
<li><p>A configuration section may be misconfigured to use an invalid section or key.</p></li>
<li><p>A duplicate configuration entry may exist. This usually means a different Puppet manifest is trying to declare the same value for a specified section and key. When the operator defines the same variable elsewhere, the deployment will error out. The example below showcases that the configuration is already handled by the Puppet class <code class="docutils literal notranslate"><span class="pre">oslo::messaging::default</span></code>.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ less /var/log/containers/stdouts/container-puppet-&lt;OPENSTACK_SERVICE&gt;.log
<span class="m">2020</span>-01-01T16:15:00.000000000-04:00 stderr F &lt;<span class="m">13</span>&gt;Jan <span class="m">01</span> <span class="m">16</span>:12:38 puppet-user: Error: Evaluation Error: Error <span class="k">while</span> evaluating a Resource Statement, Evaluation Error: Error <span class="k">while</span> evaluating a Function Call, Duplicate declaration: &lt;OPENSTACK_SERVICE&gt;_config<span class="o">[</span>&lt;SECTION&gt;/&lt;KEY&gt;<span class="o">]</span> is already declared at <span class="o">(</span>file: /etc/puppet/modules/&lt;OPENSTACK_SERVICE&gt;/manifests/config.pp, line: <span class="m">36</span><span class="o">)</span><span class="p">;</span> cannot redeclare <span class="o">(</span>file: /etc/puppet/modules/oslo/manifests/messaging/default.pp, line: <span class="m">47</span><span class="o">)</span> <span class="o">(</span>file: /etc/puppet/modules/oslo/manifests/messaging/default.pp, line: <span class="m">47</span>, column: <span class="m">3</span><span class="o">)</span> <span class="o">(</span>file: /etc/puppet/modules/&lt;OPENSTACK_SERVICE&gt;/manifests/init.pp, line: <span class="m">445</span><span class="o">)</span> on node undercloud.localhost.localdomain
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Failed to pull image &lt;CONTAINER_REGISTRY_NAMESPACE&gt;/&lt;CONTAINER_IMAGE_NAME&gt;:&lt;CONTAINER_IMAGE_TAG&gt;</strong></p>
<ul class="simple">
<li><p>Verify that (1) the registry works, (2) the container name exists, and (3) that the container tag exists.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ skopeo inspect --tls-verify<span class="o">=</span>False docker://&lt;CONTAINER_REGISTRY_NAMESPACE&gt;/&lt;CONTAINER_NAME_PERFIX&gt;&lt;CONTAINER_IMAGE_NAME&gt;
$ skopeo inspect --tls-verify<span class="o">=</span>False docker://&lt;CONTAINER_REGISTRY_NAMESPACE&gt;/&lt;CONTAINER_NAME_PERFIX&gt;&lt;CONTAINER_IMAGE_NAME&gt;:&lt;CONTAINER_IMAGE_TAG&gt;
    <span class="s2">&quot;RepoTags&quot;</span>: <span class="o">[</span>
     <span class="s2">&quot;latest&quot;</span>,
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Object GET failed: https://192.168.24.2:13808/v1/AUTH_&lt;PROJECT_ID&gt;/overcloud/plan-environment.yaml 404 Not Found  [first 60 chars of response] &lt;html&gt;&lt;h1&gt;Not Found&lt;/h1&gt;&lt;p&gt;The resource could not be found.&lt;</strong></p>
<ul>
<li><p>Delete the <code class="docutils literal notranslate"><span class="pre">overcloud</span></code> Swift container.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack container delete --recursive overcloud
</pre></div>
</div>
</li>
<li><p>Re-run the deployment with the <code class="docutils literal notranslate"><span class="pre">--templates</span></code> directory. All of the TripleO Heat templates used in the deployment should be stored in that directory.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openstack overcloud deploy --templates ~/templates
</pre></div>
</div>
</li>
</ul>
<p>[67]</p>
<hr class="docutils" />
<p><strong>Error: mistralclient.api.base.APIException: Duplicate entry for WorkbookDefinition [\\\’name\\\’, \\\’namespace\\\’, \\\’project_id\\\’]: tripleo.deployment.v1, , None\\n\’\n[2020-01-23 00:00:00,000]</strong></p>
<ul>
<li><p>There is a duplicate Mistral workflow on the Undercloud. In this example, it is <code class="docutils literal notranslate"><span class="pre">tripleo.deployment.v1</span></code>.</p></li>
<li><p>Look for files that may have been copied and/or renamed.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ find /usr/share/tripleo-common/workbooks/ ! -name <span class="s2">&quot;*.yaml&quot;</span>
</pre></div>
</div>
</li>
<li><p>Look for files containing the workflow definition.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ grep -rl <span class="s1">&#39;name: tripleo.deployment.v1&#39;</span> /usr/share/tripleo-common/workbooks/
</pre></div>
</div>
</li>
<li><p>Delete any files found based on the previous two commands or at least move them out of the “workbooks” directory.</p></li>
</ul>
</div>
</div>
<div class="section" id="openshift-on-openstack">
<h2><a class="toc-backref" href="#id54">OpenShift on OpenStack</a><a class="headerlink" href="#openshift-on-openstack" title="Permalink to this headline">¶</a></h2>
<p>Red Hat provides a way to install the Red Hat OpenShift Container Platform (RHOCP, their Kubernetes product) using infrastructure from a RHOSP Overcloud.</p>
<p>OpenStack integration:</p>
<ul class="simple">
<li><p>Ceilometer = Provides metrics of OpenShift resources.</p></li>
<li><p>Cinder = Block storage can be used for persistent storage on OpenShift.</p></li>
<li><p>Designate = Native DNS integration between OpenStack and OpenShift.</p></li>
<li><p>Heat = Automatic scaling of OpenShift Nodes based on capacity and usage.</p></li>
<li><p>Keystone = Authentication providers used in OpenStack, such as LDAP, can be used in OpenShift.</p></li>
<li><p>Load-Balancing-as-a-Service (Octavia) = A public load balancer than can be used by OpenShift.</p></li>
<li><p>Neutron = Kuryr is a networking plugin for Kubernetes that allows it to natively use Neutron. This removes the double overhead of having a Kubernetes overlay network ontop of OpenStack’s overlay network.</p></li>
<li><p>Nova = OpenShift Nodes can be deployed as virtual machines or on baremetal.</p></li>
</ul>
<p>The first tool to accomplish this was <a class="reference external" href="https://github.com/ktenzer/openshift-on-openstack-123">openshift-openstack-1-2-3</a> which was an unofficial tool written by a Red Hat employee. All of the infrastructure is defined via Heat templates. Then the official <a class="reference external" href="https://github.com/openshift/openshift-ansible">openshift-ansible</a> tool is used to install OpenShift. [70] Much of that work has been integrated into the openshift-ansible project for the 3.11 release.</p>
<p>OpenShift 4 now uses the concept of User Provisioned Infrastructure (UPI). [71] This means that the infrastructure is no longer managed by OpenShift but reference architecture material is available. [72] However, Ansible content is being developed to automate those steps (without Heat) in the new <a class="reference external" href="https://github.com/openshift/installer/tree/master/upi/openstack">openshift/installer project</a>. The deployment is highly opinionated to provide an out-of-the-box solution following best practices. It supports deploying infrastracture on RHOSP 13 and 16 and installing OpenShift 4 ontop of it. [73]</p>
</div>
<div class="section" id="history">
<h2><a class="toc-backref" href="#id55">History</a><a class="headerlink" href="#history" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/openstack/tripleo.rst">Latest</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/virtualization/openstack.rst">&lt; 2020.01.01 (OpenStack)</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/openstack.rst">&lt; 2019.01.01 (OpenStack)</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/markdown/openstack.md">&lt; 2018.01.01 (OpenStack)</a></p></li>
</ul>
</div>
<div class="section" id="bibliography">
<h2><a class="toc-backref" href="#id56">Bibliography</a><a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>“Red Hat OpenStack Platform Life Cycle.” Red Hat Support. Accessed June 17, 2020. <a class="reference external" href="https://access.redhat.com/support/policy/updates/openstack/platform">https://access.redhat.com/support/policy/updates/openstack/platform</a></p></li>
<li><p>“Frequently Asked Questions.” RDO Project. Accessed December 21, 2017. <a class="reference external" href="https://www.rdoproject.org/rdo/faq/">https://www.rdoproject.org/rdo/faq/</a></p></li>
<li><p>“Director Installation and Usage.” Red Hat OpenStack Platform 13 Documentation. September 26, 2018. Accessed September 26, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/pdf/director_installation_and_usage/Red_Hat_OpenStack_Platform-13-Director_Installation_and_Usage-en-US.pdf">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/pdf/director_installation_and_usage/Red_Hat_OpenStack_Platform-13-Director_Installation_and_Usage-en-US.pdf</a></p></li>
<li><p>“Packstack: Create a proof of concept cloud.” RDO Project. Accessed March 19, 2018. <a class="reference external" href="https://www.rdoproject.org/install/packstack/">https://www.rdoproject.org/install/packstack/</a></p></li>
<li><p>“Neutron with existing external network. RDO Project. Accessed September 28, 2017. <a class="reference external" href="https://www.rdoproject.org/networking/neutron-with-existing-external-network/">https://www.rdoproject.org/networking/neutron-with-existing-external-network/</a></p></li>
<li><p>“Error while installing openstack ‘newton’ using rdo packstack.” Ask OpenStack. October 25, 2016. Accessed September 28, 2017. <a class="reference external" href="https://ask.openstack.org/en/question/97645/error-while-installing-openstack-newton-using-rdo-packstack/">https://ask.openstack.org/en/question/97645/error-while-installing-openstack-newton-using-rdo-packstack/</a></p></li>
<li><p>“TripleO quickstart.” RDO Project. Accessed March 26, 2018. <a class="reference external" href="https://www.rdoproject.org/tripleo/">https://www.rdoproject.org/tripleo/</a></p></li>
<li><p>“[TripleO] Minimum System Requirements.” TripleO Documentation. September 7, 2016. Accessed March 26, 2018. <a class="reference external" href="https://images.rdoproject.org/docs/baremetal/requirements.html">https://images.rdoproject.org/docs/baremetal/requirements.html</a></p></li>
<li><p>[RDO] Recommended hardware.” RDO Project. Accessed September 28, 2017. <a class="reference external" href="https://www.rdoproject.org/hardware/recommended/">https://www.rdoproject.org/hardware/recommended/</a></p></li>
<li><p>“[TripleO] Virtual Environment.” TripleO Documentation. Accessed September 28, 2017. <a class="reference external" href="http://tripleo-docs.readthedocs.io/en/latest/environments/virtual.html">http://tripleo-docs.readthedocs.io/en/latest/environments/virtual.html</a></p></li>
<li><p>“Getting started with TripleO-Quickstart.” OpenStack Documentation. Accessed December 20, 2017. <a class="reference external" href="https://docs.openstack.org/tripleo-quickstart/latest/getting-started.html">https://docs.openstack.org/tripleo-quickstart/latest/getting-started.html</a></p></li>
<li><p>“TripleO Documentation.” OpenStack Documentation. Accessed September 12, 2017. <a class="reference external" href="https://docs.openstack.org/tripleo-docs/latest/">https://docs.openstack.org/tripleo-docs/latest/</a></p></li>
<li><p>“Basic Deployment (CLI).” TripleO Documentation. November 23, 2020. Accessed December 3, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/install_overcloud.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/install_overcloud.html</a></p></li>
<li><p>“Bug 1466744 - Include docker.yaml and docker-ha.yaml environment files by default.” Red Hat Bugzilla. December 13, 2017. Accessed January 12, 2018. <a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1466744">https://bugzilla.redhat.com/show_bug.cgi?id=1466744</a></p></li>
<li><p>“Baremetal Environment.” TripleO OpenStack Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/environments/baremetal.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/environments/baremetal.html</a></p></li>
<li><p>“Does Red Hat Ceph support migration from FileStore to BlueStore with the release of RHCS 3.2?” Red Hat Customer Portal. May 23, 2019. Accessed October 28, 2019. <a class="reference external" href="https://access.redhat.com/articles/3793241">https://access.redhat.com/articles/3793241</a></p></li>
<li><p>“Configuring Ceph with Custom Config Settings.” OpenStack Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/ceph_config.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/ceph_config.html</a></p></li>
<li><p>“[Ironic] Enabling drivers.” OpenStack Documentation. March 15, 2018. Accessed March 15, 2018. <a class="reference external" href="https://docs.openstack.org/ironic/queens/admin/drivers.html">https://docs.openstack.org/ironic/queens/admin/drivers.html</a></p></li>
<li><p>“CHAPTER 8. SCALING THE OVERCLOUD.” Red Hat Documentation. Accessed January 30, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/10/html/director_installation_and_usage/sect-scaling_the_overcloud">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/10/html/director_installation_and_usage/sect-scaling_the_overcloud</a></p></li>
<li><p>“Containers based Undercloud Deployment.” OpenStack Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/undercloud.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/undercloud.html</a></p></li>
<li><p>“[TripleO Quickstart] Networking.” TripleO Documentation. September 7, 2016. Accessed April 9, 2018. <a class="reference external" href="https://images.rdoproject.org/docs/baremetal/networking.html">https://images.rdoproject.org/docs/baremetal/networking.html</a></p></li>
<li><p>“Repository Enablement.” OpenStack TripleO Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/repositories.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/repositories.html</a></p></li>
<li><p>“TripleO: Using the fake_pxe driver with Ironic.” Leif Madsen Blog. November 11, 2016. Accessed June 13, 2018. <a class="reference external" href="http://blog.leifmadsen.com/blog/2016/11/11/tripleo-using-the-fake_pxe-driver-with-ironic/">http://blog.leifmadsen.com/blog/2016/11/11/tripleo-using-the-fake_pxe-driver-with-ironic/</a></p></li>
<li><p>“Bug 1535214 - baremetal commands that were deprecated in Ocata have been removed in Queens.” Red Hat Bugzilla. Accessed June 13, 2018. <a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1535214">https://bugzilla.redhat.com/show_bug.cgi?id=1535214</a></p></li>
<li><p>“OpenStack lab on your laptop with TripleO and director.” Tricky Cloud. November 25, 2015. Accessed June 13, 2018. <a class="reference external" href="https://trickycloud.wordpress.com/2015/11/15/openstack-lab-on-your-laptop-with-tripleo-and-director/">https://trickycloud.wordpress.com/2015/11/15/openstack-lab-on-your-laptop-with-tripleo-and-director/</a></p></li>
<li><p>“Director Installation and Usage.” Red Hat OpenStack Platform 10 Documentation. Accessed July 18, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/10/html/director_installation_and_usage/">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/10/html/director_installation_and_usage/</a></p></li>
<li><p>“Director Installation and Usage.” Red Hat OpenStack Platform 13 Documentation. Accessed July 18, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/</a></p></li>
<li><p>“Red Hat OpenStack Platform 13 Release Notes.” Red Hat OpenStack Platform 13 Documentation. September 20, 2018. Accessed September 26, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/pdf/release_notes/Red_Hat_OpenStack_Platform-13-Release_Notes-en-US.pdf">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/pdf/release_notes/Red_Hat_OpenStack_Platform-13-Release_Notes-en-US.pdf</a></p></li>
<li><p>“Use an external Ceph cluster with the Overcloud.” TripleO Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/ceph_external.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/ceph_external.html</a></p></li>
<li><p>“TRIPLEO AND ANSIBLE: CONFIG-DOWNLOAD WITH ANSIBLE TOWER (PART 3).” Slagle’s Blog. June 1, 2018. Accessed October 3, 2018. <a class="reference external" href="https://blogslagle.wordpress.com/2018/06/01/tripleo-and-ansible-config-download-with-ansible-tower-part-3/">https://blogslagle.wordpress.com/2018/06/01/tripleo-and-ansible-config-download-with-ansible-tower-part-3/</a></p></li>
<li><p>“Configuring Network Isolation.” TripleO Documentation. January 30, 2020. Accessed February 5, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/network_isolation.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/network_isolation.html</a></p></li>
<li><p>“Modifying default node configuration.” TripleO Documentation. September 21, 2020. Accessed September 23, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/node_config.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/node_config.html</a></p></li>
<li><p>“Containers based Overcloud Deployment.” OpenStack Documentation. October 25, 2019. Accessed October 28, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/overcloud.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/overcloud.html</a></p></li>
<li><p>CHAPTER 12. REBOOTING NODES.” Red Hat OpenStack Platform 13 Documentation. Accessed January 28, 2019. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/sect-rebooting_the_overcloud">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/sect-rebooting_the_overcloud</a></p></li>
<li><p>“Bootstrap.” InfraRed Documentation. Accessed February 8, 2019. <a class="reference external" href="https://infrared.readthedocs.io/en/stable/bootstrap.html">https://infrared.readthedocs.io/en/stable/bootstrap.html</a></p></li>
<li><p>“CHAPTER 8. CONFIGURING A BASIC OVERCLOUD USING PRE-PROVISIONED NODES.” Red Hat Documentation. Accessed January 28, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/chap-configuring_basic_overcloud_requirements_on_pre_provisioned_nodes">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/chap-configuring_basic_overcloud_requirements_on_pre_provisioned_nodes</a></p></li>
<li><p>“Using Already Deployed Servers.” OpenStack Documentation. January 30, 2020. Accessed February 4, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deployed_server.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deployed_server.html</a></p></li>
<li><p>“CHAPTER 4. INSTALLING THE UNDERCLOUD.” Red Hat Documentation. Accessed April 1, 2019. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/installing-the-undercloud">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/installing-the-undercloud</a></p></li>
<li><p>“CHAPTER 10. CONFIGURING THE OVERCLOUD WITH ANSIBLE.” Red Hat Documentation. Accessed May 14, 2019. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/configuring-the-overcloud-with-ansible">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/configuring-the-overcloud-with-ansible</a></p></li>
<li><p>“Evaluating OpenStack: Single-Node Deployment.” Red Hat Knowledgebase. October 5, 2018. Accessed May 15, 2019. <a class="reference external" href="https://access.redhat.com/articles/1127153">https://access.redhat.com/articles/1127153</a></p></li>
<li><p>“TripleO config-download User’s Guide: Deploying with Ansible.” TripleO Documentation. November 23, 2020. Accessed December 8, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/ansible_config_download.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/ansible_config_download.html</a></p></li>
<li><p>“CHAPTER 3. PREPARING FOR DIRECTOR INSTALLATION.” Red Hat RHOSP 15 Documentation. Accessed September 26, 2019. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/15/html/director_installation_and_usage/preparing-for-director-installation">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/15/html/director_installation_and_usage/preparing-for-director-installation</a></p></li>
<li><p>“The road ahead for the Red Hat OpenStack Platform.” Red Hat Blog. August 20, 2019. Accessed September 26, 2019. <a class="reference external" href="https://www.redhat.com/en/blog/road-ahead-red-hat-openstack-platform">https://www.redhat.com/en/blog/road-ahead-red-hat-openstack-platform</a></p></li>
<li><p>“Installing a Undercloud Minion.” OpenStack Documentation. October 29, 2019. Accessed November 1, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/undercloud_minion.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/undercloud_minion.html</a></p></li>
<li><p>“CHAPTER 3. PLANNING YOUR OVERCLOUD.” Red Hat Documentation. Accessed November 20, 2019. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/chap-planning_your_overcloud">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/chap-planning_your_overcloud</a></p></li>
<li><p>“Configuring High Availability.” tripleo-docs. November 20, 2019. Accessed November 20, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/high_availability.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/high_availability.html</a></p></li>
<li><p>“Scale Undercloud with a Minion.” tripleo-docs. May 3, 2019. Accessed December 3, 2019. <a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/specs/train/undercloud-minion.html">https://specs.openstack.org/openstack/tripleo-specs/specs/train/undercloud-minion.html</a></p></li>
<li><p>“Understanding undercloud/standalone stack updates.” tripleo-docs. December 19, 2019. Accessed December 19, 2019. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/updating-stacks-notes.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/updating-stacks-notes.html</a></p></li>
<li><p>“Deleting Overcloud Nodes.” TripleO Documentation. January 30, 2020. Accessed January 30, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/delete_nodes.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/delete_nodes.html</a></p></li>
<li><p>“Scaling the Overcloud. Red Hat OpenStack Platform 13 Documentation. Accessed January 30, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/sect-scaling_the_overcloud">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/director_installation_and_usage/sect-scaling_the_overcloud</a></p></li>
<li><p>“Chapter 19. Storage Configuration.” Red Hat OpenStack Platform 13 Documentation. Accessed February 5, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/advanced_overcloud_customization/storage_configuration">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/advanced_overcloud_customization/storage_configuration</a></p></li>
<li><p>“TripleO Architecture.” TripleO Documentation. August 16, 2019. Accessed February 6, 2020. <a class="reference external" href="https://docs.openstack.org/tripleo-docs/latest/install/introduction/architecture.html">https://docs.openstack.org/tripleo-docs/latest/install/introduction/architecture.html</a></p></li>
<li><p>“Overview of available RDO repos.” RDO Project. January 27, 2018. Accessed February 6, 2020. <a class="reference external" href="https://www.rdoproject.org/what/repos/">https://www.rdoproject.org/what/repos/</a></p></li>
<li><p>“Workflow: RDO Trunk repo.” RDO Project. May 24, 2019. Accessed February 6, 2020. <a class="reference external" href="https://www.rdoproject.org/what/trunk-repos/">https://www.rdoproject.org/what/trunk-repos/</a></p></li>
<li><p>“Director Installation and Usage.” Red Hat OpenStack Platform 16.0 Documentation. Accessed February 7, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html/director_installation_and_usage/index">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html/director_installation_and_usage/index</a></p></li>
<li><p>“Ensure config-download mappings are unset on ceph-upgrade.” OpenDev openstack/tripleo-heat-templates. April 27, 2018. Accessed February 10, 2020. <a class="reference external" href="https://opendev.org/openstack/tripleo-heat-templates/commit/24469e3c02747b7b6de6d61fcf2a8b9be67b370b">https://opendev.org/openstack/tripleo-heat-templates/commit/24469e3c02747b7b6de6d61fcf2a8b9be67b370b</a></p></li>
<li><p>“TripleO Project Specifications.” TripleO Documentation. October 16, 2019. Accessed February 17, 2020. <a class="reference external" href="https://specs.openstack.org/openstack/tripleo-specs/">https://specs.openstack.org/openstack/tripleo-specs/</a></p></li>
<li><p>“Blueprints for tripleo.” tripleo Launchpad. Accessed February 17, 2020. <a class="reference external" href="https://blueprints.launchpad.net/tripleo">https://blueprints.launchpad.net/tripleo</a></p></li>
<li><p>“CHAPTER 7. CONFIGURING A BASIC OVERCLOUD WITH CLI TOOLS.” Red hat RHOSP 16 Documentation. Accessed April 21, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html/director_installation_and_usage/creating-a-basic-overcloud-with-cli-tools">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html/director_installation_and_usage/creating-a-basic-overcloud-with-cli-tools</a></p></li>
<li><p>“Building a Single Image.” TripleO Documentation. April 20, 2020. Accessed April 21, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/build_single_image.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/build_single_image.html</a></p></li>
<li><p>“Network Configuration with os-net-config.” Ales Nosek - The Software Practitioner. September 28, 2015. Accessed May 4, 2020. <a class="reference external" href="http://alesnosek.com/blog/2015/09/28/network-configuration-with-os-net-config/">http://alesnosek.com/blog/2015/09/28/network-configuration-with-os-net-config/</a></p></li>
<li><p>“Linux Bridge Container Permission Issues.” Launchpad Bugs tripleo. May 4, 2020. Accessed May 4, 2020. <a class="reference external" href="https://bugs.launchpad.net/tripleo/+bug/1862179">https://bugs.launchpad.net/tripleo/+bug/1862179</a></p></li>
<li><p>“Deploying with Custom Roles.” TripleO Documentation. May 7, 2020. Accessed May 7, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/custom_roles.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/custom_roles.html</a></p></li>
<li><p>“Deploying with Composable Services.” TripleO Documentation. May 7, 2020. Accessed May 7, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/composable_services.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/composable_services.html</a></p></li>
<li><p>“Promotion Stages.” TripleO Documentation. August 16, 2019. Accessed May 26, 2020. <a class="reference external" href="https://docs.openstack.org/tripleo-docs/latest/ci/stages-overview.html">https://docs.openstack.org/tripleo-docs/latest/ci/stages-overview.html</a></p></li>
<li><p>“Scaling Red Hat OpenStack Platform to more than 500 Overcloud Nodes.” Red Hat Blog. October 28, 2019. Accessed May 26, 2020. <a class="reference external" href="https://www.redhat.com/en/blog/scaling-red-hat-openstack-platform-more-500-overcloud-nodes">https://www.redhat.com/en/blog/scaling-red-hat-openstack-platform-more-500-overcloud-nodes</a></p></li>
<li><p>“Bug 1607453 - Deployment fails with: Object GET failed: <a class="reference external" href="https://.../overcloud/plan-environment.yaml">https://…/overcloud/plan-environment.yaml</a> 404 Not Found.” Red Hat Bugzilla. November 13, 2019. Accessed May 28, 2020. <a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1607453">https://bugzilla.redhat.com/show_bug.cgi?id=1607453</a></p></li>
<li><p>“Minor version update.” TripleO Upgrade Developer Documentation. January 20, 2020. Accessed June 19, 2020. <a class="reference external" href="https://docs.openstack.org/tripleo-docs/latest/upgrade/developer/upgrades/minor_update.html">https://docs.openstack.org/tripleo-docs/latest/upgrade/developer/upgrades/minor_update.html</a></p></li>
<li><p>“Upgrading to a Next Major Release.” TripleO Upgrade Documentation. June 8, 2020. Accessed June 19, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/upgrade/major_upgrade.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/post_deployment/upgrade/major_upgrade.html</a></p></li>
<li><p>“OpenShift on OpenStack 1-2-3: Bringing IaaS and PaaS Together.” Red Hat OpenShift Blog. March 12, 2018. Accessed June 30, 2020. <a class="reference external" href="https://www.openshift.com/blog/openshift-openstack-1-2-3-bringing-iaas-paas-together">https://www.openshift.com/blog/openshift-openstack-1-2-3-bringing-iaas-paas-together</a></p></li>
<li><p>“Deploying a UPI environment for OpenShift 4.1 on VMs and Bare Metal.” Red Hat OpenShift Blog. July 15, 2019. Accessed June 30, 2020. <a class="reference external" href="https://www.openshift.com/blog/deploying-a-upi-environment-for-openshift-4-1-on-vms-and-bare-metal">https://www.openshift.com/blog/deploying-a-upi-environment-for-openshift-4-1-on-vms-and-bare-metal</a></p></li>
<li><p>“OpenStack UPI.” GitHub openshift/enhancements. September 18, 2019. Accessed June 30, 2020. <a class="reference external" href="https://github.com/openshift/enhancements/blob/master/enhancements/installer/openstack-upi.md">https://github.com/openshift/enhancements/blob/master/enhancements/installer/openstack-upi.md</a></p></li>
<li><p>“Reference Architectures 2020 Deploying Red Hat OpenShift Container Platform 4.4 on Red Hat OpenStack Platform 13 and 16.0.” Red Hat OpenShift Resources. Accessed June 30, 2020. <a class="reference external" href="https://www.redhat.com/cms/managed-files/cl-openshift-container-platform-4-4-on-openstack-platform-13-16-reference-architecture-f23768-202005-en.pdf">https://www.redhat.com/cms/managed-files/cl-openshift-container-platform-4-4-on-openstack-platform-13-16-reference-architecture-f23768-202005-en.pdf</a></p></li>
<li><p>“Quick Start Guide Red Hat OpenStack Platform 16.1-Beta.” Red Hat Documentation. Accessed July 23, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.1-beta/html-single/quick_start_guide/index">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.1-beta/html-single/quick_start_guide/index</a></p></li>
<li><p>“SERVICE TELEMETRY FRAMEWORK.” Red Hat OpenStack Platform 16.0 Service Telemetry Framework. Accessed October 21, 2020. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html-single/service_telemetry_framework/index">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/16.0/html-single/service_telemetry_framework/index</a></p></li>
<li><p>“Container Image Prepare.” TripleO Documentation. October 30, 2020. Accessed November 16, 2020. <a class="reference external" href="https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/container_image_prepare.html">https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/container_image_prepare.html</a></p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../programming/index.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="openstack-ansible.html" class="btn btn-neutral float-left" title="OpenStack-Ansible" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright None, Copyleft 2021, Luke Short. Documents licensed under GFDLv1.3.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>