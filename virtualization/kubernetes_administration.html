

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Kubernetes Administration &mdash; Root Pages  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Kubernetes Development" href="kubernetes_development.html" />
    <link rel="prev" title="Containers" href="containers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Root Pages
          

          
          </a>

          
            
            
              <div class="version">
                2021.04.01
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Administration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../administration/authentication.html">Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/chromebook.html">Chromebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/graphics.html">Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/linux.html">Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/macs.html">Macs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/mail_servers.html">Mail Servers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/operating_systems.html">Operating Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/package_managers.html">Package Managers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/security.html">Security</a></li>
</ul>
<p class="caption"><span class="caption-text">Automation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../automation/ansible.html">Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="../automation/puppet.html">Puppet</a></li>
</ul>
<p class="caption"><span class="caption-text">Computer Hardware</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/graphics_cards.html">Graphics Cards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/laptops.html">Laptops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/monitors.html">Monitors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/processors.html">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/storage_devices.html">Storage Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer_hardware/webcams.html">Webcams</a></li>
</ul>
<p class="caption"><span class="caption-text">HTTP</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../http/clustering.html">Clustering and High Availability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/cms.html">Content Management Systems (CMSs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/http_servers.html">HTTP Servers</a></li>
</ul>
<p class="caption"><span class="caption-text">Networking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../networking/dns_servers.html">DNS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../networking/networking_hardware.html">Networking (Hardware)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../networking/linux.html">Linux Networking</a></li>
</ul>
<p class="caption"><span class="caption-text">Observation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../observation/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../observation/monitoring.html">Monitoring</a></li>
</ul>
<p class="caption"><span class="caption-text">OpenStack</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../openstack/openstack.html">OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../openstack/developer.html">OpenStack Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../openstack/kolla.html">Kolla</a></li>
<li class="toctree-l1"><a class="reference internal" href="../openstack/openstack-ansible.html">OpenStack-Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="../openstack/tripleo.html">TripleO</a></li>
</ul>
<p class="caption"><span class="caption-text">Programming</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../programming/c_and_c%2B%2B.html">C and C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/devops.html">DevOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/go.html">Go</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/packaging.html">Packaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming/python.html">Python 3</a></li>
</ul>
<p class="caption"><span class="caption-text">Storage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../storage/backup_and_recovery.html">Backup and Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/bootloaders.html">Bootloaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/ceph.html">Ceph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/file_systems.html">File Systems</a></li>
</ul>
<p class="caption"><span class="caption-text">Virtualization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="containers.html">Containers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Kubernetes Administration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#architecture">Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#kubernetes">Kubernetes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#networking">Networking</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#k3s">k3s</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Networking</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#openshift">OpenShift</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tanzu">Tanzu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tkgm">TKGm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#releases">Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">OpenShift</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">Tanzu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">TKGm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#minikube">Minikube</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kubeadm">kubeadm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">k3s</a></li>
<li class="toctree-l3"><a class="reference internal" href="#minishift">Minishift</a></li>
<li class="toctree-l3"><a class="reference internal" href="#codeready-containers-crc">CodeReady Containers (CRC)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kind">kind</a></li>
<li class="toctree-l3"><a class="reference internal" href="#openshift-ansible">OpenShift Ansible</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Tanzu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">TKGm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#uninstall">Uninstall</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id10">CodeReady Containers (CRC)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">kubeadm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">k3s</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">kind</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">Tanzu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id15">TKGm</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#upgrade">Upgrade</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">Minikube</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id17">kubeadm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#control-plane-nodes">Control Plane Nodes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#worker-nodes">Worker Nodes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id18">k3s</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">kind</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ingress-controllers">Ingress Controllers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#traefik">Traefik</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#concepts">Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#container-network-interface-cni-plugins">Container Network Interface (CNI) Plugins</a></li>
<li class="toctree-l3"><a class="reference internal" href="#role-based-access-control-rbac">Role-Based Access Control (RBAC)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#user-accounts">User Accounts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tls-certificate-creation-cert-manager">TLS Certificate Creation (cert-manager)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#errors">Errors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#history">History</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bibliography">Bibliography</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="kubernetes_development.html">Kubernetes Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="virtual_machines.html">Virtual Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="wine.html">Wine</a></li>
</ul>
<p class="caption"><span class="caption-text">Commands</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../commands/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/compression.html">Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/configuration_management.html">Configuration Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/firewalls.html">Firewalls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/hardware.html">Hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/openstack.html">OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/package_managers.html">Package Managers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/permissions.html">Permissions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/phones.html">Phones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/security.html">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/software_code_management.html">Source Code Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/storage.html">Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/text_editors.html">Text Editors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../commands/virtualization.html">Virtualization</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Root Pages</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">&lt;no title&gt;</a> &raquo;</li>
        
      <li>Kubernetes Administration</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/virtualization/kubernetes_administration.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="kubernetes-administration">
<h1><a class="toc-backref" href="#id20">Kubernetes Administration</a><a class="headerlink" href="#kubernetes-administration" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#kubernetes-administration" id="id20">Kubernetes Administration</a></p>
<ul>
<li><p><a class="reference internal" href="#architecture" id="id21">Architecture</a></p>
<ul>
<li><p><a class="reference internal" href="#kubernetes" id="id22">Kubernetes</a></p>
<ul>
<li><p><a class="reference internal" href="#networking" id="id23">Networking</a></p>
<ul>
<li><p><a class="reference internal" href="#pod-networking" id="id24">Pod Networking</a></p></li>
<li><p><a class="reference internal" href="#ports" id="id25">Ports</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#k3s" id="id26">k3s</a></p>
<ul>
<li><p><a class="reference internal" href="#id1" id="id27">Networking</a></p>
<ul>
<li><p><a class="reference internal" href="#id2" id="id28">Ports</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#openshift" id="id29">OpenShift</a></p></li>
<li><p><a class="reference internal" href="#tanzu" id="id30">Tanzu</a></p>
<ul>
<li><p><a class="reference internal" href="#tkgm" id="id31">TKGm</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#releases" id="id32">Releases</a></p>
<ul>
<li><p><a class="reference internal" href="#id3" id="id33">Kubernetes</a></p></li>
<li><p><a class="reference internal" href="#id4" id="id34">OpenShift</a></p></li>
<li><p><a class="reference internal" href="#id5" id="id35">Tanzu</a></p>
<ul>
<li><p><a class="reference internal" href="#id6" id="id36">TKGm</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#installation" id="id37">Installation</a></p>
<ul>
<li><p><a class="reference internal" href="#minikube" id="id38">Minikube</a></p></li>
<li><p><a class="reference internal" href="#kubeadm" id="id39">kubeadm</a></p></li>
<li><p><a class="reference internal" href="#id7" id="id40">k3s</a></p></li>
<li><p><a class="reference internal" href="#minishift" id="id41">Minishift</a></p></li>
<li><p><a class="reference internal" href="#codeready-containers-crc" id="id42">CodeReady Containers (CRC)</a></p></li>
<li><p><a class="reference internal" href="#kind" id="id43">kind</a></p></li>
<li><p><a class="reference internal" href="#openshift-ansible" id="id44">OpenShift Ansible</a></p></li>
<li><p><a class="reference internal" href="#id8" id="id45">Tanzu</a></p>
<ul>
<li><p><a class="reference internal" href="#id9" id="id46">TKGm</a></p>
<ul>
<li><p><a class="reference internal" href="#aws" id="id47">AWS</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#uninstall" id="id48">Uninstall</a></p>
<ul>
<li><p><a class="reference internal" href="#id10" id="id49">CodeReady Containers (CRC)</a></p></li>
<li><p><a class="reference internal" href="#id11" id="id50">kubeadm</a></p></li>
<li><p><a class="reference internal" href="#id12" id="id51">k3s</a></p></li>
<li><p><a class="reference internal" href="#id13" id="id52">kind</a></p></li>
<li><p><a class="reference internal" href="#id14" id="id53">Tanzu</a></p>
<ul>
<li><p><a class="reference internal" href="#id15" id="id54">TKGm</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#upgrade" id="id55">Upgrade</a></p>
<ul>
<li><p><a class="reference internal" href="#introduction" id="id56">Introduction</a></p></li>
<li><p><a class="reference internal" href="#id16" id="id57">Minikube</a></p></li>
<li><p><a class="reference internal" href="#id17" id="id58">kubeadm</a></p>
<ul>
<li><p><a class="reference internal" href="#control-plane-nodes" id="id59">Control Plane Nodes</a></p></li>
<li><p><a class="reference internal" href="#worker-nodes" id="id60">Worker Nodes</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id18" id="id61">k3s</a></p></li>
<li><p><a class="reference internal" href="#id19" id="id62">kind</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ingress-controllers" id="id63">Ingress Controllers</a></p>
<ul>
<li><p><a class="reference internal" href="#traefik" id="id64">Traefik</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#concepts" id="id65">Concepts</a></p>
<ul>
<li><p><a class="reference internal" href="#container-network-interface-cni-plugins" id="id66">Container Network Interface (CNI) Plugins</a></p></li>
<li><p><a class="reference internal" href="#role-based-access-control-rbac" id="id67">Role-Based Access Control (RBAC)</a></p>
<ul>
<li><p><a class="reference internal" href="#user-accounts" id="id68">User Accounts</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tls-certificate-creation-cert-manager" id="id69">TLS Certificate Creation (cert-manager)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#troubleshooting" id="id70">Troubleshooting</a></p>
<ul>
<li><p><a class="reference internal" href="#errors" id="id71">Errors</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#history" id="id72">History</a></p></li>
<li><p><a class="reference internal" href="#bibliography" id="id73">Bibliography</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="architecture">
<h2><a class="toc-backref" href="#id21">Architecture</a><a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h2>
<div class="section" id="kubernetes">
<h3><a class="toc-backref" href="#id22">Kubernetes</a><a class="headerlink" href="#kubernetes" title="Permalink to this headline">¶</a></h3>
<p>Kubernetes, also known as k8s, is an open-source container management platform. It handles the life-cycle of Pods which are a collection of related containers required to run an application. Kubernetes clusters contain two types of servers:</p>
<ul class="simple">
<li><p>Control Plane Node (previously known as Master Node) = Manages the state of the Nodes and their Pods.</p></li>
<li><p>Worker Node (previously known as Node, Worker, Worker Machines, or Minion) = Run user applications in containers and respond to requests from the Control Plane Nodes.</p></li>
</ul>
<p>Control Plane Node services:</p>
<ul class="simple">
<li><p>etcd = The most common database for storing all of the Kubernetes configuration data.</p></li>
<li><p>kube-apiserver = Handles authentication requests and retrieving/storing data from/to etcd.</p></li>
<li><p>kube-controller-manager = Monitors and controls Kubernetes resources. It will perform recovery tasks if a failure is detected. This binary runs many different controller processes:</p>
<ul>
<li><p>attachdetach, bootstrapsigner, cloud-node-lifecycle, clusterrole-aggregation, cronjob, csrapproving, csrcleaner, csrsigning, daemonset, deployment, disruption, endpoint, endpointslice, garbagecollector, horizontalpodautoscaling, job, namespace, nodeipam, nodelifecycle, persistentvolume-binder, persistentvolume-expander, podgc, pv-protection, pvc-protection, replicaset, replicationcontroller, resourcequota, root-ca-cert-publisher, route, service, serviceaccount, serviceaccount-token, statefulset, tokencleaner, ttl, ttl-after-finished [18]</p></li>
</ul>
</li>
<li><p>kube-scheduler = Determines what Node to schedule a Pod on.</p></li>
</ul>
<p>Worker Node services:</p>
<ul class="simple">
<li><p>Container runtime = Any service for executing containers that supports the Container Runtime Interface (CRI). Kubernetes officially supports containerd, CRI-O, and docker. [42]</p></li>
<li><p>kubelet = Manages containers using the container runtime.</p></li>
<li><p>kube-proxy = Handles virtual networking connections for internal (containers across different Nodes) and external (Kubernetes Services) use.</p></li>
</ul>
<p>[1]</p>
<div class="section" id="networking">
<h4><a class="toc-backref" href="#id23">Networking</a><a class="headerlink" href="#networking" title="Permalink to this headline">¶</a></h4>
<div class="section" id="pod-networking">
<h5><a class="toc-backref" href="#id24">Pod Networking</a><a class="headerlink" href="#pod-networking" title="Permalink to this headline">¶</a></h5>
<p>Kubernetes requires a Container Network Interface (CNI) plugin to create an overlay network for inter-communication between Pods across all of the Control Plane and Worker Nodes. The default Pod network CIDR (as configured by <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">--pod-network-cidr</span></code>) is normally assumed to be 10.244.0.0/16.</p>
</div>
<div class="section" id="ports">
<h5><a class="toc-backref" href="#id25">Ports</a><a class="headerlink" href="#ports" title="Permalink to this headline">¶</a></h5>
<p>Depending on the role of the Node and what Container Network Interface (CNI) plugin is used, different ports need to be opened in the firewall.</p>
<p>Control Plane Nodes:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Port</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>2379/TCP</p></td>
<td><p>etcd client.</p></td>
</tr>
<tr class="row-odd"><td><p>2380/TCP</p></td>
<td><p>etcd server.</p></td>
</tr>
<tr class="row-even"><td><p>6443/TCP</p></td>
<td><p>kube-api-server.</p></td>
</tr>
<tr class="row-odd"><td><p>10250/TCP</p></td>
<td><p>kubelet.</p></td>
</tr>
<tr class="row-even"><td><p>10251/TCP</p></td>
<td><p>kube-scheduler.</p></td>
</tr>
<tr class="row-odd"><td><p>10252/TCP</p></td>
<td><p>kube-controller-manager.</p></td>
</tr>
<tr class="row-even"><td><p>10254/TCP</p></td>
<td><p>Ingress Controller probes.</p></td>
</tr>
<tr class="row-odd"><td><p>30000-32767/TCP+UDP</p></td>
<td><p>Default NodePort ports when a port is not specified.</p></td>
</tr>
</tbody>
</table>
<p>Worker Nodes:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Port</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>10250/TCP</p></td>
<td><p>kubelet.</p></td>
</tr>
<tr class="row-odd"><td><p>30000-32767/TCP+UDP</p></td>
<td><p>Default NodePort ports when a port is not specified.</p></td>
</tr>
</tbody>
</table>
<p>CNI Ports (All Nodes):</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Port</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>179/TCP</p></td>
<td><p>Calico BGP.</p></td>
</tr>
<tr class="row-odd"><td><p>8472/UDP</p></td>
<td><p>Flannel VXLAN overlay network (Linux).</p></td>
</tr>
<tr class="row-even"><td><p>4789/UDP</p></td>
<td><p>Flannel VXLAN overlay network (Windows).</p></td>
</tr>
<tr class="row-odd"><td><p>9099/TCP</p></td>
<td><p>Flannel probes.</p></td>
</tr>
<tr class="row-even"><td><p>6783/TCP</p></td>
<td><p>Weave.</p></td>
</tr>
<tr class="row-odd"><td><p>6783-6784/UDP</p></td>
<td><p>Weave.</p></td>
</tr>
</tbody>
</table>
<p>[47]</p>
</div>
</div>
</div>
<div class="section" id="k3s">
<h3><a class="toc-backref" href="#id26">k3s</a><a class="headerlink" href="#k3s" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id1">
<h4><a class="toc-backref" href="#id27">Networking</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<div class="section" id="id2">
<h5><a class="toc-backref" href="#id28">Ports</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h5>
<p>Control Plane Nodes:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Port</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>22/TCP</p></td>
<td><p>SSH for the Node Driver.</p></td>
</tr>
<tr class="row-odd"><td><p>80/TCP</p></td>
<td><p>Proxy to use with an external SSL/TLS termination app.</p></td>
</tr>
<tr class="row-even"><td><p>443/TCP</p></td>
<td><p>Rancher UI and API. Rancher Catalogs.</p></td>
</tr>
<tr class="row-odd"><td><p>2376/TCP</p></td>
<td><p>Docker TLS port for Docker Machine.</p></td>
</tr>
<tr class="row-even"><td><p>6443/TCP</p></td>
<td><p>kube-api-server.</p></td>
</tr>
<tr class="row-odd"><td><p>8472/UDP</p></td>
<td><p>Flannel VXLAN overlay network (Linux).</p></td>
</tr>
<tr class="row-even"><td><p>10250/TCP</p></td>
<td><p>kubelet.</p></td>
</tr>
</tbody>
</table>
<p>Worker Nodes:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Port</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>22/TCP</p></td>
<td><p>SSH for the Node Driver.</p></td>
</tr>
<tr class="row-odd"><td><p>443/TCP</p></td>
<td><p>Rancher Catalogs.</p></td>
</tr>
<tr class="row-even"><td><p>2376/TCP</p></td>
<td><p>Docker TLS port for Docker Machine.</p></td>
</tr>
<tr class="row-odd"><td><p>8472/UDP</p></td>
<td><p>Flannel VXLAN overlay network (Linux).</p></td>
</tr>
<tr class="row-even"><td><p>10250/TCP</p></td>
<td><p>kubelet.</p></td>
</tr>
</tbody>
</table>
<p>[47]</p>
</div>
</div>
</div>
<div class="section" id="openshift">
<h3><a class="toc-backref" href="#id29">OpenShift</a><a class="headerlink" href="#openshift" title="Permalink to this headline">¶</a></h3>
<p>The Red Hat OpenShift Container Platform (RHOCP) is an enterprise product based on Google’s Kubernetes. [16] It has a stronger focus on security with support for having access control lists (ACLs) for managing containers in separate projects and full SELinux support. It also provides more features to extend Kubernetes functionality.</p>
<p>The Origin Kubernetes Distribution (OKD), originally known as OpenShift Origin, is the free and open source community edition of RHOCP. [4] OKD 4.5 was the first stable release for the 4.Y series. [21] It supports being deployed ontop of Red Hat CoreOS and Fedora CoreOS. [21]</p>
<p>OpenShift has 3 primary architectures:</p>
<ul class="simple">
<li><p>Single Node (OKD only) = Proof-of-concept deployments with all OpenShift services running on a single Node.</p></li>
<li><p>Three Node = Edge deployments using multiple Single Nodes.</p></li>
<li><p>Full = Production deployments (recommended minimum requirements). [23]</p>
<ul>
<li><p>x3 Control Nodes</p></li>
<li><p>x2 Logging and monitoring Nodes</p></li>
<li><p>x3 Routing Nodes</p></li>
<li><p>x2 Worker Nodes</p></li>
</ul>
</li>
</ul>
<p>Node types and services:</p>
<ul class="simple">
<li><p>Control = These Nodes have to be deployed using Red Hat CoreOS (RHOCP) or Fedora CoreOS (OKD). [24] All other Nodes can use RHEL (RHOCP) or Fedora (OKD).</p>
<ul>
<li><p>etcd</p></li>
<li><p>kube-api</p></li>
<li><p>kube-controller-manager</p></li>
</ul>
</li>
<li><p>Logging and Monitoring [25]</p>
<ul>
<li><p>EFK stack</p>
<ul>
<li><p>Fluentd = Log collection.</p></li>
<li><p>Elasticsearch = Log storage.</p></li>
<li><p>Kibana = Visualization.</p></li>
</ul>
</li>
<li><p>Curator = Log filtering (based on timestamps) in OpenShift &lt; 4.5.</p></li>
</ul>
</li>
<li><p>Router = This Node is optional and is combined with the Control Node by default. [26]</p>
<ul>
<li><p>Ingress = HAProxy and/or F5 BIG-IP.</p></li>
</ul>
</li>
<li><p>Worker/Compute = The life-cycle of these Nodes are handled by the MachineSet API. Control Plane Nodes do not use the MachineSet API as to prevent accidental deletion of the control plane. [24]</p>
<ul>
<li><p>CRI-O (container runtime)</p></li>
<li><p>kubelet</p></li>
</ul>
</li>
</ul>
<p>Supported infrastructure for installing OpenShift on [27]:</p>
<ul class="simple">
<li><p>Public cloud</p>
<ul>
<li><p>Amazon Web Services (AWS)</p></li>
<li><p>Google Compute Platform (GCP)</p></li>
<li><p>Microsoft Azure</p></li>
</ul>
</li>
<li><p>On-site</p>
<ul>
<li><p>Bare metal</p></li>
<li><p>OpenStack</p></li>
<li><p>Red Hat Virtualization (RHV)</p></li>
<li><p>VMWare vSphere</p></li>
</ul>
</li>
</ul>
<p>PersistentVolume support [3]:</p>
<ul class="simple">
<li><p>AWS Elastic Block Store (EBS)</p></li>
<li><p>Azure Disk</p></li>
<li><p>Azure File</p></li>
<li><p>Cinder</p></li>
<li><p>Container Storage Interface (CSI) = Any storage provider that uses CSI as a front-end can be used with OpenShift.</p></li>
<li><p>Fibre Channel</p></li>
<li><p>Google Compute Engine (GCE) Persistent Disk</p></li>
<li><p>HostPath</p></li>
<li><p>iSCSI</p></li>
<li><p>Local volume</p></li>
<li><p>NFS</p></li>
<li><p>Red Hat OpenShift Container Storage (Ceph RBD)</p></li>
<li><p>VMWare vSphere</p></li>
</ul>
</div>
<div class="section" id="tanzu">
<h3><a class="toc-backref" href="#id30">Tanzu</a><a class="headerlink" href="#tanzu" title="Permalink to this headline">¶</a></h3>
<p>Tanzu (pronounced tawn-zoo) Kubernetes Grid (TKG) is developed by VMware as a collection of different products to install upstream Kubernetes.</p>
<p>There are currently three offerings for TKG [54]:</p>
<ul class="simple">
<li><p><strong>TKG Multicloud (TKGm)</strong> = TKGm supports creating and managing infrastructure on Amazon Web Services, Microsoft Azure, and VMware vSphere 6. For VMware vSphere 7, TKGm can be used but TKGS is recommended instead.</p></li>
<li><p><strong>TKG Services (TKGS)</strong> = VMware vSphere 7 creates and manages the Kubernetes cluster.</p></li>
<li><p><strong>TKG Integrated Edition (TKGI)</strong> = Previosuly Enterprise PKS. Uses BOSH to deploy and manage virtual machines for the Kubernetes cluster. BOSH supports creating infrastructure on Alibaba Cloud, Amazon Web Services, Google Cloud Platform, Microsoft Azure, OpenStack, and VMware vSphere. [55]</p></li>
</ul>
<div class="section" id="tkgm">
<h4><a class="toc-backref" href="#id31">TKGm</a><a class="headerlink" href="#tkgm" title="Permalink to this headline">¶</a></h4>
<p>TKGm stands for TKG Multicloud. It is a product for installing Kubernetes on-top of virtual infrastructure provided by AWS, Azure, GCE, or VMware vSphere. It first deploys an all-in-one TKG Management Cluster using <a class="reference external" href="https://kind.sigs.k8s.io/">kind</a>. This then uses the <a class="reference external" href="https://cluster-api.sigs.k8s.io/">Cluster API</a> to deploy and manage one or more production Kubernetes clouds. [32]</p>
</div>
</div>
</div>
<div class="section" id="releases">
<h2><a class="toc-backref" href="#id32">Releases</a><a class="headerlink" href="#releases" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id3">
<h3><a class="toc-backref" href="#id33">Kubernetes</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Kubernetes was originally created by Google in 2003 and was called the Borg System. In 2014, it was renamed to Kubernetes and released as open-source software under the Apache License version 2.0. [2]</p>
<p>Release highlights:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.zdnet.com/article/google-releases-kubernetes-1-0/">1.0</a></p>
<ul>
<li><p>First stable public release of Kubernetes.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2015/11/kubernetes-1-1-performance-upgrades-improved-tooling-and-a-growing-community/">1.1</a></p>
<ul>
<li><p><a class="reference external" href="https://learnk8s.io/autoscaling-apps-kubernetes">Horizontal Pod Autoscaler</a> added to automatically scale the number of containers based on metrics inside of a running Pod.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a> now supports HTTP load balancing.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">Job objects</a> are added to allow an app to run until it successfully completes.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.2.md">1.2</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/">ConfigMap objects</a> now support Dynamic Configuration to allow Pod changes at any time.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment objects</a> now supports Turnkey Deployments to automate the full life-cycle of a Pod.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">DaemonSet objects</a> added to run one Pod on every Node.</p></li>
<li><p>Ingress now supports TLS.</p></li>
<li><p>Introduced <a class="reference external" href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#drain">kubectl drain</a> to force all Pods to be moved off one Node to other Nodes.</p></li>
<li><p>Added an optional web graphical user interface (GUI) known as the Kubernetes <a class="reference external" href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Dashboard</a>.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2016/07/kubernetes-1-3-bridging-cloud-native-and-enterprise-workloads/">1.3</a></p>
<ul>
<li><p><a class="reference external" href="https://minikube.sigs.k8s.io/docs/">Minikube</a> was created for quick and easy development environment for Kubernetes.</p></li>
<li><p><a class="reference external" href="https://github.com/containernetworking/cni">Container Network Interface (CNI)</a> is now supported.</p></li>
<li><p><a class="reference external" href="https://coreos.com/rkt/">rkt</a> can now be used as a container runtime.</p></li>
<li><p>Cross-cluster discovery support for running Pods across multiple clouds.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">PetSet objects</a> (later <a class="reference external" href="https://github.com/kubernetes/kubernetes/issues/35534">renamed to SatefulSet</a>) introduced for running stateful applications such as databases.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2016/09/kubernetes-1-4-making-it-easy-to-run-on-kuberentes-anywhere/">1.4</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/">kubeadm</a> introduced for installing Kubernetes clusters.</p></li>
<li><p>ScheduledJob objects (later named to <a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">CronJob</a>) added to run an application during a regularyly scheduled time.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/">PodSecurityPolicies</a> object added for setting the security context of containers.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity">Anti- and Inter-Affinity</a> for helping to select which Nodes a Pod will be deployed on.</p></li>
<li><p>AppArmor support.</p></li>
<li><p>Azure Data Disk and Quobyte volume plugins.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2016/12/kubernetes-1-5-supporting-production-workloads/">1.5</a></p>
<ul>
<li><p><a class="reference external" href="https://github.com/kubernetes-sigs/kubefed/blob/master/docs/userguide.md">kubefed</a> command for manginging federated Kubernetes clusters.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/run-application/configure-pdb/">PodDistruptionBudget</a> object allows for managing Node eviction rules.</p></li>
<li><p>Windows container support.</p></li>
<li><p><a class="reference external" href="https://developer.ibm.com/technologies/containers/blogs/kube-cri-overview/">Container Runtime Interface (CRI)</a> allows different runtimes besides docker.</p></li>
<li><p>Functionality tests for Nodes.</p></li>
<li><p>PetSet renamed to StatefulSet.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://coreos.com/blog/kubernetes-1-6.html">1.6</a></p>
<ul>
<li><p>The first release of Kubernetes not from Google (from CoreOS).</p></li>
<li><p>etcd now defaults to version 3.</p></li>
<li><p>docker is no longer a dependency. Other runtimes such as rkt and CRI-O are supported.</p></li>
<li><p>RBAC is now in beta.</p></li>
<li><p>PersistentVolumeClaim objects will now be created automatically.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.redhat.com/en/blog/whats-new-kubernetes-17-extensibility-rules">1.7</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/">Custom Resource Definitions (CRDs)</a> allows existing APIs to have expanded functionality.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">API Aggregation</a> allows new APIs to be natively added to Kubernetes.</p></li>
<li><p>Secrets can now be encrypted in etcd.</p></li>
<li><p>Nodes can now have limited access to a subset of the Kubernetes APIs (only the ones it needs).</p></li>
<li><p>Extensible External Admission Control adds additional security policies and checks.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy API</a> is now stable.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.8.md#notable-features">1.8</a></p>
<ul>
<li><p>RBAC is now stable.</p></li>
<li><p>Storage mount options are now stable.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/">kubectl plugins</a> are now supported to extend the CLI’s functionality.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2017/12/kubernetes-19-workloads-expanded-ecosystem/">1.9</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#-strong-workloads-apis-strong-">Workloads APIs</a> are now stable.</p></li>
<li><p>Introduced Container Storage Interface (CSI) for adding additional storage back-ends to Kubernetes.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/administer-cluster/coredns/">CoreDNS installation</a> is now supported by <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2018/03/26/kubernetes-1.10-stabilizing-storage-security-networking/">1.10</a></p>
<ul>
<li><p>Third-party authentication can now be used with <code class="docutils literal notranslate"><span class="pre">kubectl</span></code>.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2018/06/27/kubernetes-1.11-release-announcement/">1.11</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/">IPVS load balancing</a> is now stable.</p></li>
<li><p>CoreDNS support is now stable.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2018/09/27/kubernetes-1.12-kubelet-tls-bootstrap-and-azure-virtual-machine-scale-sets-vmss-move-to-general-availability/">1.12</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/">Kubelet TLS Bootstrap</a> is now stable.</p></li>
<li><p>Snapshot support for CSI managed Persistent Volumes.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2018/12/03/kubernetes-1-13-release-announcement/">1.13</a></p>
<ul>
<li><p><a class="reference external" href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/">kubeadm</a> is now officially supported for installing and setting up a Kubernetes cluster.</p></li>
<li><p><a class="reference external" href="https://coredns.io/">CoreDNS</a> is the default DNS provider.</p></li>
<li><p><a class="reference external" href="https://kubernetes-csi.github.io/docs/drivers.html">Container Storage Interface (CSI)</a> is now stable for integrating more cloud storage solutions.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement/">1.14</a></p>
<ul>
<li><p>Windows Nodes is now stable.</p></li>
<li><p>Persistent Local Volumes is now stable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kubectl</span></code> plugin mechanism is now stable.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2019/06/19/kubernetes-1-15-release-announcement/">1.15</a></p>
<ul>
<li><p>CRDs now support default settings.</p></li>
<li><p>Storage plugins are being converted to use CSI instead.</p></li>
<li><p>Cloning CSI Persistent Volumes is now supported.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/">1.16</a></p>
<ul>
<li><p>CRDs are now stable.</p></li>
<li><p>Metrics now use a registry (just as how all other Kubernetes services do).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> now supports joining and reseting Windows Nodes.</p></li>
<li><p>CSI support on Windows.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlice API</a> introduced as a scalable alternative to Endpoints.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-release-announcement/">1.17</a></p>
<ul>
<li><p>Cloud Provider Labels are now stable.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2020/03/25/kubernetes-1-18-release-announcement/">1.18</a></p>
<ul>
<li><p>Topology Manager API now supports NUMA CPU pinning.</p></li>
<li><p><a class="reference external" href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-running-pod/#ephemeral-container">kubectl alpha debug</a> argument introduced to attach a temporary container to a running container for troubleshooting purposes.</p></li>
<li><p>Windows CSI now supports privileged storage configurations.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://kubernetes.io/blog/2020/08/26/kubernetes-release-1.19-accentuate-the-paw-sitive/">1.19</a></p>
<ul>
<li><p>Each major Kubernetes release is now supported for 12 months (up from 9).</p></li>
<li><p>APIs that are in-development must reach the next tier of stability during the next Kubernetes release. If not, they will be deprecated and removed from the project.</p></li>
<li><p>New APIs:</p>
<ul>
<li><p>EndpointSlice</p></li>
<li><p>CSIStorageCapacity = An object is automatically created for a supported CSI driver to report back the available storage.</p></li>
</ul>
</li>
<li><p>Stable APIs:</p>
<ul>
<li><p>CertificateSigningRequest</p></li>
<li><p>Event</p></li>
<li><p>Ingress</p></li>
</ul>
</li>
<li><p>TLS 1.3 support.</p></li>
<li><p>Ephemeral PVCs.</p></li>
<li><p>Consistent log format for all Kubernetes control plane logs.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id4">
<h3><a class="toc-backref" href="#id34">OpenShift</a><a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Below is a list of RHOCP and OKD versions that correspond with the upstream Kubernetes release. The RHOCP 4.0 release was skipped and used for internal testing only. RHOCP 4 introduced Operators and OperatorHub. It also requires all Control Plane Nodes to be installed on Red Hat CoreOS. [5]</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>RHOCP/OKD</p></th>
<th class="head"><p>Kubernetes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>4.5</p></td>
<td><p>1.18</p></td>
</tr>
<tr class="row-odd"><td><p>4.4</p></td>
<td><p>1.17</p></td>
</tr>
<tr class="row-even"><td><p>4.3</p></td>
<td><p>1.16</p></td>
</tr>
<tr class="row-odd"><td><p>4.2</p></td>
<td><p>1.14</p></td>
</tr>
<tr class="row-even"><td><p>4.1</p></td>
<td><p>1.13</p></td>
</tr>
<tr class="row-odd"><td><p>3.11</p></td>
<td><p>1.11</p></td>
</tr>
<tr class="row-even"><td><p>3.10</p></td>
<td><p>1.10</p></td>
</tr>
<tr class="row-odd"><td><p>3.9</p></td>
<td><p>1.9</p></td>
</tr>
</tbody>
</table>
<p>Every release of RHOCP is supported for about 1.5 years. When <code class="docutils literal notranslate"><span class="pre">&lt;RHOCP_RELEASE&gt;</span> <span class="pre">+</span> <span class="pre">3</span></code> is released, the <code class="docutils literal notranslate"><span class="pre">&lt;RHOCP_RELEASE&gt;</span></code> soon becomes end-of-life. [6]</p>
</div>
<div class="section" id="id5">
<h3><a class="toc-backref" href="#id35">Tanzu</a><a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id6">
<h4><a class="toc-backref" href="#id36">TKGm</a><a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>Tanzu supports a few of the versions of Kubernetes. Listed below is the minimum Tanzu Kubernetes Grid (TKG) version to deploy the specified Kubernetes version. [33]</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>TKG</p></th>
<th class="head"><p>Kubernetes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1.2.0</p></td>
<td><p>1.19.1, 1.18.8, and 1.17.11</p></td>
</tr>
<tr class="row-odd"><td><p>1.1.0</p></td>
<td><p>1.18.6 and 1.17.9</p></td>
</tr>
<tr class="row-even"><td><p>1.0.0</p></td>
<td><p>1.17.3</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="section" id="installation">
<h2><a class="toc-backref" href="#id37">Installation</a><a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="minikube">
<h3><a class="toc-backref" href="#id38">Minikube</a><a class="headerlink" href="#minikube" title="Permalink to this headline">¶</a></h3>
<p>Minikube deploys a virtual machine with Kubernetes pre-installed as a test environment for developers. This is only supported on x86_64 processors.</p>
<p>Download the latest Minikube release from <a class="reference external" href="https://github.com/kubernetes/minikube/releases">here</a>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">MINIKUBE_VER</span><span class="o">=</span><span class="m">1</span>.8.2
$ sudo curl -L https://github.com/kubernetes/minikube/releases/download/v<span class="si">${</span><span class="nv">MINIKUBE_VER</span><span class="si">}</span>/minikube-linux-amd64 -o /usr/local/bin/minikube
$ sudo chmod +x /usr/local/bin/minikube
</pre></div>
</div>
<p>Optionally install a driver such as KVM2. The <code class="docutils literal notranslate"><span class="pre">minikube</span></code> installer will automatically download it if it cannot be found.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo curl -L https://github.com/kubernetes/minikube/releases/download/v<span class="si">${</span><span class="nv">MINIKUBE_VER</span><span class="si">}</span>/docker-machine-driver-kvm2 -o /usr/local/bin/docker-machine-driver-kvm2
$ sudo chmod +x /usr/local/bin/docker-machine-driver-kvm2
</pre></div>
</div>
<p>Deploy Kubernetes. Optionally specify the Kubernetes version to use. If using the <code class="docutils literal notranslate"><span class="pre">kvm2</span></code> driver as the root user, the <code class="docutils literal notranslate"><span class="pre">--force</span></code> argument is also required.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ minikube start --vm-driver kvm2 --kubernetes-version <span class="si">${</span><span class="nv">KUBERNETES_VERSION</span><span class="si">}</span>
</pre></div>
</div>
<p>[7]</p>
</div>
<div class="section" id="kubeadm">
<h3><a class="toc-backref" href="#id39">kubeadm</a><a class="headerlink" href="#kubeadm" title="Permalink to this headline">¶</a></h3>
<p>Supported operating systems:</p>
<ul class="simple">
<li><p>Debian &gt;= 9, Ubuntu &gt;= 16.04</p></li>
<li><p>Fedora &gt;= 25</p></li>
<li><p>Flatcar Container Linux</p></li>
<li><p>HypriotOS &gt;= 1.0.1</p></li>
<li><p>RHEL/CentOS &gt;= 7</p></li>
</ul>
<p>The official <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> utility is used to quickly create production environments and manage their life-cycle. This tool had became stable and supported since the Kubernetes 1.13 release. [8] Install it using the instructions found <a class="reference external" href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">here</a>. Other pre-requisite steps include disabling swap partitions, enabling IP forwarding, and installing docker. On RHEL/CentOS, SELinux needs to be disabled as it is not supported for use with kubeadm.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo swapoff --all
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo modprobe br_netfilter
$ <span class="nb">echo</span> <span class="s2">&quot;net.ipv4.ip_forward = 1&quot;</span> <span class="p">|</span> sudo tee -a /etc/sysctl.conf
$ sudo sysctl -p
</pre></div>
</div>
<p>Install Kubernetes. This will bootstrap a <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> container which will read manifest files to create all of the other required services as containers.</p>
<p>Syntax for a single Control Plane Node:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm init --pod-network-cidr<span class="o">=</span><span class="m">10</span>.244.0.0/16
</pre></div>
</div>
<p>Syntax for the first of many Control Plane Nodes (take note of the <code class="docutils literal notranslate"><span class="pre">[upload-certs]</span> <span class="pre">Using</span> <span class="pre">certificate</span> <span class="pre">key</span></code> message that will appear as it will be required later):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm init --pod-network-cidr<span class="o">=</span><span class="m">10</span>.244.0.0/16 --upload-certs --control-plane-endpoint &lt;LOAD_BALANCED_IP&gt;:6443
</pre></div>
</div>
<p>Although it is <a class="reference external" href="https://blog.scottlowe.org/2019/08/12/converting-kubernetes-to-ha-control-plane/">possible to change the Control Plane endpoint</a> for a highly available cluster, it is not recommended. Ensure it is configured to a load balanced IP address and not just a single IP address of one of the Control Plane Nodes.</p>
<p>Load the administrator Kubernetes configuration file as root and continue. Otherwise, copy the configuration file to the local user.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ su -
<span class="c1"># export KUBECONFIG=/etc/kubernetes/admin.conf</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ mkdir -p <span class="nv">$HOME</span>/.kube
$ sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
$ sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</pre></div>
</div>
<p>Install the Canal (Flannel and Calico) Container Network Interface (CNI) plugins. Otherwise, the first Control Plane Node will be stuck in the “NotReady” state as seen by <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">nodes</span></code>.</p>
<p>Flannel [48]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</pre></div>
</div>
<p>Calico [49]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f https://docs.projectcalico.org/manifests/canal.yaml
</pre></div>
</div>
<p>Create an authentication token if the original deployment token expired.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubeadm token list
$ kubeadm token create
</pre></div>
</div>
<p>Look-up the discovery token hash by using the certificate authority file.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt <span class="p">|</span> openssl rsa -pubin -outform der <span class="m">2</span>&gt;/dev/null <span class="p">|</span> openssl dgst -sha256 -hex <span class="p">|</span> sed <span class="s1">&#39;s/^.* //&#39;</span>
</pre></div>
</div>
<p>On the Worker Nodes, add them to the cluster by running:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm join --token &lt;TOKEN&gt; &lt;MASTER_IP_ADDRESS&gt;:6443 --discovery-token-ca-cert-hash sha256:&lt;HASH&gt;
</pre></div>
</div>
<p>Optionally allow Control Plane Nodes to also run Pods.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl taint nodes --all node-role.kubernetes.io/master-
</pre></div>
</div>
<p>[9]</p>
</div>
<div class="section" id="id7">
<h3><a class="toc-backref" href="#id40">k3s</a><a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>k3s was created by Rancher Labs as a simple way to deploy small Kubernetes clusters quickly. It supports both x86 and ARM processors. It uses the <code class="docutils literal notranslate"><span class="pre">containerd</span></code> runtime by default, CoreDNS for hostname resolution and management, and Flannel for networking. All of the tools and resources are provided in a single <code class="docutils literal notranslate"><span class="pre">k3s</span></code> binary. All beta and alpha features of Kubernetes have been removed to keep the binary small.</p>
<p>Pre-requisites:</p>
<p><a class="reference external" href="https://github.com/k3s-io/k3s/issues/1825">cgroupsv2 were not supported until v1.20.4+ks1</a>. For older releases, force the use of cgroupsv1 and then reboot the Node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo vim /etc/default/grub
<span class="nv">GRUB_CMDLINE_LINUX_DEFAULT</span><span class="o">=</span><span class="s2">&quot;quiet cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory&quot;</span>
$ sudo update-grub
</pre></div>
</div>
<p>Common installation environment variables [50]:</p>
<ul class="simple">
<li><p>INSTALL_K3S_VERSION = The version of k3s to install. Specify a <a class="reference external" href="https://github.com/k3s-io/k3s/tags">k3s tag from GitHub</a>.</p></li>
<li><p>INSTALL_K3S_CHANNEL = <code class="docutils literal notranslate"><span class="pre">stable</span></code> (default), <code class="docutils literal notranslate"><span class="pre">latest</span></code>, or <code class="docutils literal notranslate"><span class="pre">testing</span></code>. The current version tied to the channel is listed <a class="reference external" href="https://update.k3s.io/v1-release/channels">here</a>.</p></li>
<li><p>K3S_URL = The Control Plane endpoint URL to connect to. The URL is provided after a successful installation of the first Control Plane Node. This variable will also set the Node to become a Worker Node.</p></li>
<li><p>K3S_TOKEN = Required for the Worker Node. The token credential to connect to the Kubernetes cluster.</p></li>
</ul>
<p>The installation script will download the <code class="docutils literal notranslate"><span class="pre">k3s</span></code> binary, setup the systemd unit file, enable the service (<code class="docutils literal notranslate"><span class="pre">k3s</span></code> for Control Plane Nodes and <code class="docutils literal notranslate"><span class="pre">k3s-agent</span></code> for Worker Nodes), then start the service.</p>
<p>Control Plane Node:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -sfL https://get.k3s.io <span class="p">|</span> <span class="nv">INSTALL_K3S_CHANNEL</span><span class="o">=</span>latest sh -
</pre></div>
</div>
<p>Find the token:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo cat /var/lib/rancher/k3s/server/node-token
</pre></div>
</div>
<p>Worker Nodes:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -sfL https://get.k3s.io <span class="p">|</span> <span class="nv">K3S_TOKEN</span><span class="o">=</span>&lt;TOKEN&gt; <span class="nv">K3S_URL</span><span class="o">=</span>https://&lt;MASTER_HOST&gt;:6443 <span class="nv">INSTALL_K3S_CHANNEL</span><span class="o">=</span>latest sh -
</pre></div>
</div>
<p><strong>Commands</strong></p>
<p>Access the <code class="docutils literal notranslate"><span class="pre">kubectl</span></code> command through <code class="docutils literal notranslate"><span class="pre">k3s</span></code> to manage resources on the cluster.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo k3s kubectl --help
</pre></div>
</div>
<p>For using the <code class="docutils literal notranslate"><span class="pre">kubectl</span></code> command on other systems, copy the configuration from the Control Plane Node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ scp root@&lt;MASTER&gt;:/etc/rancher/k3s/k3s.yaml ~/.kube/config
$ sed -i s<span class="s1">&#39;/localhost/&lt;MASTER_HOST&gt;/&#39;</span>g ~/.kube/config
</pre></div>
</div>
<p>[10]</p>
<p>For storage, k3s supports all of the stable Container Storage Interface (CSI) and sample driver providers. As of k3s v0.4.0 (Kubernetes 1.14.0), these are the supported providers:</p>
<ul class="simple">
<li><p>Alicloud Elastic Block Storage</p></li>
<li><p>Alicloud Elastic File System</p></li>
<li><p>Alicloud OSS</p></li>
<li><p>AWS Elastic File System</p></li>
<li><p>AWS Elastic Storage</p></li>
<li><p>AWS FSx for Lustre</p></li>
<li><p>CephFS</p></li>
<li><p>Cinder</p></li>
<li><p>cloudscale.ch</p></li>
<li><p>Datera</p></li>
<li><p>DigitalOcean Block Storage</p></li>
<li><p>DriveScale</p></li>
<li><p>Flexvolume</p></li>
<li><p>GlusterFS</p></li>
<li><p>Hitachi Vantra</p></li>
<li><p>HostPath</p></li>
<li><p>Linode Block Storage</p></li>
<li><p>LINSTOR</p></li>
<li><p>MapR</p></li>
<li><p>NFS</p></li>
<li><p>Portworx</p></li>
<li><p>QingCloud CSI</p></li>
<li><p>QingStor CSI</p></li>
<li><p>Quobyte</p></li>
<li><p>RBD</p></li>
<li><p>ScaleIO</p></li>
<li><p>StorageOS</p></li>
<li><p>Synology NAS</p></li>
<li><p>XSKY</p></li>
<li><p>VFS Driver</p></li>
<li><p>vSphere</p></li>
<li><p>YanRongYun</p></li>
</ul>
<p>[11]</p>
</div>
<div class="section" id="minishift">
<h3><a class="toc-backref" href="#id41">Minishift</a><a class="headerlink" href="#minishift" title="Permalink to this headline">¶</a></h3>
<p>Requirements:</p>
<ul class="simple">
<li><p>Minimum</p>
<ul>
<li><p>2 CPU cores</p></li>
<li><p>4 GB RAM</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/minishift/minishift/issues/3217#issuecomment-533769748">Recommended</a></p>
<ul>
<li><p>4 CPU cores</p></li>
<li><p>8 GB RAM</p></li>
</ul>
</li>
</ul>
<p>Minishift deploys a virtual machine with OpenShift pre-installed as a test environment for developers. This is only supported on x86_64 processors.</p>
<p><strong>Install (Fedora):</strong></p>
<ul class="simple">
<li><p>Download the latest release of Minishift from <a class="reference external" href="https://github.com/minishift/minishift/releases">here</a> and the latest release of OC from <a class="reference external" href="https://github.com/openshift/origin/releases">here</a>.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">MINISHIFT_VER</span><span class="o">=</span><span class="m">1</span>.34.2
$ wget https://github.com/minishift/minishift/releases/download/v<span class="si">${</span><span class="nv">MINISHIFT_VER</span><span class="si">}</span>/minishift-<span class="si">${</span><span class="nv">MINISHIFT_VER</span><span class="si">}</span>-linux-amd64.tgz
$ tar -v -x -f minishift-<span class="si">${</span><span class="nv">MINISHIFT_VER</span><span class="si">}</span>-linux-amd64.tgz
$ sudo curl -L https://github.com/dhiltgen/docker-machine-kvm/releases/download/v0.10.0/docker-machine-driver-kvm-centos7 -o /usr/local/bin/docker-machine-driver-kvm
$ sudo chmod <span class="m">0755</span> /usr/local/bin/docker-machine-driver-kvm
$ wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz
$ tar -v -x -f openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz
$ sudo cp openshift-origin-client-tools-v3.11.0*/oc /usr/local/bin/
$ <span class="nb">cd</span> ./minishift-<span class="si">${</span><span class="nv">MINISHIFT_VER</span><span class="si">}</span>-linux-amd64/
$ ./minishift openshift version list
$ ./minishift start --openshift-version v3.11.0
</pre></div>
</div>
<ul class="simple">
<li><p>Optionally access the virtual machine.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ ./minishift ssh
</pre></div>
</div>
<p>[12][13]</p>
<p><strong>Install (RHEL 7):</strong></p>
<p>Enable the Red Hat Developer Tools repository first. Then Minishift can be installed.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo subscription-manager repos --enable rhel-7-server-devtools-rpms
$ sudo yum install cdk-minishift
$ minishift setup-cdk --force --default-vm-driver<span class="o">=</span><span class="s2">&quot;kvm&quot;</span>
$ sudo ln -s ~/.minishift/cache/oc/v3.*/linux/oc /usr/bin/oc
$ minishift openshift version list
$ minishift start --openshift-version v3.11.0
</pre></div>
</div>
<p>[14]</p>
<p>For installing newer versions of Minishift, the old environment must be wiped first.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ minishift stop
$ minishift delete
$ rm -rf ~/.kube ~/.minishift
$ sudo rm -f <span class="k">$(</span>which oc<span class="k">)</span>
</pre></div>
</div>
<p>[17]</p>
</div>
<div class="section" id="codeready-containers-crc">
<h3><a class="toc-backref" href="#id42">CodeReady Containers (CRC)</a><a class="headerlink" href="#codeready-containers-crc" title="Permalink to this headline">¶</a></h3>
<p>Requirements:</p>
<ul class="simple">
<li><p>4 CPU cores</p></li>
<li><p>9 GB RAM</p></li>
<li><p>35 GB of storage</p></li>
<li><p>Operating system: Enterprise Linux &gt;= 7.5 or Fedora</p></li>
</ul>
<p><a class="reference external" href="https://github.com/code-ready/crc">Red Hat CodeReady Containers (CRC)</a> deploys a minimal RHOCP 4 environment into a virtual machine without machine-config and monitoring services. It requires a free developer account from Red Hat to download the <code class="docutils literal notranslate"><span class="pre">crc</span></code> binary and copy the pull secret from <a class="reference external" href="https://cloud.redhat.com/openshift/install/crc/installer-provisioned">here</a>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tar -x -v -f ~/Downloads/crc-linux-amd64.tar.xz
$ mv ~/Downloads/crc-linux-*-amd64/crc ~/.local/bin/
</pre></div>
</div>
<p>Delete any existing CRC virtual machines if they exist, prepare the hypervisor, and then start a new OpenShift virtual machine. All installation files are stored in <code class="docutils literal notranslate"><span class="pre">~/.crc</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ crc delete
$ crc setup
$ crc start
? Image pull secret &lt;PASTE_PULL_SECRET_HERE&gt;
</pre></div>
</div>
<p>Find the path to the <code class="docutils literal notranslate"><span class="pre">oc</span></code> binary to use.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ crc oc-env
</pre></div>
</div>
<p>Optionally log into the virtual machine.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ crc console
</pre></div>
</div>
<p>Stop the virtual machine at any time.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ crc stop
</pre></div>
</div>
<p>[28]</p>
</div>
<div class="section" id="kind">
<h3><a class="toc-backref" href="#id43">kind</a><a class="headerlink" href="#kind" title="Permalink to this headline">¶</a></h3>
<p>kind is a tool written in Go that is used by the upstream Kubernetes developers. It simulates different Kubernetes nodes via the use of containers on a single local workstation.</p>
<p>Installation:</p>
<ul>
<li><p>All operating systems:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nv">GO111MODULE</span><span class="o">=</span><span class="s2">&quot;on&quot;</span> go get sigs.k8s.io/kind@v0.9.0
</pre></div>
</div>
</li>
<li><p>macOS specific:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ brew install kind
</pre></div>
</div>
</li>
</ul>
<p>Usage:</p>
<ul>
<li><p>Create a cluster:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kind create cluster
</pre></div>
</div>
</li>
<li><p>Or create a cluster using a specific tag from <a class="reference external" href="https://hub.docker.com/r/kindest/node/tags?page=1&amp;ordering=last_updated">here</a>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kind create cluster --image kindest/node:&lt;TAG&gt;
</pre></div>
</div>
</li>
<li><p>Or create a cluster using a Kubernetes manifest file for the Cluster API:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kind create cluster --config<span class="o">=</span>&lt;CLUSTER_MANIFEST&gt;.yaml
</pre></div>
</div>
</li>
<li><p>Configure kubectl to use the cluster by default:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl cluster-info --context kind-kind
</pre></div>
</div>
</li>
</ul>
<p>[45]</p>
</div>
<div class="section" id="openshift-ansible">
<h3><a class="toc-backref" href="#id44">OpenShift Ansible</a><a class="headerlink" href="#openshift-ansible" title="Permalink to this headline">¶</a></h3>
<p>The OpenShift Ansible project is an official collection of Ansible playbooks to manage the installation and life-cycle of production OpenShift clusters.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/openshift/openshift-ansible.git
$ <span class="nb">cd</span> openshift-ansible
$ git checkout release-3.11
</pre></div>
</div>
<p>Settings for the deployment are defined in a single inventory file. Examples can be found in the <code class="docutils literal notranslate"><span class="pre">inventory</span></code> directory. <code class="docutils literal notranslate"><span class="pre">[OSEv3:children]</span></code> is a group of groups that should contain all of the hosts.</p>
<p>Inventory file variables:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_deployment_type</span></code> = <code class="docutils literal notranslate"><span class="pre">origin</span></code> for the upstream OKD on CentOS or <code class="docutils literal notranslate"><span class="pre">openshift-enterprise</span></code> for the downstream OCP on Red Hat CoreOS.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_release</span></code> = The OpenShift release to use. Example: <code class="docutils literal notranslate"><span class="pre">v3.11</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_master_identity_providers=[{'name':</span> <span class="pre">'htpasswd_auth',</span> <span class="pre">'login':</span> <span class="pre">'true',</span> <span class="pre">'challenge':</span> <span class="pre">'true',</span> <span class="pre">'kind':</span> <span class="pre">'HTPasswdPasswordIdentityProvider'}]</span></code> = Enable htpasswd authentication.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_master_htpasswd_users={'&lt;USER1&gt;':</span> <span class="pre">'&lt;HTPASSWD_HASH&gt;',</span> <span class="pre">'&lt;USER2&gt;':</span> <span class="pre">'&lt;HTPASSWD_HASH&gt;'}</span></code> = Configure OpenShift users. Create a password for the user by running <code class="docutils literal notranslate"><span class="pre">htpasswd</span> <span class="pre">-nb</span> <span class="pre">&lt;USER&gt;</span> <span class="pre">&lt;PASSWORD&gt;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_disable_check=memory_availability,disk_availability</span></code> = Disable certain checks for a minimal lab deployment.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_master_cluster_hostname</span></code> = The private internal hostname.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">openshift_master_cluster_public_hostname</span></code> = The public internal hostname.</p></li>
</ul>
<p>[15]</p>
<p>The container registry is ephemeral so after a reboot the data will be wiped. All of the storage inventory configuration options and settings can be found <a class="reference external" href="https://docs.openshift.com/container-platform/3.11/install/configuring_inventory_file.html#advanced-install-registry">here</a>. For lab environments using NFS, unsupported options will need to be enabled using <code class="docutils literal notranslate"><span class="pre">openshift_enable_unsupported_configurations=True</span></code>. The <code class="docutils literal notranslate"><span class="pre">nfs</span></code> group will also need to be created and added to the <code class="docutils literal notranslate"><span class="pre">OSEv3:children</span></code> group of groups.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo yum -y ansible pyOpenSSL python-cryptography python-lxml
$ sudo ansible-playbook -i &lt;INVENTORY_FILE&gt; playbooks/prerequisites.yml
$ sudo ansible-playbook -i &lt;INVENTORY_FILE&gt; playbooks/deploy_cluster.yml
</pre></div>
</div>
<p>Persistent container application storage can also be configured after installation by using one of the configurations from <a class="reference external" href="https://docs.openshift.com/container-platform/3.11/install_config/persistent_storage/index.html">here</a>.</p>
<p>Uninstall OpenShift services from Nodes by specifying them in the inventory and using the uninstall playbook.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo ansible-playbook -i &lt;INVENTORY_FILE&gt; playbooks/adhoc/uninstall.yml
</pre></div>
</div>
</div>
<div class="section" id="id8">
<h3><a class="toc-backref" href="#id45">Tanzu</a><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id9">
<h4><a class="toc-backref" href="#id46">TKGm</a><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p>Before installing a Kubernetes cloud with Tanzu, the <code class="docutils literal notranslate"><span class="pre">tkg</span></code> utility has to be set up.</p>
<ul class="simple">
<li><p>Install both <code class="docutils literal notranslate"><span class="pre">docker</span></code> and <code class="docutils literal notranslate"><span class="pre">kubectl</span></code>.</p></li>
<li><p>Download the Tanzu-related binaries from <a class="reference external" href="https://www.vmware.com/go/get-tkg">here</a>. A VMWare account is required to login and download it.</p></li>
<li><p>Extract the binaries:  <code class="docutils literal notranslate"><span class="pre">tar</span> <span class="pre">-v</span> <span class="pre">-x</span> <span class="pre">-f</span> <span class="pre">tkg-linux-amd64-v${TKG_VERSION}-vmware.1.tar.gz</span></code></p></li>
<li><p>Move them into an executable location in <code class="docutils literal notranslate"><span class="pre">$PATH</span></code>: <code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">+x</span> <span class="pre">./tkg/*</span> <span class="pre">&amp;&amp;</span> <span class="pre">mv</span> <span class="pre">./tkg/*</span> <span class="pre">~/.local/bin/</span></code></p></li>
<li><p>Symlink the <code class="docutils literal notranslate"><span class="pre">tkg</span></code> binary: <code class="docutils literal notranslate"><span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">~/.local/bin/tkg-linux-amd64-v${TKG_VERSION}+vmware.1</span> <span class="pre">~/.local/bin/tkg</span></code></p></li>
<li><p>Verify that <code class="docutils literal notranslate"><span class="pre">tkg</span></code> works: <code class="docutils literal notranslate"><span class="pre">tkg-linux-amd64-&lt;VERSION&gt;+vmware.1</span> <span class="pre">version</span></code>.</p></li>
<li><p>Create the configuration files in <code class="docutils literal notranslate"><span class="pre">~/.tkg/</span></code> by running: <code class="docutils literal notranslate"><span class="pre">tkg</span> <span class="pre">get</span> <span class="pre">management-cluster</span></code></p></li>
</ul>
<p>[34]</p>
<div class="section" id="aws">
<h5><a class="toc-backref" href="#id47">AWS</a><a class="headerlink" href="#aws" title="Permalink to this headline">¶</a></h5>
<p>Setup a TKG Management Cluster and then the production Kubernetes cluster using infrastructure provided by Amazon Web Services (AWS).</p>
<ul>
<li><p>Install <code class="docutils literal notranslate"><span class="pre">jq</span></code>.</p></li>
<li><p>Install the dependencies for the <code class="docutils literal notranslate"><span class="pre">aws</span></code> command: <code class="docutils literal notranslate"><span class="pre">glibc</span></code>, <code class="docutils literal notranslate"><span class="pre">groff</span></code>, and <code class="docutils literal notranslate"><span class="pre">less</span></code>.</p></li>
<li><p>Install the <code class="docutils literal notranslate"><span class="pre">aws</span></code> utility and verify it works. Find the latest version from <a class="reference external" href="https://github.com/aws/aws-cli/blob/v2/CHANGELOG.rst">here</a>. [35]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">AWS_CLI_VERSION</span><span class="o">=</span><span class="s2">&quot;2.0.59&quot;</span>
$ curl -O <span class="s2">&quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64-</span><span class="si">${</span><span class="nv">AWS_CLI_VERSION</span><span class="si">}</span><span class="s2">.zip&quot;</span>
$ unzip awscli-*.zip
$ sudo ./aws/install
$ aws --version
</pre></div>
</div>
</li>
<li><p>Generate a SSH key pair: <code class="docutils literal notranslate"><span class="pre">aws</span> <span class="pre">ec2</span> <span class="pre">create-key-pair</span> <span class="pre">--key-name</span> <span class="pre">default</span> <span class="pre">--output</span> <span class="pre">json</span> <span class="pre">|</span> <span class="pre">jq</span> <span class="pre">.KeyMaterial</span> <span class="pre">-r</span> <span class="pre">&gt;</span> <span class="pre">default.pem</span></code></p></li>
<li><p>Kubernetes installation:</p>
<blockquote>
<div><ul>
<li><p>Creat the AWS CloudFormation stack and then initialize/create the TKG Management Cluster. [36]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># CLI setup.</span>
$ <span class="nb">export</span> <span class="nv">AWS_REGION</span><span class="o">=</span>&lt;REGION&gt;
$ <span class="nb">export</span> <span class="nv">AWS_SSH_KEY_NAME</span><span class="o">=</span><span class="s2">&quot;default&quot;</span>
$ tkg config permissions aws
$ tkg init --infrastructure aws --plan <span class="o">[</span>dev<span class="p">|</span>prod<span class="o">]</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Alternatively, use the web dashboard setup.</span>
$ tkg init --ui
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<ul>
<li><p>Optionally create a configuration file for the production Kubernetes cluster. By default, the “dev” plan will create one Control Plane Node and the “prod” plan will create three. Both will create one Worker Node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tkg config cluster &lt;KUBERNETES_CLUSTER_NAME&gt; --plan <span class="o">[</span>dev<span class="p">|</span>prod<span class="o">]</span> --controlplane-machine-count &lt;CONTROLPLANE_COUNT&gt; --worker-machine-count &lt;WORKER_COUNT&gt; --namespace &lt;NAMESPACE&gt; &gt; ~/.tkg/cluster_config.yaml
</pre></div>
</div>
</li>
<li><p>Deploy the production Kubernetes cluster and give it a unique and descriptive name. [37]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tkg create cluster &lt;KUBERNETES_CLUSTER_NAME&gt; --plan <span class="o">[</span>dev<span class="p">|</span>prod<span class="o">]</span> --kubernetes-version<span class="o">=</span>v1.19.1
</pre></div>
</div>
</li>
<li><p>Verify that the production Kubernetes cluster can now be accessed. [38]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tkg get cluster
$ tkg get credentials &lt;KUBERNETES_CLUSTER_NAME&gt;
Credentials of workload cluster <span class="s1">&#39;&lt;KUBERNETES_CLUSTER_NAME&gt;&#39;</span> have been saved
You can now access the cluster by running <span class="s1">&#39;kubectl config use-context &lt;KUBERNETES_CLUSTER_NAME&gt;-admin@&lt;KUBERNETES_CLUSTER_NAME&gt;&#39;</span>
$ kubectl config use-context &lt;KUBERNETES_CLUSTER_NAME&gt;-admin@&lt;KUBERNETES_CLUSTER_NAME&gt;
$ kubectl get nodes -o wide
$ kubectl get -n kube-system pods
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section" id="uninstall">
<h2><a class="toc-backref" href="#id48">Uninstall</a><a class="headerlink" href="#uninstall" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id10">
<h3><a class="toc-backref" href="#id49">CodeReady Containers (CRC)</a><a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>Stop CRC, delete the virtual machine, and cleanup system-wide configuration changes the installer made. Then delete all of the CRC files or at least remove the <code class="docutils literal notranslate"><span class="pre">~/.crc/cache/</span></code> directory to free up storage space.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ crc stop
$ crc delete
$ crc cleanup
$ rm -rf ~/.crc/
</pre></div>
</div>
</div>
<div class="section" id="id11">
<h3><a class="toc-backref" href="#id50">kubeadm</a><a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>Any Node provisioned with <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">init</span></code> or <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">join</span></code> can uninstall Kubernetes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm reset
$ sudo rm -f /etc/cni/net.d/*
$ sudo ipvsadm --clear
</pre></div>
</div>
<p>Reset the <code class="docutils literal notranslate"><span class="pre">iptables</span></code> rules [51]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo iptables -F
$ sudo iptables -t nat -F
$ sudo iptables -t mangle -F
$ sudo iptables -X
</pre></div>
</div>
</div>
<div class="section" id="id12">
<h3><a class="toc-backref" href="#id51">k3s</a><a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>Control Plane Nodes:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo /usr/local/bin/k3s-uninstall.sh
</pre></div>
</div>
<p>Worker Nodes:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo /usr/local/bin/k3s-agent-uninstall.sh
</pre></div>
</div>
</div>
<div class="section" id="id13">
<h3><a class="toc-backref" href="#id52">kind</a><a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>Remove all kind containers by running this command [45]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kind delete cluster
</pre></div>
</div>
</div>
<div class="section" id="id14">
<h3><a class="toc-backref" href="#id53">Tanzu</a><a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id15">
<h4><a class="toc-backref" href="#id54">TKGm</a><a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>First, uninstall the production Kubernetes cluster(s). [39]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tkg delete cluster &lt;TKG_CLUSTER&gt;
</pre></div>
</div>
</li>
<li><p>Finally, delete the Management Cluster. [40]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ tkg delete management-cluster &lt;TKG_MANAGEMENT_CLUSTER&gt;
</pre></div>
</div>
<ul>
<li><p>This error may occur. Workaround the issue by setting the environment variable <code class="docutils literal notranslate"><span class="pre">AWS_B64ENCODED_CREDENTIALS</span></code> to any value. [41]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Logs</span> <span class="n">of</span> <span class="n">the</span> <span class="n">command</span> <span class="n">execution</span> <span class="n">can</span> <span class="n">also</span> <span class="n">be</span> <span class="n">found</span> <span class="n">at</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">tkg</span><span class="o">-</span><span class="mi">20201031</span><span class="n">T164426485425119</span><span class="o">.</span><span class="n">log</span>
<span class="n">Verifying</span> <span class="n">management</span> <span class="n">cluster</span><span class="o">...</span>

<span class="n">Error</span><span class="p">:</span> <span class="p">:</span> <span class="n">unable</span> <span class="n">to</span> <span class="n">delete</span> <span class="n">management</span> <span class="n">cluster</span><span class="p">:</span> <span class="n">unable</span> <span class="n">to</span> <span class="n">get</span> <span class="n">management</span> <span class="n">cluster</span> <span class="n">provider</span> <span class="n">information</span><span class="p">:</span> <span class="n">error</span> <span class="n">verifying</span> <span class="n">config</span> <span class="n">variables</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">variables</span> <span class="p">[</span><span class="n">AWS_B64ENCODED_CREDENTIALS</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">set</span><span class="o">.</span> <span class="n">Please</span> <span class="nb">set</span> <span class="n">the</span> <span class="n">value</span> <span class="n">using</span> <span class="n">os</span> <span class="n">environment</span> <span class="n">variables</span> <span class="ow">or</span> <span class="n">the</span> <span class="n">tkg</span> <span class="n">config</span> <span class="n">file</span>

<span class="n">Detailed</span> <span class="n">log</span> <span class="n">about</span> <span class="n">the</span> <span class="n">failure</span> <span class="n">can</span> <span class="n">be</span> <span class="n">found</span> <span class="n">at</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">tkg</span><span class="o">-</span><span class="mi">20201031</span><span class="n">T164426485425119</span><span class="o">.</span><span class="n">log</span>
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">AWS_B64ENCODED_CREDENTIALS</span><span class="o">=</span>foobar
$ tkg delete management-cluster &lt;TKG_MANAGEMENT_CLUSTER&gt;
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="upgrade">
<h2><a class="toc-backref" href="#id55">Upgrade</a><a class="headerlink" href="#upgrade" title="Permalink to this headline">¶</a></h2>
<div class="section" id="introduction">
<h3><a class="toc-backref" href="#id56">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h3>
<p>Upgrades can be done from one minor or patch release to another. Minor version upgrades cannot skip a version. For example, upgrading from 1.17.0 to 1.18.4 can be done but from 1.17.0 to 1.19.0 will not work. [30]</p>
<p>Compatibility guarantees differ between services [31]:</p>
<ul class="simple">
<li><p>kube-apiserver = No other component in the cluster can have a minor version higher than this.</p></li>
<li><p>kubelet and kube-proxy = Supports two versions behind the kube-apiserver.</p></li>
<li><p>cloud-controller-manager, kube-controller-manager, and kube-scheduler = Supports one version behind kube-apiserver.</p></li>
<li><p>kubectl (client) = Supports one version older than, later than, or equal to the kube-apiserver.</p></li>
</ul>
<p>Common upgrade scenarios (for a Kubernetes and/or operating system upgrade), in order of recommendation:</p>
<ol class="arabic simple">
<li><p>Upgrade one Node at a time. Workloads will be migrated off the Node.</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">drain</span></code> to remove all workloads from the Node.</p></li>
<li><p>Once the upgrade is complete, use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">uncordon</span></code> to allow workloads to be scheduled on the Node again.</p></li>
</ul>
</li>
<li><p>Upgrade one Node at a time to new hardware. Workloads will be migrated off the Node.</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">drain</span></code> to remove all workloads from the old Node.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">delete</span> <span class="pre">node</span></code> to delete the old Node.</p></li>
</ul>
</li>
<li><p>Upgrade all Nodes at the same time. This will cause downtime.</p></li>
</ol>
</div>
<div class="section" id="id16">
<h3><a class="toc-backref" href="#id57">Minikube</a><a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>Minikube can be upgraded by starting with a specified Kubernetes version (or use “latest”). [29]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ minikube stop
$ minikube start --kubernetes-version<span class="o">=</span>&lt;VERSION&gt;
</pre></div>
</div>
</div>
<div class="section" id="id17">
<h3><a class="toc-backref" href="#id58">kubeadm</a><a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<div class="section" id="control-plane-nodes">
<h4><a class="toc-backref" href="#id59">Control Plane Nodes</a><a class="headerlink" href="#control-plane-nodes" title="Permalink to this headline">¶</a></h4>
<p>Check for a newer version of <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ apt update
$ apt-cache madison kubeadm
</pre></div>
</div>
<p>Update <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> to the desired Kubernetes version to upgrade to.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo apt-get install -y --allow-change-held-packages <span class="nv">kubeadm</span><span class="o">=</span>&lt;KUBERNETES_PACKAGE_VERSION&gt;
</pre></div>
</div>
<p>View the modifications that a <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">upgrade</span></code> would make.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm upgrade plan
</pre></div>
</div>
<p>Upgrade to the specified <code class="docutils literal notranslate"><span class="pre">X.Y.Z</span></code> version on the first Control Plane Node</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm upgrade apply vX.Y.Z
</pre></div>
</div>
<p>Log into the other Control Plane Nodes and upgrade those.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm upgrade node vX.Y.Z
</pre></div>
</div>
<p>Upgrade the <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> service on all of the Control Plane Nodes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ apt-get install -y --allow-change-held-packages <span class="nv">kubelet</span><span class="o">=</span>&lt;KUBERNETES_PACKAGE_VERSION&gt; <span class="nv">kubectl</span><span class="o">=</span>&lt;KUBERNETES_PACKAGE_VERSION&gt;
$ sudo systemctl daemon-reload
$ sudo systemctl restart kubelet
</pre></div>
</div>
<p>[30]</p>
</div>
<div class="section" id="worker-nodes">
<h4><a class="toc-backref" href="#id60">Worker Nodes</a><a class="headerlink" href="#worker-nodes" title="Permalink to this headline">¶</a></h4>
<p>Update <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>.</p>
<p>Drain all objects from one of the Worker Nodes.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl drain --ignore-daemonsets &lt;NODE&gt;
</pre></div>
</div>
<p>Upgrade the Worker Node.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo kubeadm upgrade node
</pre></div>
</div>
<p>Upgrade the <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> service.</p>
<p>Allow objects to be scheduled onto the Node again.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl uncordon &lt;NODE&gt;
</pre></div>
</div>
<p>Verify that all Nodes have the “READY” status.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl get nodes
</pre></div>
</div>
<p>[30]</p>
</div>
</div>
<div class="section" id="id18">
<h3><a class="toc-backref" href="#id61">k3s</a><a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>Either update the local git repository and checkout the desired version tag to upgrade to or curl the latest installer script and specify the version using an environment variable.</p>
<p>Control Plane Nodes:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -sfL https://get.k3s.io <span class="p">|</span> <span class="nv">INSTALL_K3S_VERSION</span><span class="o">=</span>&lt;GITHUB_VERSION_TAG&gt; sh -a
</pre></div>
</div>
<p>Work Nodes:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ curl -sfL https://get.k3s.io <span class="p">|</span> <span class="nv">K3S_TOKEN</span><span class="o">=</span>&lt;TOKEN&gt; <span class="nv">K3S_URL</span><span class="o">=</span>https://&lt;MASTER_HOST&gt;:6443 <span class="nv">INSTALL_K3S_VERSION</span><span class="o">=</span>&lt;GITHUB_VERSION_TAG&gt; sh -a
</pre></div>
</div>
<p>Verify that the upgrade worked.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ k3s --version
</pre></div>
</div>
<p>[10]</p>
</div>
<div class="section" id="id19">
<h3><a class="toc-backref" href="#id62">kind</a><a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>kind does not officially support upgrades. It was designed for developers to spin up new Kubernetes clusters temporarily for testing. However, it is technically possible to use <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> to upgrade each Node. [46]</p>
</div>
</div>
<div class="section" id="ingress-controllers">
<h2><a class="toc-backref" href="#id63">Ingress Controllers</a><a class="headerlink" href="#ingress-controllers" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Ingress</span></code> API requires at least one Ingress Controller to be installed. That controller creates a <code class="docutils literal notranslate"><span class="pre">Service</span></code> of type <code class="docutils literal notranslate"><span class="pre">LoadBalancer</span></code> using an external IP address that is available on all of the Nodes. Domain names should have their DNS resolve to that IP address.</p>
<p>The Ingress Controller will handle all incoming HTTP connections on port 80. It also supports handling TLS termination for incoming HTTPS connections on port 443. Custom layer 7 routing rules for the HTTP/S traffic can be defined via the API.</p>
<p>Other ports and protocols are not supported. Use a <code class="docutils literal notranslate"><span class="pre">Service</span></code> of type <code class="docutils literal notranslate"><span class="pre">LoadBalancer</span></code> or <code class="docutils literal notranslate"><span class="pre">NodePort</span></code> instead for applications that do not use HTTP or require a custom port. [58]</p>
<p>Popular Ingress controllers [57]:</p>
<ul class="simple">
<li><p>Ambassador</p></li>
<li><p>Contour</p></li>
<li><p>HAProxy</p></li>
<li><p>Istio</p></li>
<li><p>Kong</p></li>
<li><p>NGINX</p></li>
<li><p>Traefik</p></li>
<li><p>Voyager</p></li>
</ul>
<p>A full list of Ingress Controllers can be found <a class="reference external" href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">here</a>.</p>
<div class="section" id="traefik">
<h3><a class="toc-backref" href="#id64">Traefik</a><a class="headerlink" href="#traefik" title="Permalink to this headline">¶</a></h3>
<p>Traefik provides features such as advancing routing, SSL/TLS certificate management, and LetsEncrypt support for automatically creating and signing new certificates. [43]</p>
<p>Installation [44]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ helm repo add traefik https://helm.traefik.io/traefik
$ helm repo update
$ helm install traefik traefik/traefik
$ helm <span class="nb">history</span> traefik
</pre></div>
</div>
</div>
</div>
<div class="section" id="concepts">
<h2><a class="toc-backref" href="#id65">Concepts</a><a class="headerlink" href="#concepts" title="Permalink to this headline">¶</a></h2>
<div class="section" id="container-network-interface-cni-plugins">
<h3><a class="toc-backref" href="#id66">Container Network Interface (CNI) Plugins</a><a class="headerlink" href="#container-network-interface-cni-plugins" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> service on each <code class="docutils literal notranslate"><span class="pre">Node</span></code> interacts with a CNI plugin to manage the network connections between Pods. The cloud operator must pick at least one plugin. For using more than one plugin, use the <a class="reference external" href="https://github.com/intel/multus-cni">Multus CNI project</a>. Canal (both Calico and Flannel combined into a single plugin) is recommended for most use cases.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Plugin</p></th>
<th class="head"><p>Arm Support</p></th>
<th class="head"><p>Ease of Configuration</p></th>
<th class="head"><p>Resource Usage</p></th>
<th class="head"><p>Network Layer</p></th>
<th class="head"><p>Encryption</p></th>
<th class="head"><p>NetworkPolicy Support</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Calico</p></td>
<td><p>Yes</p></td>
<td><p>Medium</p></td>
<td><p>Low</p></td>
<td><p>3</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Highly configurable</p></td>
</tr>
<tr class="row-odd"><td><p>Canal</p></td>
<td><p>Yes</p></td>
<td><p>Medium</p></td>
<td><p>Low</p></td>
<td><p>3</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Combine the easiness of Flannel and the NetworkPolicy support of Calico</p></td>
</tr>
<tr class="row-even"><td><p>Cilium</p></td>
<td><p>No</p></td>
<td><p>Easy</p></td>
<td><p>High</p></td>
<td><p>3</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>BPF Linux kernel integration</p></td>
</tr>
<tr class="row-odd"><td><p>Flannel</p></td>
<td><p>Yes</p></td>
<td><p>Easy</p></td>
<td><p>Low</p></td>
<td><p>2</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>Simple overlay network management</p></td>
</tr>
<tr class="row-even"><td><p>kubenet</p></td>
<td><p>Yes</p></td>
<td><p>Easy</p></td>
<td><p>Low</p></td>
<td><p>2</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>Very basic Linux bridge management</p></td>
</tr>
<tr class="row-odd"><td><p>kube-router</p></td>
<td><p>Yes</p></td>
<td><p>Medium</p></td>
<td><p>Low</p></td>
<td><p>3</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Feature rich</p></td>
</tr>
<tr class="row-even"><td><p>Weave Net</p></td>
<td><p>Yes</p></td>
<td><p>Hard</p></td>
<td><p>Medium</p></td>
<td><p>3</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Manage mesh networks</p></td>
</tr>
<tr class="row-odd"><td><p>Weave Net (Encrypted)</p></td>
<td><p>Yes</p></td>
<td><p>Hard</p></td>
<td><p>High</p></td>
<td><p>3</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Secure networks</p></td>
</tr>
</tbody>
</table>
<p>Recommended CNI plugins for each use case:</p>
<ul class="simple">
<li><p>Proof-of-concept = kubenet. It is built into Kubernetes and does not require any additional setup.</p></li>
<li><p>Home lab = Flannel. Easy to setup and provides container network separation.</p></li>
<li><p>Work lab = Canal. It expands upond Flannel by adding support for other features such as the  NetworkPolicy API.</p></li>
<li><p>Encryption = Weave Net. Designed to be scalable and secure.</p></li>
</ul>
<p>Legacy plugins that are no longer maintained:</p>
<ul class="simple">
<li><p>Romana</p></li>
</ul>
<p>[19][20]</p>
</div>
<div class="section" id="role-based-access-control-rbac">
<h3><a class="toc-backref" href="#id67">Role-Based Access Control (RBAC)</a><a class="headerlink" href="#role-based-access-control-rbac" title="Permalink to this headline">¶</a></h3>
<p>RBAC is enabled by default on a Kubernetes cluster by the <code class="docutils literal notranslate"><span class="pre">kube-apiserver</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kube-apiserver --authorization-mode<span class="o">=</span>RBAC
</pre></div>
</div>
<p>There are four APIs that configure RBAC. Roles define what verbs (actions) are allowed. RoleBindings assign a Role to a user or, group or service account.</p>
<p>Namespaced APIs:</p>
<ul class="simple">
<li><p>Role</p></li>
<li><p>RoleBinding</p></li>
</ul>
<p>Non-namespaced APIs:</p>
<ul class="simple">
<li><p>ClusterRole</p></li>
<li><p>ClusterRoleBinding</p></li>
</ul>
<p>Common verbs:</p>
<ul class="simple">
<li><p>create</p></li>
<li><p>delete</p></li>
<li><p>get (read)</p></li>
<li><p>update</p></li>
</ul>
<p>Find out if the current user, or a different user, can run a specific command.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl auth can-i &lt;VERB&gt; &lt;API&gt;
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl auth can-i &lt;VERB&gt; &lt;API&gt; --as<span class="o">=</span>&lt;USER&gt;
</pre></div>
</div>
<p>Commands can be run as a specific user or group:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl --as<span class="o">=</span>&lt;USER&gt;
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl --as-group<span class="o">=</span>&lt;GROUP&gt;
</pre></div>
</div>
<p>[56]</p>
<div class="section" id="user-accounts">
<h4><a class="toc-backref" href="#id68">User Accounts</a><a class="headerlink" href="#user-accounts" title="Permalink to this headline">¶</a></h4>
<p>A user is defined using the “common name” (CN) subject in a TLS certificate. The certificate is used instead of a password to authenticate to a Kubernetes cluster. Basic/password authentication was removed in Kubernetes 1.19. [61] The certificate must be signed by the Kubernetes certificate authority (CA).</p>
<ul>
<li><p>Create a public and private key-pair for a new user.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openssl genrsa -out &lt;USER&gt;.key <span class="m">4096</span>
</pre></div>
</div>
</li>
<li><p>Create a certificate signing request for the new user.</p>
<ul>
<li><p>Normal user:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openssl req -new -key &lt;USER&gt;.key -subj <span class="s2">&quot;/CN=&lt;USER&gt;&quot;</span> -out &lt;USER&gt;.csr
</pre></div>
</div>
</li>
<li><p>Administrative user. Only use this if the certificate will be manually signed. The <code class="docutils literal notranslate"><span class="pre">CertificateSigningRequest</span></code> (CSR) API does not allow creating objects with the organization field set to “system:masters”. Instead, create a normal user above and apply administrative privileges as part of the CSR and [Cluster]RoleBinding objects.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openssl req -new -key &lt;USER&gt;.key -subj <span class="s2">&quot;/CN=&lt;USER&gt;/O=system:masters&quot;</span> -out &lt;USER&gt;.csr
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Create and sign the certificate either manually using the Kubernetes certificate authority (found on the Control Plane Nodes) or using the Kubernetes CSR API.</p>
<ul>
<li><p>Manually:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ openssl x509 -req -in &lt;USER&gt;.csr -CA ca.crt -CAkey ca.key -out &lt;USER&gt;.crt
</pre></div>
</div>
</li>
<li><p>CSR API:</p>
<ul>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">base64</span></code> to encode the certificate key file into a string.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ base64 -w <span class="m">0</span> &lt;USER&gt;.csr
</pre></div>
</div>
</li>
<li><p>Create a CSR object. Refer to <a class="reference external" href="kubernetes_development.html#certificatesigningrequest">examples from the Kubernetes Development documentation about CSR</a>.</p></li>
<li><p>The CSR will be in a <code class="docutils literal notranslate"><span class="pre">Pending</span></code> state until manually approved by an administrator user.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl get csr &lt;CSR_OBJECT_NAME&gt;
$ kubectl certificate approve &lt;CSR_OBJECT_NAME&gt;
</pre></div>
</div>
</li>
<li><p>Extract the certificate file. If the CSR was valid, a <code class="docutils literal notranslate"><span class="pre">csr.status.certificate</span></code> field will be populated with the <code class="docutils literal notranslate"><span class="pre">base64</span></code> encoded certificate file.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl get csr &lt;CSR_OBJECT_NAME&gt; --template<span class="o">={{</span>.status.certificate<span class="o">}}</span> <span class="p">|</span> base64 -d &gt; &lt;USER&gt;.crt
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Unless the certificate was created manually with the <code class="docutils literal notranslate"><span class="pre">/O=system:masters</span></code> privileges, a [Cluster]Role and [Cluster]RoleBinding must be created for the user to assign permissions.</p></li>
<li><p>Find or create a role to use that will define the permissions the user has to the cluster.</p>
<blockquote>
<div><ul>
<li><p>Find and use an existing ClusterRole (this can be used for a RoleBinding, not just a ClusterRoleBinding). For an administrator account, use <code class="docutils literal notranslate"><span class="pre">cluster-admin</span></code> for full access to everything or <code class="docutils literal notranslate"><span class="pre">admin</span></code> for full access only to the default APIs.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl get clusterroles
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<ul>
<li><p>Or create a new [Cluster]Role.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl create <span class="o">[</span>cluster<span class="o">]</span>role &lt;ROLE_NAME&gt; --verb<span class="o">=</span>&lt;VERB_1&gt;,&lt;VERB_2&gt; --resource<span class="o">=</span>&lt;API_1&gt;,&lt;API_2&gt;
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Create a [Cluster]RoleBinding to grant the user those permissions.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl create <span class="o">[</span>cluster<span class="o">]</span>rolebinding --<span class="o">[</span>cluster<span class="o">]</span><span class="nv">role</span><span class="o">=</span>&lt;ROLE_NAME&gt; --user<span class="o">=</span>&lt;USER&gt; &lt;ROLEBINDING_NAME&gt;
</pre></div>
</div>
</li>
</ul>
<p>[56][62]</p>
<ul>
<li><p>Finally a user can authenticate to the cluster either via <code class="docutils literal notranslate"><span class="pre">kubectl</span></code> or manually via an HTTP request through a tool such as <code class="docutils literal notranslate"><span class="pre">curl</span></code>. Verify that the new account is working as expected.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">$HOME/.kube/config</span></code> file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">curl</span></code>:</p></li>
</ol>
<blockquote>
<div><p>2a.  Syntax: <code class="docutils literal notranslate"><span class="pre">curl</span> <span class="pre">--cert</span> <span class="pre">&lt;USER&gt;.crt</span> <span class="pre">--key</span> <span class="pre">&lt;USER&gt;.key</span> <span class="pre">--cacert</span> <span class="pre">ca.crt</span> <span class="pre">https://&lt;CONTROL_PLANE_IP&gt;:6443/</span></code>
2b.  Example: <code class="docutils literal notranslate"><span class="pre">curl</span> <span class="pre">--cert</span> <span class="pre">&lt;USER&gt;.crt</span> <span class="pre">--key</span> <span class="pre">&lt;USER&gt;.key</span> <span class="pre">-k</span> <span class="pre">https://127.0.0.1:6443/api/v1/namespaces/default/pods/</span></code></p>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="tls-certificate-creation-cert-manager">
<h3><a class="toc-backref" href="#id69">TLS Certificate Creation (cert-manager)</a><a class="headerlink" href="#tls-certificate-creation-cert-manager" title="Permalink to this headline">¶</a></h3>
<p>cert-manager provides a set of APIs that assist in the manual and automatic creation of TLS certificates.</p>
<p>cert-manager.io/v1 APIs:</p>
<ul class="simple">
<li><p>Certificate = Create a CertificateRequest and, if it processes correctly, a Secret object will be created containing the TLS certificate.</p></li>
<li><p>CertificateRequest = A request to cert-manager (either manually from the Certificate API or automatically by specifying <code class="docutils literal notranslate"><span class="pre">ingress.metadata.annotations:</span> <span class="pre">cert-manager.io/clusterissuer:</span> <span class="pre">&lt;CLUSTER_ISSUER&gt;</span></code>) to automatically create a certificate.</p></li>
<li><p>ClusterIssuer = A cluster-wide provider of certificates. Common Issuers include selfSigned, CA, and ACME (Let’s Encrypt).</p></li>
<li><p>Issuer = Namespaced Issuers.</p></li>
</ul>
<p>acme.cert-manager.io/v1 APIs (used automatically by the CertificateRequest API):</p>
<ul class="simple">
<li><p>Challenge = A DNS or HTTP challenge for ACME to prove that the domain is owned by the person making the request for a signed certificate.</p></li>
<li><p>Order = A request to ACME for a new certificate.</p></li>
</ul>
<p>[60]</p>
<p>cert-manager installation [59]:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ helm repo add jetstack https://charts.jetstack.io
$ helm repo update
$ helm install cert-manager jetstack/cert-manager --namespace cert-manager --version v1.2.0 --create-namespace --set <span class="nv">installCRDs</span><span class="o">=</span><span class="nb">true</span>
$ kubectl --namespace cert-manager get pods
</pre></div>
</div>
<p>The process of managing certificates:</p>
<ol class="arabic simple">
<li><p>Create a [Cluster]Issuer object once.</p></li>
<li><p>Create a Certificate object using a [Cluster]Issuer for each domain that requires TLS encryption.</p></li>
<li><p>Use the Certificate(s) in an Ingress or Gateway object(s).</p></li>
</ol>
</div>
</div>
<div class="section" id="troubleshooting">
<h2><a class="toc-backref" href="#id70">Troubleshooting</a><a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<div class="section" id="errors">
<h3><a class="toc-backref" href="#id71">Errors</a><a class="headerlink" href="#errors" title="Permalink to this headline">¶</a></h3>
<p>Error when installing Flannel with <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">apply</span> <span class="pre">-f</span> <span class="pre">https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl -n kube-system describe pod kube-flannel-ds-rgzpn
E0304 <span class="m">04</span>:04:44.958281       <span class="m">1</span> main.go:292<span class="o">]</span> Error registering network: failed to acquire lease: node <span class="s2">&quot;&lt;NODE_HOSTNAME&gt;&quot;</span> pod cidr not assigned
</pre></div>
</div>
<p>Solution:</p>
<ul class="simple">
<li><p>Kubernetes was not installed with a Pod network CIDR assigned. For kubeadm, uninstall the cluster and reinstall with the argument: <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">--pod-network-cidr=10.244.0.0/16</span></code>.</p></li>
</ul>
<hr class="docutils" />
<p>CoreDNS container is stuck in the <code class="docutils literal notranslate"><span class="pre">STATUS</span></code> of <code class="docutils literal notranslate"><span class="pre">ContainerCreating</span></code> with the error message <code class="docutils literal notranslate"><span class="pre">failed</span> <span class="pre">to</span> <span class="pre">find</span> <span class="pre">plugin</span> <span class="pre">&quot;&lt;PLUGIN&gt;&quot;</span> <span class="pre">in</span> <span class="pre">path</span> <span class="pre">[&lt;PATH&gt;]</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl -n kube-system describe pod coredns-f9fd979d6-cr7p6
  Warning  FailedCreatePodSandBox  69s <span class="o">(</span>x17 over 4m40s<span class="o">)</span>  kubelet            <span class="o">(</span>combined from similar events<span class="o">)</span>: Failed to create pod sandbox: rpc error: <span class="nv">code</span> <span class="o">=</span> Unknown <span class="nv">desc</span> <span class="o">=</span> failed to setup network <span class="k">for</span> sandbox <span class="s2">&quot;76c5c21331dd5998d9a6efd5ac6d74c45b10386db7d34555c7e0f22f5969ee13&quot;</span>: failed to find plugin <span class="s2">&quot;loopback&quot;</span> <span class="k">in</span> path <span class="o">[</span>/usr/lib/cni<span class="o">]</span>
</pre></div>
</div>
<p>Solutions:</p>
<ul>
<li><p>The CNI plugins might be installed to a different path such as <code class="docutils literal notranslate"><span class="pre">/opt/cni/bin/</span></code> instead of <code class="docutils literal notranslate"><span class="pre">/usr/lib/cni/</span></code>. Run this command to create a symlink to it: <code class="docutils literal notranslate"><span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">/opt/cni/bin</span> <span class="pre">/usr/lib/cni</span></code>.</p></li>
<li><p>If the CNI plugins are missing from the system, then download the source code, compile the plugins, and then copy them to the correct directory. [52]</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/containernetworking/plugins.git
$ <span class="nb">cd</span> plugins
$ ./build_linux.sh
$ sudo mkdir -p /usr/lib/cni/ <span class="c1"># Or use &#39;/opt/cni/bin/&#39;.</span>
$ sudo cp ./bin/* /usr/lib/cni/
</pre></div>
</div>
</li>
</ul>
<hr class="docutils" />
<p>CoreDNS container is stuck in <code class="docutils literal notranslate"><span class="pre">STATUS</span></code> of <code class="docutils literal notranslate"><span class="pre">ContainerCreating</span></code> with the error message <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">getting</span> <span class="pre">ClusterInformation:</span> <span class="pre">connection</span> <span class="pre">is</span> <span class="pre">unauthorized:</span> <span class="pre">Unauthorized</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl -n kube-system describe pod coredns-f9fd979d6-72lh2
  Warning  FailedCreatePodSandBox  3m3s <span class="o">(</span>x17 over 6m33s<span class="o">)</span>  kubelet            <span class="o">(</span>combined from similar events<span class="o">)</span>: Failed to create pod sandbox: rpc error: <span class="nv">code</span> <span class="o">=</span> Unknown <span class="nv">desc</span> <span class="o">=</span> failed to setup network <span class="k">for</span> sandbox <span class="s2">&quot;dcc4d29a213211977d0aa11195980a11533d722cfcd9ef11cf7b1385ef9dde10&quot;</span>: error getting ClusterInformation: connection is unauthorized: Unauthorized
</pre></div>
</div>
<p>Solution:</p>
<ul>
<li><p>Calico/Canal or another CNI plugin was uninstalled. CNI plugins usually leave configuration files on the system. Manually delete those files.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo rm -f /etc/cni/net.d/10-canal.conflist /etc/cni/net.d/calico-kubeconfig
</pre></div>
</div>
</li>
</ul>
<hr class="docutils" />
<p><code class="docutils literal notranslate"><span class="pre">k3s</span></code> keeps reporting the error <code class="docutils literal notranslate"><span class="pre">x509:</span> <span class="pre">certificate</span> <span class="pre">has</span> <span class="pre">expired</span> <span class="pre">or</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">yet</span> <span class="pre">valid</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ sudo cat /var/log/syslog
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: E0310 <span class="m">21</span>:11:18.648950     <span class="m">438</span> reflector.go:153<span class="o">]</span> k8s.io/client-go/informers/factory.go:135: Failed to list *v1beta1.Event: Unauthorized
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: E0310 <span class="m">21</span>:11:18.664390     <span class="m">438</span> authentication.go:104<span class="o">]</span> Unable to authenticate the request due to an error: x509: certificate has expired or is not yet valid
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: I0310 <span class="m">21</span>:11:18.665009     <span class="m">438</span> log.go:172<span class="o">]</span> http: TLS handshake error from <span class="m">127</span>.0.0.1:45154: remote error: tls: bad certificate
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: E0310 <span class="m">21</span>:11:18.666361     <span class="m">438</span> reflector.go:153<span class="o">]</span> k8s.io/client-go/informers/factory.go:135: Failed to list *v1beta1.CSIDriver: Get https://127.0.0.1:6443/apis/storage.k8s.io/v1beta1/csidrivers?limit<span class="o">=</span><span class="m">500</span><span class="p">&amp;</span><span class="nv">resourceVersion</span><span class="o">=</span><span class="m">0</span>: x509: certificate has expired or is not yet valid
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: E0310 <span class="m">21</span>:11:18.667607     <span class="m">438</span> reflector.go:153<span class="o">]</span> k8s.io/client-go/informers/factory.go:135: Failed to list *v1.Pod: Unauthorized
Mar <span class="m">10</span> <span class="m">21</span>:11:18 kube0 k3s<span class="o">[</span><span class="m">438</span><span class="o">]</span>: E0310 <span class="m">21</span>:11:18.696824     <span class="m">438</span> authentication.go:104<span class="o">]</span> Unable to authenticate the request due to an error: x509: certificate has expired or is not yet valid
</pre></div>
</div>
<p>Solutions:</p>
<ul>
<li><p>The system time is set incorrectly.</p></li>
<li><p>Upgrade to &gt;= <code class="docutils literal notranslate"><span class="pre">v1.19.1+k3s1</span></code> where certificate rotation was fixed.</p></li>
<li><p>Restart the <code class="docutils literal notranslate"><span class="pre">k3s</span></code> service. Once it starts, if it detects that a certificate is going to expire within 90 days or less, it will recreate the certificates.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Control-plane Node</span>
$ sudo systemctl restart k3s
<span class="c1"># Worker Node</span>
$ sudo systemctl restart k3s-agent
</pre></div>
</div>
</li>
<li><p>The certificate has already expired. <code class="docutils literal notranslate"><span class="pre">k3s</span></code> will only rotate certificates that are about to expire (not ones that have expired). Manually set the date back to force the certificates to be regenerated.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl get nodes
Unable to connect to the server: x509: certificate has expired or is not yet valid: current <span class="nb">time</span> <span class="m">2021</span>-03-10T21:34:56Z is after <span class="m">2021</span>-02-27T21:54:59Z
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stop the &#39;k3s&#39; (Control Plane) or &#39;k3s-agent&#39; (Worker Node) service.</span>
$ sudo systemctl stop k3s
<span class="c1"># Manually set the date to be within 90 days before the certificate has expired.</span>
$ sudo date -s <span class="m">20210220</span>
<span class="c1"># Start k3s to rotate the certificates.</span>
$ sudo systemctl start k3s
<span class="c1"># Verify it works now.</span>
$ kubectl get nodes
<span class="c1"># Stop k3s.</span>
$ sudo systemctl stop k3s
<span class="c1"># Set the date back manually. Or use a time synchornization program such as &#39;chronyd&#39; or &#39;ntpd&#39;.</span>
$ sudo date -s <span class="m">20210310</span>
</pre></div>
</div>
</li>
</ul>
<p>[53]</p>
<hr class="docutils" />
<p>Error <code class="docutils literal notranslate"><span class="pre">use</span> <span class="pre">of</span> <span class="pre">&lt;SIGNER_NAME&gt;</span> <span class="pre">signer</span> <span class="pre">with</span> <span class="pre">system:masters</span> <span class="pre">group</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">allowed</span></code> when creating a CertificateSigningRequest object:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f csr-user-foobar.yaml
Error from server <span class="o">(</span>Forbidden<span class="o">)</span>: error when creating <span class="s2">&quot;csr-user-foobar.yaml&quot;</span>: certificatesigningrequests.certificates.k8s.io <span class="s2">&quot;csr-user-foobar&quot;</span> is forbidden: use of kubernetes.io/kube-apiserver-client signer with system:masters group is not allowed
</pre></div>
</div>
<p>Solutions:</p>
<ul class="simple">
<li><p>Manually create/sign the certificate with <code class="docutils literal notranslate"><span class="pre">openssl</span></code> and the Kubernetes CA.</p></li>
<li><p>Or use <code class="docutils literal notranslate"><span class="pre">openssl</span></code> to generate a new certificate signing request that does not include <code class="docutils literal notranslate"><span class="pre">/O=system:masters</span></code>.</p></li>
</ul>
</div>
</div>
<div class="section" id="history">
<h2><a class="toc-backref" href="#id72">History</a><a class="headerlink" href="#history" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/virtualization/kubernetes_administration.rst">Latest</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/virtualization/kubernetes.rst">&lt; 2019.10.01</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/virtualization/containers.rst">&lt; 2019.07.01</a></p></li>
<li><p><a class="reference external" href="https://github.com/ekultails/rootpages/commits/master/src/administration/virtualization.rst">&lt; 2019.04.01</a></p></li>
</ul>
</div>
<div class="section" id="bibliography">
<h2><a class="toc-backref" href="#id73">Bibliography</a><a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>“Kubernetes Components.” Kubernetes Concepts. January 16, 2020. Accessed April 8, 2020. <a class="reference external" href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/</a></p></li>
<li><p>“The History of Kubernetes on a Timeline.” RisingStack Blog. June 20, 2018. Accessed April 8, 2020. <a class="reference external" href="https://blog.risingstack.com/the-history-of-kubernetes/">https://blog.risingstack.com/the-history-of-kubernetes/</a></p></li>
<li><p>“Understanding persistent storage.” Red Hat OpenShift Container Platform 4.5 Documentation. Accessed July 16, 2020. <a class="reference external" href="https://docs.openshift.com/container-platform/4.5/storage/understanding-persistent-storage.html">https://docs.openshift.com/container-platform/4.5/storage/understanding-persistent-storage.html</a></p></li>
<li><p>“OKD: Renaming of OpenShift Origin with 3.10 Release.” Red Hat OpenShift Blog. August 3, 2018. Accessed September 17, 2018. <a class="reference external" href="https://blog.openshift.com/okd310release/">https://blog.openshift.com/okd310release/</a></p></li>
<li><p>“Releases Notes. OpenShift Container Platform 4.1 Documentation. <a class="reference external" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.1/html-single/release_notes/index">https://access.redhat.com/documentation/en-us/openshift_container_platform/4.1/html-single/release_notes/index</a></p></li>
<li><p>“Red Hat OpenShift Container Platform Life Cycle Policy.” Red Hat Support. Accessed March 9, 2020. <a class="reference external" href="https://access.redhat.com/support/policy/updates/openshift">https://access.redhat.com/support/policy/updates/openshift</a></p></li>
<li><p>“Install Minikube.” Kubernetes Documentation. Accessed September 17, 2018. <a class="reference external" href="https://kubernetes.io/docs/tasks/tools/install-minikube/">https://kubernetes.io/docs/tasks/tools/install-minikube/</a></p></li>
<li><p>“Kubernetes 1.13: Simplified Cluster Management with Kubeadm, Container Storage Interface (CSI), and CoreDNS as Default DNS are Now Generally Available.” Kubernetes Blog. December 3, 2018. Accessed December 5, 2018. <a class="reference external" href="https://kubernetes.io/blog/2018/12/03/kubernetes-1-13-release-announcement/">https://kubernetes.io/blog/2018/12/03/kubernetes-1-13-release-announcement/</a></p></li>
<li><p>“Creating a cluster with kubeadm.” Kubernetes Documentation. February 4, 2021. Accessed February 19, 2021. <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></p></li>
<li><p>“k3s - 5 less than k8s.” k3s, GitHub. March 29, 2019. Accessed April 1, 2019. <a class="reference external" href="https://github.com/rancher/k3s">https://github.com/rancher/k3s</a></p></li>
<li><p>“Drivers.” Kubernetes CSI Developer Documentation. Accessed April 11, 2019. <a class="reference external" href="https://kubernetes-csi.github.io/docs/drivers.html">https://kubernetes-csi.github.io/docs/drivers.html</a></p></li>
<li><p>“Minishift Quickstart.” OpenShift Documentation. Accessed February 26, 2018. <a class="reference external" href="https://docs.openshift.org/latest/minishift/getting-started/quickstart.html">https://docs.openshift.org/latest/minishift/getting-started/quickstart.html</a></p></li>
<li><p>“Run OpenShift Locally with Minishift.” Fedora Magazine. June 20, 2017. Accessed February 26, 2018. <a class="reference external" href="https://fedoramagazine.org/run-openshift-locally-minishift/">https://fedoramagazine.org/run-openshift-locally-minishift/</a></p></li>
<li><p>“CHAPTER 5. INSTALLING RED HAT CONTAINER DEVELOPMENT KIT.” Red Hat Customer Portal. Accessed February 26, 2018. <a class="reference external" href="https://access.redhat.com/documentation/en-us/red_hat_container_development_kit/3.0/html/installation_guide/installing-rhcdk">https://access.redhat.com/documentation/en-us/red_hat_container_development_kit/3.0/html/installation_guide/installing-rhcdk</a></p></li>
<li><p>“Configuring Clusters.” OpenShift Container Platform Documentation. Accessed February 5, 2019. <a class="reference external" href="https://docs.openshift.com/container-platform/3.11/install_config/index.html">https://docs.openshift.com/container-platform/3.11/install_config/index.html</a></p></li>
<li><p>“OpenShift: Container Application Platform by Red Hat.” OpenShift. Accessed February 26, 2018. <a class="reference external" href="https://www.openshift.com/">https://www.openshift.com/</a></p></li>
<li><p>“How to run AWX on Minishift.” opensource.com. October 26, 2018. Accessed July 3, 2020. <a class="reference external" href="https://opensource.com/article/18/10/how-run-awx-minishift">https://opensource.com/article/18/10/how-run-awx-minishift</a></p></li>
<li><p>“kube-controller-manager.” Kubernetes Reference. April 13, 2020. Accessed June 8, 2020. <a class="reference external" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/</a></p></li>
<li><p>“Comparing Kubernetes CNI Providers: Flannel, Calico, Canal, and Weave.” Rancher Lab’s Kubernetes Blog. December 4, 2019. Accessed July 14, 2020. <a class="reference external" href="https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave/">https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave/</a></p></li>
<li><p>“Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network (Updated: April 2019).” ITNEXT. April 12, 2019. Accessed July 14, 2020. <a class="reference external" href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560">https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560</a></p></li>
<li><p>“OKD4 is now Generally Available.” Red Hat OpenShift Blog. July 15, 2020. Accessed July 16, 2020. <a class="reference external" href="https://www.openshift.com/blog/okd4-is-now-generally-available">https://www.openshift.com/blog/okd4-is-now-generally-available</a></p></li>
<li><p>“Guide to Installing an OKD 4.4 Cluster on your Home Lab.” Red Hat OpenShift Blog. March 24, 2020. July 16, 2020. <a class="reference external" href="https://openshift.com/blog/guide-to-installing-an-okd-4-4-cluster-on-your-home-lab">https://openshift.com/blog/guide-to-installing-an-okd-4-4-cluster-on-your-home-lab</a></p></li>
<li><p>“OpenShift 4.0 Infrastructure Deep Dive.” YouTube - Rob Szumski. January 23, 2019. Accessed July 16, 2020. <a class="reference external" href="https://www.youtube.com/watch?v=Wi3QNi4zi_4">https://www.youtube.com/watch?v=Wi3QNi4zi_4</a></p></li>
<li><p>“The OpenShift Container Platform control plane.” Red Hat OpenShift Container Platform 4.5 Documentation. Accessed July 16, 2020. <a class="reference external" href="https://docs.openshift.com/container-platform/4.5/architecture/control-plane.html">https://docs.openshift.com/container-platform/4.5/architecture/control-plane.html</a></p></li>
<li><p>“Understanding cluster logging.” Red Hat OpenShift Container Platform 4.5 Documentation. Accessed July 16. <a class="reference external" href="https://docs.openshift.com/container-platform/4.5/logging/cluster-logging.html">https://docs.openshift.com/container-platform/4.5/logging/cluster-logging.html</a></p></li>
<li><p>“Router Overview.” Red Hat OpenShift Container Platform 3.11 Documentation. Accessed July 16, 2020. <a class="reference external" href="https://docs.openshift.com/container-platform/3.11/install_config/router/index.html">https://docs.openshift.com/container-platform/3.11/install_config/router/index.html</a></p></li>
<li><p>“Installation methods for different platforms.” Red Hat OpenShift Container Platform 4.5. Accessed July 16, 2020. <a class="reference external" href="https://docs.openshift.com/container-platform/4.5/installing/install_config/installation-types.html">https://docs.openshift.com/container-platform/4.5/installing/install_config/installation-types.html</a></p></li>
<li><p>“Getting Started Guide.” crc. Accessed August 13, 2020. <a class="reference external" href="https://code-ready.github.io/crc/">https://code-ready.github.io/crc/</a></p></li>
<li><p>“Basic controls.” minikube Documentation. April 7, 2020. Accessed October 18, 2020. <a class="reference external" href="https://minikube.sigs.k8s.io/docs/handbook/controls/">https://minikube.sigs.k8s.io/docs/handbook/controls/</a></p></li>
<li><p>“Upgrading kubeadm clusters.” Kubernetes Documentation. August 7, 2020. Accessed October 18, 2020. <a class="reference external" href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/</a></p></li>
<li><p>“Kubernetes version and version skew support policy.” Kubernetes Documentation. August 15, 2020. Accessed October 18, 2020. <a class="reference external" href="https://kubernetes.io/docs/setup/release/version-skew-policy/">https://kubernetes.io/docs/setup/release/version-skew-policy/</a></p></li>
<li><p>“Deploying Tanzu Kubernetes Clusters and Managing their Lifecycle.” VMware Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-index.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-index.html</a></p></li>
<li><p>“VMware Tanzu Kubernetes Grid 1.2 Release Notes.” VMware Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/rn/VMware-Tanzu-Kubernetes-Grid-12-Release-Notes.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/rn/VMware-Tanzu-Kubernetes-Grid-12-Release-Notes.html</a></p></li>
<li><p>“Download and Install the Tanzu Kubernetes Grid CLI.” VMware Tanzu Kubernetes Grid Docs. August 27, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.1/vmware-tanzu-kubernetes-grid-11/GUID-install-tkg-set-up-tkg.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.1/vmware-tanzu-kubernetes-grid-11/GUID-install-tkg-set-up-tkg.html</a></p></li>
<li><p>“AWS Command Line Interface User Guide.” AWS Documentation. May 19, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.aws.amazon.com/cli/latest/userguide/aws-cli.pdf">https://docs.aws.amazon.com/cli/latest/userguide/aws-cli.pdf</a></p></li>
<li><p>“Deploy Management Clusters to Amazon EC2 with the CLI.” VMware Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-mgmt-clusters-aws-cli.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-mgmt-clusters-aws-cli.html</a></p></li>
<li><p>“Create Tanzu Kubernetes Clusters.” VMware Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-create.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-create.html</a></p></li>
<li><p>“Connect to and Examine Tanzu Kubernetes Clusters.” VMware Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 27, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-connect.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-connect.html</a></p></li>
<li><p>“Delete Tanzu Kubernetes Clusters.” VMWare Tanzu Kubernetes Grid Docs. October 26, 2020. Accessed October 31, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-delete-cluster.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.2/vmware-tanzu-kubernetes-grid-12/GUID-tanzu-k8s-clusters-delete-cluster.html</a></p></li>
<li><p>“Delete Management Clusters.” VMWare Tanzu Kubernetes Grid Docs. August 27, 2020. Accessed October 31, 2020. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.1/vmware-tanzu-kubernetes-grid-11/GUID-manage-instance-delete-management-cluster.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.1/vmware-tanzu-kubernetes-grid-11/GUID-manage-instance-delete-management-cluster.html</a></p></li>
<li><p>“[clusterctl] “clusterctl config provider” fails to show AWS, VSphere, and Azure info #2876.” GitHub kubernetes-sigs/cluster-api. April 20, 2020. Accessed October 31, 2020.</p></li>
<li><p>“Container runtimes.” Kubernetes Documentation. October 28, 2020. Accessed November 14, 2020. <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">https://kubernetes.io/docs/setup/production-environment/container-runtimes/</a></p></li>
<li><p>“Traefik &amp; Kubernetes.” Traefik Labs Docs. 2020. Accessed November 30, 2020. <a class="reference external" href="https://doc.traefik.io/traefik/providers/kubernetes-ingress/">https://doc.traefik.io/traefik/providers/kubernetes-ingress/</a></p></li>
<li><p>“Install Traefik.” Traefik Labs Docs. 2020. Accessed November 30, 2020. <a class="reference external" href="https://doc.traefik.io/traefik/getting-started/install-traefik/">https://doc.traefik.io/traefik/getting-started/install-traefik/</a></p></li>
<li><p>“Quick Start.” kind. December 3, 2020. Accessed January 19, 2021. <a class="reference external" href="https://kind.sigs.k8s.io/docs/user/quick-start">https://kind.sigs.k8s.io/docs/user/quick-start</a></p></li>
<li><p>“Upgrading underlying kubernetes version #1972.” GitHub kubernetes-sigs/kind. December 9, 2020. Accessed January 19, 2021. <a class="reference external" href="https://github.com/kubernetes-sigs/kind/issues/1972">https://github.com/kubernetes-sigs/kind/issues/1972</a></p></li>
<li><p>“Port Requirements.” Rancher Docs: Port Requirements. November 17, 2020. Accessed February 19, 2021. <a class="reference external" href="https://rancher.com/docs/rancher/v2.x/en/installation/requirements/ports/">https://rancher.com/docs/rancher/v2.x/en/installation/requirements/ports/</a></p></li>
<li><p>“kubeadm.” GitHub flannel-io/flannel. October 25, 2020. Accessed February 19, 2021. <a class="reference external" href="https://github.com/flannel-io/flannel/blob/master/Documentation/kubernetes.md">https://github.com/flannel-io/flannel/blob/master/Documentation/kubernetes.md</a></p></li>
<li><p>“Install Calico for policy and flannel (aka Canal) for networking.” Project Calico Documentation. April 17, 2020. Accessed February 19, 2021. <a class="reference external" href="https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel">https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel</a></p></li>
<li><p>“Installation Options.” Rancher Docs. Accessed February 24, 2021. <a class="reference external" href="https://rancher.com/docs/k3s/latest/en/installation/install-options/">https://rancher.com/docs/k3s/latest/en/installation/install-options/</a></p></li>
<li><p>“Properly Resetting Your kubeadm-bootstrapped Cluster Nodes — #HeptioProTip.” Heptio Blog. January 3, 2018. March 2, 2021. <a class="reference external" href="https://blog.heptio.com/properly-resetting-your-kubeadm-bootstrapped-cluster-nodes-heptioprotip-473bd0b824aa">https://blog.heptio.com/properly-resetting-your-kubeadm-bootstrapped-cluster-nodes-heptioprotip-473bd0b824aa</a></p></li>
<li><p>“coredns been in Pending state.” Programmer Sought. Accessed March 3, 2021.  <a class="reference external" href="https://www.programmersought.com/article/23693305901/">https://www.programmersought.com/article/23693305901/</a></p></li>
<li><p>“certificate expired and rotate #1621.” GitHub k3s-io/k3s. February 8, 2021. Accessed March 10, 2021. <a class="reference external" href="https://github.com/k3s-io/k3s/issues/1621">https://github.com/k3s-io/k3s/issues/1621</a></p></li>
<li><p>“VMware Tanzu Kubernetes Grid Documentation.” VMware Docs. Accessed March 11, 2021. <a class="reference external" href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/index.html">https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/index.html</a></p></li>
<li><p>“Welcome to Cloud Foundry BOSH.” Cloud Foundry BOSH. Accessed March 11, 2021. <a class="reference external" href="https://bosh.io/docs/">https://bosh.io/docs/</a></p></li>
<li><p>“Authenticating.” Kubernetes Documentation. February 27, 2021. Accessed March 31, 2021. <a class="reference external" href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/">https://kubernetes.io/docs/reference/access-authn-authz/authentication/</a></p></li>
<li><p>“Comparing Ingress controllers for Kubernetes.” Flant Blog. October 12, 2019. Accessed March 26, 2021. <a class="reference external" href="https://medium.com/flant-com/comparing-ingress-controllers-for-kubernetes-9b397483b46b">https://medium.com/flant-com/comparing-ingress-controllers-for-kubernetes-9b397483b46b</a></p></li>
<li><p>“Ingress Controllers.” Kubernetes Documentation. February 13, 2021. Accessed March 30, 2021. <a class="reference external" href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers">https://kubernetes.io/docs/concepts/services-networking/ingress-controllers</a></p></li>
<li><p>“Kubernetes.” cert-manager Documentation. March 8, 2021. Accessed March 31, 2021. <a class="reference external" href="https://cert-manager.io/docs/installation/kubernetes/">https://cert-manager.io/docs/installation/kubernetes/</a></p></li>
<li><p>“API reference docs.” cert-manager Documentation. January 1, 2021. Accessed March 31, 2021. <a class="reference external" href="https://cert-manager.io/docs/reference/api-docs/">https://cert-manager.io/docs/reference/api-docs/</a></p></li>
<li><p>“basic auth is deprecated.” Kubernetes Master Charm Bugs. October 2, 2021. Accessed March 31, 2021. <a class="reference external" href="https://bugs.launchpad.net/charm-kubernetes-master/+bug/1841226">https://bugs.launchpad.net/charm-kubernetes-master/+bug/1841226</a></p></li>
<li><p>“Using RBAC Authentication.” Kubernetes Documentation. February 11, 2021. Accessed March 31, 2021. <a class="reference external" href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">https://kubernetes.io/docs/reference/access-authn-authz/rbac/</a></p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="kubernetes_development.html" class="btn btn-neutral float-right" title="Kubernetes Development" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="containers.html" class="btn btn-neutral float-left" title="Containers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright None, Copyleft 2021, Luke Short. Documents licensed under GFDLv1.3.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>